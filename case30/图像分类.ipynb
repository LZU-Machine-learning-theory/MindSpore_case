{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2455484-0759-46d6-b780-2332e90ffffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from mindspore import context\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.dataset.vision as C\n",
    "from mindspore.dataset.vision import Inter\n",
    "from mindspore import dtype as mstype\n",
    "import mindspore.nn as nn\n",
    "from mindspore.common.initializer import Normal\n",
    "from mindspore.nn.loss import SoftmaxCrossEntropyWithLogits\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig\n",
    "from mindspore.nn.metrics import Accuracy\n",
    "import mindspore.dataset.transforms as C2\n",
    "from mindspore.train.callback import LossMonitor\n",
    "from mindspore import Model\n",
    "import mindspore.ops as ops\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "from src.resnet import resnet50 as resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c65387-ea20-4ba1-8319-0e62cb22a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_home, do_train, batch_size=32, repeat_num=1):\n",
    "    \"\"\"\n",
    "    create a train or evaluate cifar10 dataset for resnet50\n",
    "    Args:\n",
    "        dataset_path(string): the path of dataset.\n",
    "        do_train(bool): whether dataset is used for train or eval.\n",
    "        repeat_num(int): the repeat times of dataset. Default: 1\n",
    "        batch_size(int): the batch size of dataset. Default: 32\n",
    "        target(str): the device target. Default: Ascend\n",
    "\n",
    "    Returns:\n",
    "        dataset\n",
    "    \"\"\"\n",
    "    # define dataset\n",
    "    cifar_ds = ds.Cifar10Dataset(data_home)\n",
    "\n",
    "    resize_height = 224\n",
    "    resize_width = 224\n",
    "    rescale = 1.0 / 255.0\n",
    "    shift = 0.0\n",
    "\n",
    "    # define map operations\n",
    "    random_crop_op = C.RandomCrop((32, 32), (4, 4, 4, 4)) # padding_mode default CONSTANT\n",
    "    random_horizontal_op = C.RandomHorizontalFlip()\n",
    "    resize_op = C.Resize((resize_height, resize_width)) # interpolation default BILINEAR\n",
    "    rescale_op = C.Rescale(rescale, shift)\n",
    "    normalize_op = C.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    changeswap_op = C.HWC2CHW()\n",
    "    type_cast_op = C2.TypeCast(mstype.int32)\n",
    "\n",
    "    c_trans = []\n",
    "    if do_train:\n",
    "        c_trans = [random_crop_op, random_horizontal_op]\n",
    "    c_trans += [resize_op, rescale_op, normalize_op, changeswap_op]\n",
    "\n",
    "    # apply map operations on images\n",
    "    cifar_ds = cifar_ds.map(operations=type_cast_op, input_columns=\"label\")\n",
    "    cifar_ds = cifar_ds.map(operations=c_trans, input_columns=\"image\")\n",
    "\n",
    "\n",
    "    # apply DatasetOps\n",
    "    # buffer_size = 10000\n",
    "    # apply shuffle operations\n",
    "    cifar_ds = cifar_ds.shuffle(buffer_size=10)\n",
    "\n",
    "    # apply batch operations\n",
    "    #cifar_ds = cifar_ds.batch(batch_size=args_opt.batch_size, drop_remainder=True) #fix this\n",
    "    cifar_ds = cifar_ds.batch(batch_size, drop_remainder=True) #fix this\n",
    "\n",
    "    # apply repeat operations\n",
    "    cifar_ds = cifar_ds.repeat(repeat_num)\n",
    "\n",
    "    return cifar_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6349d635-6d9d-4eb2-9067-4e9e303751f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(model, epoch_size, data_home, repeat_size, ckpoint_cb, sink_mode):\n",
    "    \"\"\"define the training method\"\"\"\n",
    "    print(\"============== Starting Training ==============\")\n",
    "        # init weight\n",
    "\n",
    "    #load training dataset\n",
    "    ds_train = create_dataset(os.path.join(data_home, \"cifar-10-batches-bin\"), do_train=True, batch_size=32,repeat_num=1)\n",
    "    model.train(epoch_size, ds_train, callbacks=[ckpoint_cb, LossMonitor()], dataset_sink_mode=sink_mode) # cifar-10-batches-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43f3d906-6dc7-4cef-870b-4aea1a5ceac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Training ==============\n",
      "epoch: 1 step: 1875, loss is 2.053201198577881\n",
      "epoch: 2 step: 1875, loss is 1.3122313022613525\n",
      "epoch: 3 step: 1875, loss is 1.238176941871643\n",
      "epoch: 4 step: 1875, loss is 1.3249584436416626\n",
      "epoch: 5 step: 1875, loss is 0.9439748525619507\n",
      "epoch: 6 step: 1875, loss is 0.7959902286529541\n",
      "epoch: 7 step: 1875, loss is 0.27575594186782837\n",
      "epoch: 8 step: 1875, loss is 0.7118561267852783\n",
      "epoch: 9 step: 1875, loss is 0.4283088445663452\n",
      "epoch: 10 step: 1875, loss is 0.5507620573043823\n"
     ]
    }
   ],
   "source": [
    "context.set_context(mode=context.GRAPH_MODE, device_target='Ascend')\n",
    "dataset_sink_mode = True\n",
    "# download mnist dataset\n",
    "#download_dataset()\n",
    "\n",
    "# loss function definition\n",
    "loss = SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n",
    "\n",
    "#learning rate setting\n",
    "#lr = 0.01\n",
    "momentum = 0.9\n",
    "#create the network\n",
    "net = resnet(class_num=10)\n",
    "#define the optimizer\n",
    "opt = nn.Momentum(filter(lambda x: x.requires_grad, net.get_parameters()), 0.01, 0.9)\n",
    "batch_num = 128\n",
    "# CheckPoint CallBack definition\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=batch_num, keep_checkpoint_max=35)\n",
    "ckpoint_cb = ModelCheckpoint(prefix=\"train_resnet_cifar10\", directory=\"./\", config=config_ck)\n",
    "\n",
    "train_epoch = 10\n",
    "cifar_path = \"\"\n",
    "dataset_size = 1\n",
    "model = Model(net, loss, opt, metrics={\"Accuracy\": Accuracy()})\n",
    "\n",
    "\n",
    "train_net(model, train_epoch, cifar_path, dataset_size, ckpoint_cb, dataset_sink_mode)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
