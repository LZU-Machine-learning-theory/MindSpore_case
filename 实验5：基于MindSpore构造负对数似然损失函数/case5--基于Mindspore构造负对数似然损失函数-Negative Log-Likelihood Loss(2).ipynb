{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c43f128",
   "metadata": {},
   "source": [
    "# 25 基于Mindspore构造负对数似然损失函数-Negative Log-Likelihood Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daf21d1",
   "metadata": {},
   "source": [
    " 本小节主要介绍构造非对称似然损失函数的设计，使用Asymmetric Loss损失函数作为讲解实例。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9317ad8",
   "metadata": {},
   "source": [
    "# 1.实验目的\n",
    "- 理解Negative Log-Likelihood Loss损失函数的意义\n",
    "- 使用MindSpore框架实现的Negative Log-Likelihood Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99b01b",
   "metadata": {},
   "source": [
    "# 2.Negative Log-Likelihood Loss损失函数知识点介绍\n",
    "- 负对数似然损失函数（Negative Log-Likelihood Loss）是在概率建模和分类任务中常用的损失函数之一。它通常用于多类别分类问题，其中每个样本被分为多个互斥的类别。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d06599",
   "metadata": {},
   "source": [
    "## 2.1 基础知识\n",
    "- 交叉熵函数和负对数似然损失函数在某种程度上是等价的。在分类任务中，交叉熵函数通常用于衡量模型输出和真实标签之间的差异，而负对数似然损失函数则用于最大化模型对观测数据的似然。\n",
    "- 对于二分类问题，交叉熵函数和负对数似然损失函数是完全等价的。对于多类别分类问题，两者在形式上稍有不同，但是在数学上是等价的。具体而言，对于多类别分类问题，交叉熵函数是对所有类别的负对数似然损失函数的平均值。\n",
    "- 需要注意的是，使用交叉熵函数计算损失时，通常要结合softmax或sigmoid等激活函数的输出，以将输出值转化为概率分布。而负对数似然损失函数通常用于直接计算概率分布的对数似然。\n",
    "- 总的来说，交叉熵函数和负对数似然损失函数在分类任务中是等价的，可以根据实际需求选择使用其中之一。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f237e9fd",
   "metadata": {},
   "source": [
    "## 2.2 似然函数(likelihood function)\n",
    "- 假设X 是观测结果序列，它的概率分布$f_x$依赖于参数$\\theta$ ，则似然函数表示为\n",
    "- 似然函数(likelihood function):\n",
    "\n",
    "$$L(\\theta|x) = f_\\theta(x) =P_\\theta(X=x)$$\n",
    "\n",
    "- $L(\\theta|x)$为参数$\\theta$的似然函数,x为随机变量X的输出.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e8547",
   "metadata": {},
   "source": [
    "## 2.3 负对数似然损失函数\n",
    "- 负对数似然损失的数学定义如下：\n",
    "\n",
    "$$L(x, y) = \\frac {-1}{N} * ∑(∑(y_i) * log(x_i)))$$\n",
    "\n",
    "- 其中，N表示样本数量，∑表示对所有样本和类别的求和操作。\n",
    "- 负对数似然损失是将真实标签和模型预测的概率分布进行逐元素相乘，然后取对数，并求和得到损失值。\n",
    "- 损失越小，模型的预测概率分布与真实标签越接近。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113605c3",
   "metadata": {},
   "source": [
    "- NLLLoss函数虽然叫负对数似然损失函数，但是该函数内部并没有像公式里那样进行了对数计算，而是在激活函数上使用了nn.LogSoftmax()函数\n",
    "- 所以NLLLoss函数只是做了求和取平均然后再取反的计算，在使用时要配合logsoftmax函数一起使用，或者直接使用交叉熵损失函数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3b592",
   "metadata": {},
   "source": [
    "# 3. 实验环境\n",
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=1.8；Python环境=3.7\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore1.8 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU CUDA 10.1|Linux-x86_64| MindSpore1.8 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore1.8 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43a45b7",
   "metadata": {},
   "source": [
    "# 4.数据处理\n",
    "\n",
    "## 4.1数据准备\n",
    "\n",
    "   在本次实验中，我们使用numpy并使用随机生成的样本点进行测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeb97e5",
   "metadata": {},
   "source": [
    "## 4.2数据处理\n",
    "\n",
    "使用numpy生成测试数据：\n",
    "\n",
    "[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]。\n",
    "\n",
    "创建一个数据样本x_sample：\n",
    "\n",
    "[[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]] \n",
    "\n",
    "\n",
    "其中包含2个样本在3个类别的预测概率,创建它们对应的标签x：[0, 2] 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1164b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入mindspore框架。\n",
    "import mindspore\n",
    "#将Model用于创建模型对象，完成网络搭建和编译，并用于训练和评估\n",
    "from mindspore import nn \n",
    "#导入可用于Cell的构造函数的算子。\n",
    "from mindspore import ops \n",
    "import sys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ce2eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入与Python解释器和它的环境有关的函数，这里是将搜索路径存放在sys模块的path中。\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10653180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[1, 3], dtype=Float32, value=\n",
       " [[ 5.00000000e+00,  7.00000000e+00,  9.00000000e+00]]),\n",
       " Tensor(shape=[2, 1], dtype=Float32, value=\n",
       " [[ 6.00000000e+00],\n",
       "  [ 1.50000000e+01]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#给定一个矩阵X，我们可以对所有元素求和。\n",
    "X = mindspore.Tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], mindspore.float32)\n",
    "X.sum(0, keepdims=True), X.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4fdcc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[2, 5], dtype=Float32, value=\n",
       "[[ 1.72094047e-01,  1.49260331e-02,  5.44132650e-01,  1.26784101e-01,  1.42063215e-01],\n",
       " [ 1.68954581e-01,  5.20583950e-02,  4.53910828e-01,  1.79067716e-01,  1.46008432e-01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#softmax函数用于将其转换为概率分布。softmax函数对每个样本（行）的元素进行指数运算，\n",
    "#然后对每个样本的元素求和，得到一个分区（partition）向量，其中每个元素表示对应样本的所有类别的指数和。\n",
    "import mindspore.ops as ops\n",
    "def softmax(X):\n",
    "    X_exp = ops.exp(X)\n",
    "    partition = X_exp.sum(1, keepdims=True)\n",
    "    return X_exp / partition\n",
    "import numpy as np\n",
    "X = mindspore.Tensor(np.random.normal(0, 1, (2, 5)), mindspore.float32)\n",
    "X\n",
    "X_prob = softmax(X)\n",
    "X_prob, X_prob.sum(1)\n",
    "X_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3961c7",
   "metadata": {},
   "source": [
    "# 5、实验过程\n",
    "\n",
    "模型的构建包括如下部分：\n",
    "- 导入库和函数\n",
    "- 定义模型\n",
    "- 自定义损失函数Negative Log-Likelihood Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1b9674",
   "metadata": {},
   "source": [
    "## 5.1内置损失函数\n",
    "下面介绍 mindspore. $\\mathrm{nn}$ 模块中内置的损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "421fe89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入必要的库，包括NumPy和MindSpore\n",
    "import numpy as np\n",
    "import mindspore as ms\n",
    "from mindspore import dataset as ds\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops.operations as P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db19287",
   "metadata": {},
   "source": [
    "## 5.2基于nn.Cell构造损失函数NLLloss\n",
    "\n",
    "nn.Cell 是MindSpore的基类，不但可用于构建网络，还可用于定义损失函数。使用 $n n$.Cell定义损失函数的过程与定义一个普通的网络相似，差别在于，其执行逻辑部分要计算的是前向网络输出与真实值之间的误差。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ff369c",
   "metadata": {},
   "source": [
    "- classmindspore.nn.NLLLoss(weight=None, ignore_index=-100, reduction='mean')\n",
    " \n",
    "- weight (Tensor) - -指定各类别的权重。若值不为None，则shape为 (C,)。数据类型仅支持float32或float16。默认值： None\n",
    " \n",
    "- reduction (str) - 指定应用于输出结果的计算方式，比如 \"none' 、 \"mean\" ， \"sum\" ，默认值： \"mean\" 。\n",
    " \n",
    "- ignore_index (int) - 指定target中需要忽略的值(一般为填充值)，使其不对梯度产生影响。默认值： -100 。\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28ddadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLLLoss(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(NLLLoss, self).__init__() \n",
    "        #使用P.LogSoftmax(axis=-1)创建了一个log_softmax操作符，\n",
    "        #该操作符在指定轴上计算对数softmax。\n",
    "        self.log_softmax = P.LogSoftmax(axis=-1)\n",
    "        #使用P.ReduceSum()创建了一个reduce_sum操作符，用于在指定轴上计算张量的和。\n",
    "        self.reduce_sum = P.ReduceSum()\n",
    "\n",
    "    def construct(self, inputs, targets):   #接收两个输入：inputs和targets。inputs表示模型的输出（经过softmax激活之前）\n",
    "                                            #targets表示目标标签。\n",
    "        log_probs = self.log_softmax(inputs)\n",
    "        loss = -self.reduce_sum(log_probs * targets)\n",
    "        print(\"log_probs\",log_probs)\n",
    "        return loss\n",
    "    # loss = -self.reduce_sum(log_probs * targets)计算了负对数似然损失。\n",
    "    # 乘积log_probs * targets将对数概率与目标标签相乘，并通过reduce_sum操作符在所有元素上求和。\n",
    "    # 负号-表示取负数，因为通常我们最小化损失函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af96e2c4",
   "metadata": {},
   "source": [
    "# 6、模型构建\n",
    "\n",
    "损失函数NLLLoss自定义完成后，创建一个数据样本及它们对应的标签y，使用y作为y_hat中概率的索引来实现负对数似然损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad6c160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "from mindspore import dataset as ds\n",
    "from mindspore.common.initializer import Normal\n",
    "from mindspore.train import LossMonitor\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor, Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f147c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Cell):#定义模型\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__\n",
    "        self.W = Parameter(initializer(Normal(0.01, 0), (num_inputs, num_outputs), mindspore.float32))\n",
    "        self.b = Parameter(initializer(Zero(), num_outputs, mindspore.float32))\n",
    "\n",
    "    def construct(self, X):\n",
    "        return softmax(ops.matmul(X.reshape((-1, self.W.shape[0])), self.W) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ec9a15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[2], dtype=Float32, value= [ 1.00000001e-01,  5.00000000e-01])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创建一个数据样本x_sample，其中包含2个样本在3个类别的预测概率，及它们对应的标签x，使用x作为x_sample中概率的索引。\n",
    "#生成标签\n",
    "x = mindspore.Tensor([0, 2], mindspore.int32)\n",
    "#生成样本\n",
    "x_sample = mindspore.Tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]], mindspore.float32)\n",
    "x_sample[[0, 1], x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96084ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[2], dtype=Float32, value= [ 2.30258751e+00,  6.93148613e-01])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#实现负对数似然损失函数\n",
    "import mindspore.numpy as mnp\n",
    "def NLLLoss(x_sample, x):\n",
    "    return -mnp.log(x_sample[mnp.arange(x_sample.shape[0]), x])\n",
    "NLLLoss(x_sample, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761d3ff2",
   "metadata": {},
   "source": [
    "# 7、模型预测\n",
    "\n",
    "定义一个计算精确度的函数，输入预测值和真实值，选择NLLLoss计算模型的精确度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f64052ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(x_sample, x):  \n",
    "    if len(x_sample.shape) > 1 and x_sample.shape[1] > 1:  \n",
    "        x_sample = x_sample.argmax(axis=1)              \n",
    "    cmp = x_sample.asnumpy() == x.asnumpy()            \n",
    "    return float(cmp.sum())\n",
    "    #使用float(cmp.sum())计算预测正确的数量，cmp.sum()返回布尔数组中为True的元素数量，即预测正确的数量。\n",
    "accuracy(x_sample, x) / len(x)\n",
    "\n",
    "    # accuracy函数接收两个输入：x_sample表示模型的预测输出，x表示真实的目标标签。\n",
    "    # 计算预测正确的数量\n",
    "    # 函数检查x_sample的形状是否大于1维且第二个维度大于1。\n",
    "    # #如果满足条件，说明x_sample是多类别预测的概率分布结果，需要使用argmax函数获取最大概率对应的类别索引。\n",
    "    # 将预测正确的数量除以样本的总数量，得到准确率。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
