{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于Mindspore构造全连接层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全连接层指的是层中的每个节点都会连接它下一层的所有节点，它是模仿人脑神经结构来构建的。用来把前边提取到的特征综合起来。由于其全相连的特性，一般全连接层的参数也是最多的。全连接层则起到将学到的“分布式特征表示”映射到样本标记空间的作用。\n",
    "\n",
    "公式如下：\n",
    "$$output=activation(X*kernel+bias)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mindspore.nn.Dense(in_channels, out_channels, weight_init='normal', bias_init='zeros', has_bias=True, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.1079562  -0.75799847 -7.678297    1.2090455 ]\n",
      " [-4.5353317   0.03348327 -4.456973    1.5525969 ]]\n",
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "from mindspore.common.tensor import Tensor\n",
    "import mindspore.nn as nn\n",
    "import numpy as np\n",
    "import mindspore.common.dtype as mstype\n",
    "\n",
    "# 构建一个2*3的矩阵，进行Dense运算\n",
    "x = Tensor(np.array([[180, 234, 154], [244, 48, 247]]), mstype.float32)\n",
    "net = nn.Dense(3, 4)\n",
    "# 输出为2*4矩阵\n",
    "output = net(x)\n",
    "print(output)\n",
    "print(output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数说明\n",
    "``` python\n",
    "in_channels (int) - Dense层输入Tensor的空间维度。\n",
    "\n",
    "out_channels (int) - Dense层输出Tensor的空间维度。\n",
    "\n",
    "weight_init (Union[Tensor, str, Initializer, numbers.Number]) - 权重参数的初始化方法。数据类型与 x 相同。str的值引用自函数 initializer。默认值：'normal'。\n",
    "\n",
    "bias_init (Union[Tensor, str, Initializer, numbers.Number]) - 偏置参数的初始化方法。数据类型与 x 相同。str的值引用自函数 initializer。默认值：'zeros'。\n",
    "\n",
    "has_bias (bool) - 是否使用偏置向量 bias 。默认值：True。\n",
    "\n",
    "activation (Union[str, Cell, Primitive, None]) - 应用于全连接层输出的激活函数。可指定激活函数名，如’relu’，或具体激活函数，如mindspore.nn.ReLU()。默认值：'None'。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自行实现Mindspore Dense API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入所需包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.common.tensor import Tensor\n",
    "from mindspore.common.initializer import initializer\n",
    "from mindspore.ops import operations as P\n",
    "from mindspore.common.parameter import Parameter\n",
    "from mindspore._extends import cell_attr_register\n",
    "from mindspore._checkparam import Rel, Validator\n",
    "from mindspore.nn.cell import Cell\n",
    "from mindspore.nn.layer.activation import get_activation\n",
    "import mindspore.common.dtype as mstype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 具体实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Dense(Cell):\n",
    "    @cell_attr_register(attrs=['has_bias', 'activation'])\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 weight_init='normal',\n",
    "                 bias_init='zeros',\n",
    "                 has_bias=True,\n",
    "                 activation=None):\n",
    "        \"\"\"Initialize Dense.\"\"\"\n",
    "        super(Dense, self).__init__()\n",
    "        self.in_channels = Validator.check_positive_int(in_channels, \"in_channels\", self.cls_name)\n",
    "        self.out_channels = Validator.check_positive_int(out_channels, \"out_channels\", self.cls_name)\n",
    "        self.has_bias = Validator.check_bool(has_bias, \"has_bias\", self.cls_name)\n",
    "        self.reshape = P.Reshape()\n",
    "        self.shape_op = P.Shape()\n",
    "        self.weight = Parameter(initializer(weight_init, [out_channels, in_channels]), name=\"weight\")\n",
    "\n",
    "        self.bias = None\n",
    "        if self.has_bias:\n",
    "            if isinstance(bias_init, Tensor):\n",
    "                if bias_init.ndim != 1 or bias_init.shape[0] != out_channels:\n",
    "                    raise ValueError(f\"For '{self.cls_name}', bias init shape error. The ndim of 'bias_init' must \"\n",
    "                                     f\"be equal to 1, and the first dim must be equal to 'out_channels'. But got \"\n",
    "                                     f\"'bias_init': {bias_init}, 'out_channels': {out_channels}.\")\n",
    "            self.bias = Parameter(initializer(bias_init, [out_channels]), name=\"bias\")\n",
    "            self.bias_add = P.BiasAdd()\n",
    "\n",
    "        self.matmul = P.MatMul(transpose_b=True)\n",
    "        self.activation = get_activation(activation) if isinstance(activation, str) else activation\n",
    "        self.activation_flag = self.activation is not None\n",
    "\n",
    "    def construct(self, x):\n",
    "        x_shape = self.shape_op(x)\n",
    "        if len(x_shape) != 2:\n",
    "            x = self.reshape(x, (-1, x_shape[-1]))\n",
    "        x = self.matmul(x, self.weight)\n",
    "        if self.has_bias:\n",
    "            x = self.bias_add(x, self.bias)\n",
    "        if self.activation_flag:\n",
    "            x = self.activation(x)\n",
    "        if len(x_shape) != 2:\n",
    "            out_shape = x_shape[:-1] + (-1,)\n",
    "            x = self.reshape(x, out_shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.9869218  -1.7707653   2.3805907   0.07664371]\n",
      " [-0.3781587  -0.6915364   1.6991204  -2.827205  ]]\n",
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "# 构建一个2*3的矩阵，进行Dense运算\n",
    "x = Tensor(np.array([[180, 234, 154], [244, 48, 247]]), mstype.float32)\n",
    "net = Dense(3, 4)\n",
    "# 输出为2*4矩阵\n",
    "output = net(x)\n",
    "print(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
