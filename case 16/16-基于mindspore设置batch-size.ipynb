{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2509b842",
   "metadata": {},
   "source": [
    "# 基于mindspore设置batch-size\n",
    "\n",
    "本小节主要介绍如何在mindspore中设置batch-size。\n",
    "\n",
    "batch操作将数据集分批，分别输入到训练系统中进行训练，可以减少训练轮次，达到加速训练过程的目的。\n",
    "\n",
    "下面的样例先构建了一个数据集，然后分别展示了丢弃多余数据与否的数据集分批结果，其中批大小为2。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896358bd",
   "metadata": {},
   "source": [
    "### 导入库和函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c481114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore.dataset as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0abc5cb",
   "metadata": {},
   "source": [
    "### 定义生成数据集函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95181c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': Tensor(shape=[3], dtype=Int32, value= [0, 1, 2])}\n",
      "{'data': Tensor(shape=[3], dtype=Int32, value= [1, 2, 3])}\n",
      "{'data': Tensor(shape=[3], dtype=Int32, value= [2, 3, 4])}\n",
      "{'data': Tensor(shape=[3], dtype=Int32, value= [3, 4, 5])}\n",
      "{'data': Tensor(shape=[3], dtype=Int32, value= [4, 5, 6])}\n"
     ]
    }
   ],
   "source": [
    "def generator_func():\n",
    "    \"\"\"定义生成数据集函数\"\"\"\n",
    "    for i in range(5):\n",
    "        yield (np.array([i, i+1, i+2]),)\n",
    "\n",
    "dataset = ds.GeneratorDataset(generator_func, [\"data\"])\n",
    "for data in dataset.create_dict_iterator():\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a74bdbc",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba43c5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------not drop remainder ------\n",
      "{'data': Tensor(shape=[2, 3], dtype=Int32, value=\n",
      "[[0, 1, 2],\n",
      " [1, 2, 3]])}\n",
      "{'data': Tensor(shape=[2, 3], dtype=Int32, value=\n",
      "[[2, 3, 4],\n",
      " [3, 4, 5]])}\n",
      "{'data': Tensor(shape=[1, 3], dtype=Int32, value=\n",
      "[[4, 5, 6]])}\n",
      "------ drop remainder ------\n",
      "{'data': Tensor(shape=[2, 3], dtype=Int32, value=\n",
      "[[0, 1, 2],\n",
      " [1, 2, 3]])}\n",
      "{'data': Tensor(shape=[2, 3], dtype=Int32, value=\n",
      "[[2, 3, 4],\n",
      " [3, 4, 5]])}\n"
     ]
    }
   ],
   "source": [
    "# 采用不丢弃多余数据的方式对数据集进行分批\n",
    "dataset = ds.GeneratorDataset(generator_func, [\"data\"])\n",
    "dataset = dataset.batch(batch_size=2, drop_remainder=False)\n",
    "print(\"------not drop remainder ------\")\n",
    "for data in dataset.create_dict_iterator():\n",
    "    print(data)\n",
    "\n",
    "# 采用丢弃多余数据的方式对数据集进行分批\n",
    "dataset = ds.GeneratorDataset(generator_func, [\"data\"])\n",
    "dataset = dataset.batch(batch_size=2, drop_remainder=True)\n",
    "print(\"------ drop remainder ------\")\n",
    "for data in dataset.create_dict_iterator():\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a72b6e",
   "metadata": {},
   "source": [
    "从上面的打印结果可以看出，数据集大小为5，每2个分一组，不丢弃多余数据时分为3组，丢弃多余数据时分为2组，最后一条数据被丢弃。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
