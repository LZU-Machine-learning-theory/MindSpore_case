{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f683d2",
   "metadata": {},
   "source": [
    "# 基于Mindspore实现二分类损失函数\n",
    "\n",
    "通过实验了解分类损失函数原理，并能够基于Mindspore框架实现分类损失函数的计算以及训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf603b85",
   "metadata": {},
   "source": [
    "## 1、实验目的\n",
    "* 学会内置损失函数的使用。\n",
    "* 掌握Mindspore中多种损失函数的特点和应用场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67132699",
   "metadata": {},
   "source": [
    "## 2、二分类损失函数原理介绍\n",
    "损失函数（loss function）或也称为代价函数（cost function），亦称目标函数，是将随机事件或其有关随机变量的取值映射为非负实数以表示该随机事件的“风险”或“损失”的函数，用于衡量预测值与真实值差异的程度。在实际的机器学习应用中，损失函数通常会作为学习准则与优化问题相联系，通过最小化损失函数求解和评估模型。\n",
    "\n",
    "(1) $n n$. L1Loss:计算预测值和目标值之间的平均绝对误差:\n",
    "$$\n",
    "\\ell(x, y)=L=\\left\\{l_1, \\ldots, l_N\\right\\}^{\\top}, \\quad \\text { with } l_n=\\left|x_n-y_n\\right|\n",
    "$$\n",
    "其中N为数据集中的 batch_size 值。\n",
    "$$\n",
    "\\ell(x, y)= \\begin{cases}\\operatorname{mean}(L), & \\text { if reduction }=\\text { 'mean'; } \\\\ \\operatorname{sum}(L), & \\text { if reduction='sum' }\\end{cases}\n",
    "$$\n",
    "nn.L1Loss 中的参数 reduction 取值可为 mean， sum，或 none 。若 reduction 为 mean 或 sum，则输出一个经过均值或求和后的标量 Tensor (降维) ；若 reduction 为 none，则所输出Tensor的shape为广播后的shape。\n",
    "\n",
    "(2)平均绝对误差MAE(Mean Absolute Error):计算模型预测值 f(x) 与样本真实值 y 之间距离的平均值。\n",
    "$$\\mathrm{MAE}=\\frac{1}{m} \\sum_{i=1}^{m}\\left|y_{i}-f\\left(x_{i}\\right)\\right|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddecf6a0",
   "metadata": {},
   "source": [
    "## 3、实验环境\n",
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=MindSpore 2.0；Python环境=3.7\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU CUDA 10.1|Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134ff345",
   "metadata": {},
   "source": [
    "## 4、数据处理\n",
    "\n",
    "### 4.1数据准备\n",
    "\n",
    "   在本次实验中，我们使用numpy从均匀分布中随机生成测试数据x，从正态分布中随机生成噪声加入因变量y。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc2ecf1",
   "metadata": {},
   "source": [
    "### 4.2数据加载\n",
    "使用GeneratorDataset，通过迭代列表构造数据集，指定生成数据集的列名为data和lable,使用batch函数指定每个批处理数据包含的数据条目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2db70731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([3.5930421], dtype=float32), array([10.325392], dtype=float32)),\n",
       " (array([7.132953], dtype=float32), array([17.879877], dtype=float32)),\n",
       " (array([5.614383], dtype=float32), array([15.581945], dtype=float32)),\n",
       " (array([-8.709806], dtype=float32), array([-13.120221], dtype=float32)),\n",
       " (array([-1.4440981], dtype=float32), array([0.6155094], dtype=float32))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mindspore import dataset as ds\n",
    "def get_data(num, w=2.0, b=3.0):\n",
    "    #生成数据及对应标签\n",
    "    for _ in range(num):#num=160,生成160个样本点\n",
    "        x = np.random.uniform(-10.0, 10.0)# 生成服从(-10.0, 10.0)范围内的均匀分布的元素，返回值的元素类型为浮点型。\n",
    "        noise = np.random.normal(0, 1)#随机产生一个服从正态分布(0,1)的数值\n",
    "        y = x * w + b + noise#增加噪音生成y\n",
    "        yield np.array([x]).astype(np.float32), np.array([y]).astype(np.float32)#将数组元素类型转换为float32位;\n",
    "        #我们为了提高效率，并不一次性返回所有数据，而是采用迭代器形式返回单一数据。\n",
    "\n",
    "def create_dataset(num_data, batch_size=16):\n",
    "    #加载数据集eval_data=list(get_data(5))\n",
    "    train_data=list(get_data(num_data))\n",
    "    dataset = ds.GeneratorDataset(train_data, column_names=['data', 'label'])\n",
    "    dataset = dataset.batch(batch_size) #设置数据批次\n",
    "    return dataset        \n",
    "#可视化生成的数据\n",
    "eval_data=list(get_data(5))\n",
    "x,y=zip(*eval_data)#zip()函数迭代eval_data，将eval_data中的元素打包成一个个元组，然后返回由这些元组组成的列表。\n",
    "eval_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4840d74",
   "metadata": {},
   "source": [
    "## 5、模型构建\n",
    "\n",
    "### 5.1内置损失函数\n",
    "下面介绍 mindspore. $\\mathrm{nn}$ 模块中内置的损失函数L1损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ba89f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.33333334\n",
      "loss_sum: 2.0\n",
      "loss_none:\n",
      " [1. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 1.内置损失函数\n",
    "import mindspore.nn as nn\n",
    "import mindspore as ms\n",
    "\n",
    "# 输出loss均值\n",
    "loss = nn.L1Loss()\n",
    "# 输出loss和\n",
    "loss_sum = nn.L1Loss(reduction='sum')\n",
    "# 输出loss原值\n",
    "loss_none = nn.L1Loss(reduction='none')\n",
    "\n",
    "input_data = ms.Tensor(np.array([1, 0, 1, 0, 1, 0]).astype(np.float32))\n",
    "target_data = ms.Tensor(np.array([0, 0, 1, 1, 1, 0]).astype(np.float32))\n",
    "\n",
    "print(\"loss:\", loss(input_data, target_data))\n",
    "print(\"loss_sum:\", loss_sum(input_data, target_data))\n",
    "print(\"loss_none:\\n\", loss_none(input_data, target_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861f25e",
   "metadata": {},
   "source": [
    "### 5.2基于nn.Cell构造损失函数\n",
    "\n",
    "nn.Cell 是MindSpore的基类，不但可用于构建网络，还可用于定义损失函数。使用 $n n$.Cell定义损失函数的过程与定义一个普通的网络相似，差别在于，其执行逻辑部分要计算的是前向网络输出与真实值之间的误差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47e762fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33333334\n"
     ]
    }
   ],
   "source": [
    "# 2.基于nn.Cell构造损失函数\n",
    "import mindspore.ops as ops\n",
    "\n",
    "class MAELoss(nn.Cell):\n",
    "    #自定义损失函数MAELoss\n",
    "\n",
    "    def __init__(self):\n",
    "        #初始化\n",
    "        super(MAELoss, self).__init__()\n",
    "        self.abs = ops.Abs()\n",
    "        self.reduce_mean = ops.ReduceMean()\n",
    "\n",
    "    def construct(self, base, target):\n",
    "        #调用算子\n",
    "        x = self.abs(base - target)\n",
    "        return self.reduce_mean(x)\n",
    "\n",
    "loss = MAELoss()\n",
    "\n",
    "input_data = ms.Tensor(np.array([1, 0, 1, 0, 1, 0]).astype(np.float32))  # 生成预测值\n",
    "target_data = ms.Tensor(np.array([0, 0, 1, 1, 1, 0]).astype(np.float32)) # 生成真实值\n",
    "\n",
    "output = loss(input_data, target_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35dcfb3",
   "metadata": {},
   "source": [
    "### 5.3基于nn.LossBase构造损失函数\n",
    "\n",
    "基于nn.LossBase构造损失函数MAELoss与基于nn.Cell构造损失函数的过程类似，都要重写__init__方法和construct方法。\n",
    "\n",
    "nn.LossBase可使用方法get_loss将reduction应用于损失计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "532ecadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33333334\n"
     ]
    }
   ],
   "source": [
    "# 基于nn.LossBase构造损失函数\n",
    "class MAELoss(nn.LossBase):\n",
    "    #自定义损失函数MAELoss\n",
    "\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        #初始化并求loss均值\n",
    "        super(MAELoss, self).__init__(reduction)\n",
    "        self.abs = ops.Abs()  # 求绝对值算子\n",
    "\n",
    "    def construct(self, base, target):\n",
    "        x = self.abs(base - target)\n",
    "        return self.get_loss(x)  # 返回loss均值\n",
    "\n",
    "loss = MAELoss()\n",
    "\n",
    "input_data = ms.Tensor(np.array([1, 0, 1, 0, 1, 0]).astype(np.float32))  # 生成预测值\n",
    "target_data = ms.Tensor(np.array([0, 0, 1, 1, 1, 0]).astype(np.float32))  # 生成真实值\n",
    "\n",
    "output = loss(input_data, target_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6a1464",
   "metadata": {},
   "source": [
    "## 6、模型构建\n",
    "\n",
    "损失函数MAELoss自定义完成后，可使用MindSpore的接口Model中train接口进行模型训练，构造Model时需传入前向网络、损失函数和优化器，Model会在内部将它们关联起来，生成一个可用于训练的网络模型。\n",
    "\n",
    "在Model中，前向网络和损失函数通过nn.WithLossCell关联起来，nn.WithLossCell支持两个输入，分别为data和label。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d78aa",
   "metadata": {},
   "source": [
    "使用最简单的线性函数模型：f(x)=wx+b；在定义任何网络块时，需要继承nn.Cell类，来实现一些模块的基本功能，在__init__中定义网络层的基本信息，在construct中定义传播过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca2c180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "from mindspore import dataset as ds\n",
    "from mindspore.common.initializer import Normal\n",
    "from mindspore.train import LossMonitor\n",
    "class LinearNet(nn.Cell):\n",
    "    #定义线性回归网络\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        # 定义一个线性层，同时初始化权重和偏置\n",
    "        self.fc = nn.Dense(1, 1, Normal(0.02), Normal(0.02))#初始化输入输出维度为1，w和b\n",
    "    def construct(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7c7457",
   "metadata": {},
   "source": [
    "## 7、模型训练\n",
    "生成num_data个数据点，实例化线性网络，选择MAELoss和Momentum优化器进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8d351dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(21220:2916,MainProcess):2023-04-20-17:09:57.945.377 [mindspore\\dataset\\engine\\datasets_user_defined.py:657] Python multiprocessing is not supported on Windows platform.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = create_dataset(num_data=160)\n",
    "ds_train.get_dataset_size()\n",
    "#print('数据集批次：',ds_train.get_dataset_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3547ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将之前定义的网络实例化\n",
    "net = LinearNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16876046",
   "metadata": {},
   "outputs": [],
   "source": [
    "#因为是回归，所以我们选择MSE均方误差来计算损失\n",
    "loss = MAELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f8e71",
   "metadata": {},
   "source": [
    "反向传播网络的目标就是要不断的进行更新其权重，来达到拟合我们的样本数据，从而使得我们的loss达到最小值，所以使用梯度下降的方式进行更新其权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73b07ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1, loss is 9.935867309570312\n",
      "epoch: 1 step: 2, loss is 7.916937828063965\n",
      "epoch: 1 step: 3, loss is 9.898558616638184\n",
      "epoch: 1 step: 4, loss is 6.957692623138428\n",
      "epoch: 1 step: 5, loss is 7.872587203979492\n",
      "epoch: 1 step: 6, loss is 6.1877264976501465\n",
      "epoch: 1 step: 7, loss is 7.800919055938721\n",
      "epoch: 1 step: 8, loss is 10.210296630859375\n",
      "epoch: 1 step: 9, loss is 6.097762107849121\n",
      "epoch: 1 step: 10, loss is 7.093074321746826\n"
     ]
    }
   ],
   "source": [
    "#这里使用Momentum优化器,传入训练参数以及学习率\n",
    "opt = nn.Momentum(net.trainable_params(), learning_rate=0.005, momentum=0.9)\n",
    "# 使用model接口将网络、损失函数和优化器关联起来\n",
    "model = ms.Model(net, loss, opt)\n",
    "model.train(epoch=1, train_dataset=ds_train, callbacks=[LossMonitor(1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
