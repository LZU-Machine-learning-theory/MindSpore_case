{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb185f4c",
   "metadata": {},
   "source": [
    "#  基于MindSpore实现LSTM算法 \n",
    "本实验基于MindSpore构建LSTM模型，输出模型的预测结果和状态信息的形状。\n",
    "## 1 实验目的\n",
    "1.通过实验了解LSTM算法\n",
    "\n",
    "2.基于MindSpore中实现LSTM算法\n",
    "## 2 LSTM算法原理介绍\n",
    "LSTM四个函数层与具体介绍如下：\n",
    "\n",
    "(1)第一个函数层：遗忘门\n",
    "    ![jupyter](./Figures/fig001.png)\n",
    " \n",
    "对于上一时刻LSTM中的单元状态，一些信息可能会随着时间的流逝而过时。为了不让过多记忆影响神经网络对现在输入的处理，我们应该选择性遗忘一些在之前单元状态中的分量——这个工作就交给了遗忘门。\n",
    "\n",
    "每一次输入一个新的输入，LSTM会先根据新的输入和上一时刻的输出决定遗忘之前的哪些记忆——输入和上一步的输出会整合为一个单独的向量，然后通过sigmoid神经层，最后点对点的乘在单元状态上。因为sigmoid 函数会将任意输入压缩到 (0,1) 的区间上，我们可以非常直觉的得出这个门的工作原理 —— 如果整合后的向量某个分量在通过sigmoid层后变为0，那么显然单元状态在对位相乘后对应的分量也会变成0，换句话说，遗忘了这个分量上的信息；如果某个分量通过sigmoid层后为1，单元状态会“保持完整记忆”。不同的sigmoid输出会带来不同信息的记忆与遗忘。通过这种方式，LSTM可以长期记忆重要信息，并且记忆可以随着输入进行动态调整。下面的公式可以用来描述遗忘门的计算，其中f_t就是sigmoid神经层的输出向量：\n",
    "\n",
    "$f_t=σ(W_f∙[h_(t-1),x_t ]+b_f)$\n",
    "\n",
    "（2）第二个、第三个函数层：记忆门\n",
    "记忆门是用来控制是否将在t时刻（现在）的数据并入单元状态中的控制单位。首先，用tanh函数层将现在的向量中的有效信息提取出来，然后使用sigmoid函数来控制这些记忆要放多少进入单元状态。这两者结合起来就可以做到：\n",
    "\n",
    " ![jupyter](./Figures/fig002.png)\n",
    " \n",
    "从当前输入中提取有效信息；对提取的有效信息做出筛选，为每个分量做出评级(0 ~ 1)，评级越高的最后会有越多的记忆进入单元状态。下面的公式可以分别表示这两个步骤在LSTM中的计算：\n",
    "\n",
    "$C_{t}^{'}=tanh⁡(W_c∙[h_{(t-1)},x_t ]+b_c)$\n",
    "\n",
    "$i_t=σ(W_i∙[h_{(t-1)},x_t ]+b_i)$\n",
    "\n",
    "（3）第四个函数层：输出门\n",
    "\n",
    "输出门就是LSTM单元用于计算当前时刻的输出值的神经层。输出层会先将当前输入值与上一时刻输出值整合后的向量用sigmoid函数提取其中的信息，然后，会将当前的单元状态通过tanh函数压缩映射到区间(-1, 1)中，将经过tanh函数处理后的单元状态与sigmoid函数处理后的单元状态，整合后的向量点对点的乘起来就可以得到LSTM在 t时刻的输出。\n",
    "\n",
    "LSTM模型是由时刻的输入词$X_{t}$ ，细胞状态$C_{t}$，临时细胞状态$\\widetilde{C_{t}} $，隐层状态$h_{t}$，遗忘门$f_{t}$，记忆门$i_{t}$，输出门$ o_{t}$组成。LSTM的计算过程可以概括为:通过对细胞状态中信息遗忘和记忆新的信息使得对后续时刻计算有用的信息得以传递，而无用的信息被丢弃，并在每个时间步都会输出隐层状态$h_{t}$ ，其中遗忘、记忆与输出由通过上个时刻的隐层状态$h_{t-1}$和当前输入$X_{t}$计算出来的遗忘门$f_{t}$，记忆门$ i_{t}$，输出门$o_{t}$来控制。\n",
    "\n",
    "LSTM总体框架图如下：\n",
    " ![jupyter](./Figures/fig003.png)\n",
    "\n",
    "\n",
    "## 3 实验环境\n",
    "### 实验环境要求\n",
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=MindSpore 2.0；Python环境=3.7\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU CUDA 10.1|Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93cec1d",
   "metadata": {},
   "source": [
    "## 4 数据处理\n",
    "IMDB是一个与国内豆瓣比较类似的与电影相关的网站，而本次实验用到的数据集是这个网站中的一些用户评论。IMDB数据集共包含50000项影评文字，训练数据和测试数据各25000项，每一项影评文字都被标记为正面评价或负面评价，所以本实验可以看做一个二分类问题。IMDB数据集官网：[Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/)。\n",
    "\n",
    "方式一，从斯坦福大学官网下载aclImdb_v1.tar.gz并解压。\n",
    "\n",
    "方式二，从华为云OBS中下载aclImdb_v1.tar.gz并解压。\n",
    "\n",
    "同时，我们要下载GloVe文件，并在文件glove.6B.300d.txt开头处添加新的一行400000 300，即总共读取400000个单词，每个单词用300维度的词向量表示。 修改glove.6B.300.txt如下:\n",
    "\n",
    "400000 300\n",
    "\n",
    "the -0.071549 0.093459 0.023738 -0.090339 0.056123 0.32547…\n",
    "\n",
    "确定评价标准：\n",
    "作为典型的分类问题，情感分类的评价标准可以比照普通的分类问题处理。常见的精度（Accuracy）、精准度（Precision）、召回率（Recall）和F_beta分数都可以作为参考。\n",
    "\n",
    "精度（Accuracy）=分类正确的样本数目/总样本数目\n",
    "\n",
    "精准度（Precision）=真阳性样本数目/所有预测类别为阳性的样本数目\n",
    "\n",
    "召回率（Recall）=真阳性样本数目/所有真实类别为阳性的样本数目\n",
    "\n",
    "F1分数=(2∗Precision∗Recall)/(Precision+Recall)\n",
    "\n",
    "在IMDB这个数据集中，正负样本数差别不大，可以简单地用精度（accuracy）作为分类器的衡量标准。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adebf4af",
   "metadata": {},
   "source": [
    "## 5 模型构建\n",
    "（1）导入Python库&模块并配置运行信息\n",
    "\n",
    "导入MindSpore模块和辅助模块，设置MindSpore上下文，如执行模式、设备等。\n",
    "\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c2fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入MindSpore中的nn模块\n",
    "import mindspore.nn as nn\n",
    "import os\n",
    "import mindspore.common.dtype as mstype\n",
    "from mindspore import dataset as ds\n",
    "import math\n",
    "from mindspore import Parameter\n",
    "from mindspore import ParameterTuple\n",
    "from mindspore import Tensor\n",
    "import gensim\n",
    "from itertools import chain\n",
    "from mindspore.common.initializer import initializer\n",
    "import numpy as np\n",
    "#导入MindSpore中的ops模块\n",
    "import mindspore.ops as ops\n",
    "#导入MindSpore中ops模块的operations类\n",
    "from mindspore.ops import operations as P\n",
    "#导入MindSpore中的Model\n",
    "from mindspore.train import Model\n",
    "#配置当前执行环境\n",
    "from mindspore import context\n",
    "from mindspore.train import Accuracy\n",
    "from mindspore import Tensor, nn, context\n",
    "from mindspore.train import LossMonitor, CheckpointConfig, ModelCheckpoint, TimeMonitor\n",
    "from mindspore import load_param_into_net, load_checkpoint\n",
    "from mindspore.mindrecord import FileWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f3a2af",
   "metadata": {},
   "source": [
    "（2）定义参数变量\n",
    "\n",
    "device_target：指定Ascend或CPU/GPU环境。\n",
    "pre_trained：预加载CheckPoint文件。\n",
    "preprocess：是否预处理数据集，默认为否。\n",
    "aclimdb_path：数据集存放路径。\n",
    "glove_path：GloVe文件存放路径。\n",
    "preprocess_path：预处理数据集的结果文件夹。\n",
    "ckpt_path：CheckPoint文件路径。\n",
    "train_url：预处理数据集拷贝出来的存放路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49364df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用EasyDict库创建LSTM的配置文件\n",
    "from easydict import EasyDict\n",
    "# as edict\n",
    "# LSTM CONFIG LSTM的配置项\n",
    "lstm_cfg = EasyDict({\n",
    "    'num_classes': 2,\n",
    "    'learning_rate': 0.1,\n",
    "    'momentum': 0.9,\n",
    "    'num_epochs': 20,   \n",
    "    'batch_size': 64,\n",
    "    'embed_size': 300,\n",
    "    'num_hiddens': 100,\n",
    "    'num_layers': 2,\n",
    "    'bidirectional': True,\n",
    "    'save_checkpoint_steps': 390,\n",
    "    'keep_checkpoint_max': 10,\n",
    "    'vocab_size':6,\n",
    "})\n",
    "#训练参数\n",
    "args_train = EasyDict({\n",
    "    'preprocess': 'true',\n",
    "    'aclimdb_path': \"./aclImdb\",\n",
    "    'glove_path':\"./glove\",\n",
    "    'preprocess_path': \"./preprocessed\",\n",
    "    'ckpt_path': \"./\",\n",
    "    'pre_trained': None,\n",
    "    'device_target': \"CPU\",\n",
    "})\n",
    "#测试参数\n",
    "args_test =EasyDict({\n",
    "    'preprocess': 'false',\n",
    "    'aclimdb_path': \"./aclImdb\",\n",
    "    'glove_path':  \"./glove\",\n",
    "    'preprocess_path':\"./preprocessed\",\n",
    "    'ckpt_path': \"./lstm-20_390.ckpt\",\n",
    "    'pre_trained': None,\n",
    "    'device_target':  \"CPU\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc623df",
   "metadata": {},
   "source": [
    "（3）数据的读取与处理\n",
    "\n",
    "对文本数据集进行处理，包括编码、分词、对齐、处理GloVe原始数据，使之能够适应网络结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd9fe49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbParser():\n",
    "    \"\"\"\n",
    "    parse aclImdb data to features and labels.\n",
    "    sentence->tokenized->encoded->padding->features\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, imdb_path, glove_path, embed_size=300):\n",
    "        self.__segs = ['train', 'test']\n",
    "        self.__label_dic = {'pos': 1, 'neg': 0}\n",
    "        self.__imdb_path = imdb_path\n",
    "        #self.__glove_dim = embed_size\n",
    "        self.__glove_dim = 300\n",
    "        self.__glove_file = os.path.join(glove_path, 'glove.6B.' + str(self.__glove_dim) + 'd.txt')\n",
    "\n",
    "        # properties\n",
    "        self.__imdb_datas = {}\n",
    "        self.__features = {}\n",
    "        self.__labels = {}\n",
    "        self.__vacab = {}\n",
    "        self.__word2idx = {}\n",
    "        self.__weight_np = {}\n",
    "        self.__wvmodel = None\n",
    "\n",
    "    def parse(self):\n",
    "        \"\"\"\n",
    "        parse imdb data to memory\n",
    "        \"\"\"\n",
    "        self.__wvmodel = gensim.models.KeyedVectors.load_word2vec_format(self.__glove_file)\n",
    "\n",
    "        for seg in self.__segs:\n",
    "            self.__parse_imdb_datas(seg)\n",
    "            self.__parse_features_and_labels(seg)\n",
    "            self.__gen_weight_np(seg)\n",
    "\n",
    "    def __parse_imdb_datas(self, seg):\n",
    "        \"\"\"\n",
    "        load data from txt\n",
    "        \"\"\"\n",
    "        data_lists = []\n",
    "        for label_name, label_id in self.__label_dic.items():\n",
    "            sentence_dir = os.path.join(self.__imdb_path, seg, label_name)\n",
    "            for file in os.listdir(sentence_dir):\n",
    "                with open(os.path.join(sentence_dir, file), mode='r', encoding='utf8') as f:\n",
    "                    sentence = f.read().replace('\\n', '')\n",
    "                    data_lists.append([sentence, label_id])\n",
    "        self.__imdb_datas[seg] = data_lists\n",
    "\n",
    "    def __parse_features_and_labels(self, seg):\n",
    "        \"\"\"\n",
    "        parse features and labels\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        labels = []\n",
    "        for sentence, label in self.__imdb_datas[seg]:\n",
    "            features.append(sentence)\n",
    "            labels.append(label)\n",
    "\n",
    "        self.__features[seg] = features\n",
    "        self.__labels[seg] = labels\n",
    "\n",
    "        # update feature to tokenized\n",
    "        self.__updata_features_to_tokenized(seg)\n",
    "        # parse vacab\n",
    "        self.__parse_vacab(seg)\n",
    "        # encode feature\n",
    "        self.__encode_features(seg)\n",
    "        # padding feature\n",
    "        self.__padding_features(seg)\n",
    "\n",
    "    def __updata_features_to_tokenized(self, seg):\n",
    "        tokenized_features = []\n",
    "        for sentence in self.__features[seg]:\n",
    "            tokenized_sentence = [word.lower() for word in sentence.split(\" \")]\n",
    "            tokenized_features.append(tokenized_sentence)\n",
    "        self.__features[seg] = tokenized_features\n",
    "\n",
    "    def __parse_vacab(self, seg):\n",
    "        # vocab\n",
    "        tokenized_features = self.__features[seg]\n",
    "        vocab = set(chain(*tokenized_features))\n",
    "        self.__vacab[seg] = vocab\n",
    "\n",
    "        word_to_idx = {word: i + 1 for i, word in enumerate(vocab)}\n",
    "        word_to_idx['<unk>'] = 0\n",
    "        self.__word2idx[seg] = word_to_idx\n",
    "\n",
    "    def __encode_features(self, seg):\n",
    "        \"\"\" encode word to index \"\"\"\n",
    "        word_to_idx = self.__word2idx['train']\n",
    "        encoded_features = []\n",
    "        for tokenized_sentence in self.__features[seg]:\n",
    "            encoded_sentence = []\n",
    "            for word in tokenized_sentence:\n",
    "                encoded_sentence.append(word_to_idx.get(word, 0))\n",
    "            encoded_features.append(encoded_sentence)\n",
    "        self.__features[seg] = encoded_features\n",
    "\n",
    "    def __padding_features(self, seg, maxlen=500, pad=0):\n",
    "        \"\"\" pad all features to the same length \"\"\"\n",
    "        padded_features = []\n",
    "        for feature in self.__features[seg]:\n",
    "            if len(feature) >= maxlen:\n",
    "                padded_feature = feature[:maxlen]\n",
    "            else:\n",
    "                padded_feature = feature\n",
    "                while len(padded_feature) < maxlen:\n",
    "                    padded_feature.append(pad)\n",
    "            padded_features.append(padded_feature)\n",
    "        self.__features[seg] = padded_features\n",
    "\n",
    "    def __gen_weight_np(self, seg):\n",
    "        \"\"\"\n",
    "        generate weight by gensim\n",
    "        \"\"\"\n",
    "        weight_np = np.zeros((len(self.__word2idx[seg]), self.__glove_dim), dtype=np.float32)\n",
    "        for word, idx in self.__word2idx[seg].items():\n",
    "            if word not in self.__wvmodel:\n",
    "                continue\n",
    "            word_vector = self.__wvmodel.get_vector(word)\n",
    "            weight_np[idx, :] = word_vector\n",
    "\n",
    "        self.__weight_np[seg] = weight_np\n",
    "\n",
    "    def get_datas(self, seg):\n",
    "        \"\"\"\n",
    "        get features, labels, and weight by gensim.\n",
    "        \"\"\"\n",
    "        features = np.array(self.__features[seg]).astype(np.int32)\n",
    "        labels = np.array(self.__labels[seg]).astype(np.int32)\n",
    "        weight = np.array(self.__weight_np[seg])\n",
    "        return features, labels, weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d27f6",
   "metadata": {},
   "source": [
    "定义创建数据集函数lstm_create_dataset，创建训练集ds_train和验证集ds_eval。\n",
    "\n",
    "定义convert_to_mindrecord函数将数据集格式转换为MindRecord格式，便于MindSpore读取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83b2b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_create_dataset(data_home, batch_size, repeat_num=1, training=True):\n",
    "    \"\"\"Data operations.\"\"\"\n",
    "    ds.config.set_seed(1)\n",
    "    data_dir = os.path.join(data_home, \"aclImdb_train.mindrecord0\")\n",
    "    if not training:\n",
    "        data_dir = os.path.join(data_home, \"aclImdb_test.mindrecord0\")\n",
    "\n",
    "    data_set = ds.MindDataset(data_dir, columns_list=[\"feature\", \"label\"], num_parallel_workers=4)\n",
    "\n",
    "    # apply map operations on images\n",
    "    data_set = data_set.shuffle(buffer_size=data_set.get_dataset_size())\n",
    "    data_set = data_set.batch(batch_size=batch_size, drop_remainder=True)\n",
    "    data_set = data_set.repeat(count=repeat_num)\n",
    "\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272e1b52",
   "metadata": {},
   "source": [
    "函数_convert_to_mindrecord中weight.txt为数据预处理后自动生成的weight参数信息文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "300ac0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_to_mindrecord(data_home, features, labels, weight_np=None, training=True):\n",
    "    \"\"\"\n",
    "    convert imdb dataset to mindrecord dataset\n",
    "    \"\"\"\n",
    "    if weight_np is not None:\n",
    "        np.savetxt(os.path.join(data_home, 'weight.txt'), weight_np)\n",
    "\n",
    "    # write mindrecord\n",
    "    schema_json = {\"id\": {\"type\": \"int32\"},\n",
    "                   \"label\": {\"type\": \"int32\"},\n",
    "                   \"feature\": {\"type\": \"int32\", \"shape\": [-1]}}\n",
    "\n",
    "    data_dir = os.path.join(data_home, \"aclImdb_train.mindrecord\")\n",
    "    if not training:\n",
    "        data_dir = os.path.join(data_home, \"aclImdb_test.mindrecord\")\n",
    "\n",
    "    def get_imdb_data(features, labels):\n",
    "        data_list = []\n",
    "        for i, (label, feature) in enumerate(zip(labels, features)):\n",
    "            data_json = {\"id\": i,\n",
    "                         \"label\": int(label),\n",
    "                         \"feature\": feature.reshape(-1)}\n",
    "            data_list.append(data_json)\n",
    "        return data_list\n",
    "\n",
    "    writer = FileWriter(data_dir, shard_num=4)\n",
    "    data = get_imdb_data(features, labels)\n",
    "    writer.add_schema(schema_json, \"nlp_schema\")\n",
    "    writer.add_index([\"id\", \"label\"])\n",
    "    writer.write_raw_data(data)\n",
    "    writer.commit()\n",
    "\n",
    "\n",
    "def convert_to_mindrecord(embed_size, aclimdb_path, preprocess_path, glove_path):\n",
    "    \"\"\"\n",
    "    convert imdb dataset to mindrecord dataset\n",
    "    \"\"\"\n",
    "    parser = ImdbParser(aclimdb_path, glove_path, embed_size)\n",
    "    parser.parse()\n",
    "\n",
    "    if not os.path.exists(preprocess_path):\n",
    "        print(f\"preprocess path {preprocess_path} is not exist\")\n",
    "        os.makedirs(preprocess_path)\n",
    "\n",
    "    train_features, train_labels, train_weight_np = parser.get_datas('train')\n",
    "    _convert_to_mindrecord(preprocess_path, train_features, train_labels, train_weight_np)\n",
    "\n",
    "    test_features, test_labels, _ = parser.get_datas('test')\n",
    "    _convert_to_mindrecord(preprocess_path, test_features, test_labels, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b5643",
   "metadata": {},
   "source": [
    "(4)模型构建\n",
    "\n",
    "定义需要单层LSTM小算子堆叠的设备类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c798dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "STACK_LSTM_DEVICE = [\"CPU\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7145dd3",
   "metadata": {},
   "source": [
    "定义lstm_default_state函数来初始化网络参数及网络状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be5a890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_default_state(batch_size, hidden_size, num_layers, bidirectional):\n",
    "    \"\"\"init default input.\"\"\"\n",
    "    num_directions = 2 if bidirectional else 1\n",
    "    h = Tensor(np.zeros((num_layers * num_directions, batch_size, hidden_size)).astype(np.float32))\n",
    "    c = Tensor(np.zeros((num_layers * num_directions, batch_size, hidden_size)).astype(np.float32))\n",
    "    return h, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d6e14e",
   "metadata": {},
   "source": [
    "对于不同平台，定义stack_lstm_default_state函数来初始化小算子堆叠需要的初始化网络参数及网络状态。\n",
    "\n",
    "针对不同的场景，自定义单层LSTM小算子堆叠，来实现多层LSTM大算子功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ccebc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_lstm_default_state(batch_size, hidden_size, num_layers, bidirectional):\n",
    "    num_directions = 2 if bidirectional else 1\n",
    "    h_state = np.zeros((num_layers * num_directions, batch_size, hidden_size), dtype=np.float32)\n",
    "    c_state = np.zeros((num_layers * num_directions, batch_size, hidden_size), dtype=np.float32)\n",
    "    return Tensor(h_state, mstype.float32), Tensor(c_state, mstype.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3be72878",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackLSTM(nn.Cell):\n",
    "    \"\"\"\n",
    "    Stack multi-layers LSTM together.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 num_layers=1,\n",
    "                 has_bias=True,\n",
    "                 batch_first=False,\n",
    "                 dropout=0.0,\n",
    "                 bidirectional=False):\n",
    "        super(StackLSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.transpose = P.Transpose()\n",
    "\n",
    "        # direction number\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "\n",
    "        # input_size list\n",
    "        input_size_list = [input_size]\n",
    "        for i in range(num_layers - 1):\n",
    "            input_size_list.append(hidden_size * num_directions)\n",
    "\n",
    "        # layers\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layers.append(nn.LSTM(input_size=input_size_list[i],\n",
    "                                      hidden_size=hidden_size,\n",
    "                                      has_bias=has_bias,\n",
    "                                      batch_first=batch_first,\n",
    "                                      bidirectional=bidirectional,\n",
    "                                      dropout=dropout))\n",
    "\n",
    "        # weights\n",
    "        weights = []\n",
    "        for i in range(num_layers):\n",
    "            # weight size\n",
    "            weight_size = (input_size_list[i] + hidden_size) * num_directions * hidden_size * 4\n",
    "            if has_bias:\n",
    "                bias_size = num_directions * hidden_size * 4\n",
    "                weight_size = weight_size + bias_size\n",
    "\n",
    "            # numpy weight\n",
    "            stdv = 1 / math.sqrt(hidden_size)\n",
    "            w_np = np.random.uniform(-stdv, stdv, (weight_size, 1, 1)).astype(np.float32)\n",
    "\n",
    "            # lstm weight\n",
    "            weights.append(Parameter(initializer(Tensor(w_np), w_np.shape), name=\"weight\" + str(i)))\n",
    "\n",
    "        #\n",
    "        self.lstms = layers\n",
    "        self.weight = ParameterTuple(tuple(weights))\n",
    "\n",
    "    def construct(self, x, hx):\n",
    "        \"\"\"construct\"\"\"\n",
    "        if self.batch_first:\n",
    "            x = self.transpose(x, (1, 0, 2))\n",
    "        h, c = hx\n",
    "        hn = cn = None\n",
    "        for i in range(self.num_layers):\n",
    "            x, hn, cn, _, _ = self.lstms[i](x, h[i], c[i], self.weight[i])\n",
    "        if self.batch_first:\n",
    "            x = self.transpose(x, (1, 0, 2))\n",
    "        return x, (hn, cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f726660",
   "metadata": {},
   "source": [
    "使用cell方法，定义SentimentNet网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b159949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentNet(nn.Cell):\n",
    "    \"\"\"Sentiment network structure.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embed_size,\n",
    "                 num_hiddens,\n",
    "                 num_layers,\n",
    "                 bidirectional,\n",
    "                 num_classes,\n",
    "                 weight,\n",
    "                 batch_size):\n",
    "        super(SentimentNet, self).__init__()\n",
    "        # Mapp words to vectors\n",
    "        self.embedding = nn.Embedding(vocab_size,\n",
    "                                      embed_size,\n",
    "                                      embedding_table=weight)\n",
    "        self.embedding.embedding_table.requires_grad = False\n",
    "        self.trans = P.Transpose()\n",
    "        self.perm = (1, 0, 2)\n",
    "\n",
    "        if context.get_context(\"device_target\") in STACK_LSTM_DEVICE:\n",
    "            # stack lstm by user\n",
    "            self.encoder = StackLSTM(input_size=embed_size,\n",
    "                                     hidden_size=num_hiddens,\n",
    "                                     num_layers=num_layers,\n",
    "                                     has_bias=True,\n",
    "                                     bidirectional=bidirectional,\n",
    "                                     dropout=0.0)\n",
    "            self.h, self.c = stack_lstm_default_state(batch_size, num_hiddens, num_layers, bidirectional)\n",
    "        elif context.get_context(\"device_target\") == \"GPU\":\n",
    "            # standard lstm\n",
    "            self.encoder = nn.LSTM(input_size=embed_size,\n",
    "                                   hidden_size=num_hiddens,\n",
    "                                   num_layers=num_layers,\n",
    "                                   has_bias=True,\n",
    "                                   bidirectional=bidirectional,\n",
    "                                   dropout=0.0)\n",
    "            self.h, self.c = lstm_default_state(batch_size, num_hiddens, num_layers, bidirectional)\n",
    "        else:\n",
    "            self.encoder = StackLSTMAscend(input_size=embed_size,\n",
    "                                           hidden_size=num_hiddens,\n",
    "                                           num_layers=num_layers,\n",
    "                                           has_bias=True,\n",
    "                                           bidirectional=bidirectional)\n",
    "            self.h, self.c = stack_lstm_default_state_ascend(batch_size, num_hiddens, num_layers, bidirectional)\n",
    "\n",
    "        self.concat = P.Concat(1)\n",
    "        self.squeeze = P.Squeeze(axis=0)\n",
    "        if bidirectional:\n",
    "            self.decoder = nn.Dense(num_hiddens * 4, num_classes)\n",
    "        else:\n",
    "            self.decoder = nn.Dense(num_hiddens * 2, num_classes)\n",
    "\n",
    "    #def construct(self, inputs):\n",
    "        # input：(64,500,300)\n",
    "     #   embeddings = self.embedding(inputs)\n",
    "      #  embeddings = self.trans(embeddings, self.perm)\n",
    "       # output, _ = self.encoder(embeddings, (self.h, self.c))\n",
    "        # states[i] size(64,200)  -> encoding.size(64,400)\n",
    "        #encoding = self.concat((self.squeeze(output[0:1:1]), self.squeeze(output[499:500:1])))\n",
    "        #outputs = self.decoder(encoding)\n",
    "        #return outputs\n",
    "    def construct(self, inputs, h, c):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        outputs, (h, c) = self.lstm(embeddings, (h, c))\n",
    "        outputs = self.dropout(outputs)\n",
    "        output = self.fc(outputs[-1, :, :])  # Use the last time step's output for classification\n",
    "        return output\n",
    "    def init_hidden_state(self, batch_size):\n",
    "        h = Tensor(np.zeros((self.num_layers * (self.bidirectional + 1), batch_size, self.num_hiddens)).astype(np.float32))\n",
    "        c = Tensor(np.zeros((self.num_layers * (self.bidirectional + 1), batch_size, self.num_hiddens)).astype(np.float32))\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c61f6",
   "metadata": {},
   "source": [
    "调用convert_to_mindrecord函数执行数据集预处理。\n",
    "转换成功后会在preprocess目录下生成MindRecord文件，通常该操作在数据集不变的情况下，无需每次训练都执行。\n",
    "\n",
    "名称包含aclImdb_train.mindrecord的为转换后的MindRecord格式的训练数据集。\n",
    "名称包含aclImdb_test.mindrecord的为转换后的MindRecord格式的测试数据集。\n",
    "weight.txt为预处理后自动生成的weight参数信息文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c14b82f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Data Pre-processing ==============\n"
     ]
    }
   ],
   "source": [
    "#if args_train.device_target == 'Ascend':\n",
    " #   cfg = lstm_cfg_ascend\n",
    "#else:\n",
    "cfg = lstm_cfg\n",
    "if args_train.preprocess == \"true\":\n",
    "    print(\"============== Starting Data Pre-processing ==============\")\n",
    "    convert_to_mindrecord(cfg.embed_size, args_train.aclimdb_path, args_train.preprocess_path, args_train.glove_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f5eba",
   "metadata": {},
   "source": [
    "实例化SentimentNet，创建网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d0be0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = lstm_cfg\n",
    "embedding_table = np.loadtxt(os.path.join(args_train.preprocess_path, \"weight.txt\")).astype(np.float32)\n",
    "if args_train.device_target == 'Ascend':\n",
    "    pad_num = int(np.ceil(cfg.embed_size / 16) * 16 - cfg.embed_size)\n",
    "    if pad_num > 0:\n",
    "        embedding_table = np.pad(embedding_table, [(0, 0), (0, pad_num)], 'constant')\n",
    "    cfg.embed_size = int(np.ceil(cfg.embed_size / 16) * 16)\n",
    "cfg.embed_size = 300 \n",
    "network = SentimentNet(vocab_size=embedding_table.shape[0],\n",
    "                        embed_size=cfg.embed_size,\n",
    "                        num_hiddens=cfg.num_hiddens,\n",
    "                        num_layers=cfg.num_layers,\n",
    "                        bidirectional=cfg.bidirectional,\n",
    "                        num_classes=cfg.num_classes,\n",
    "                        weight=Tensor(embedding_table),\n",
    "                        batch_size=cfg.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15551c3",
   "metadata": {},
   "source": [
    "## 6 模型训练\n",
    "根据建立的LSTM模型，对模型进行训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efe7b354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Training ==============\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "construct() missing 2 required positional arguments: 'h' and 'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8552\\1633848831.py\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mtime_cb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeMonitor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dataset_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0margs_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_target\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"CPU\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtime_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpoint_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_sink_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtime_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpoint_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mindspore\\train\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epoch, train_dataset, callbacks, dataset_sink_mode, sink_size, initial_epoch)\u001b[0m\n\u001b[0;32m   1054\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_methods_for_custom_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m         self._train(epoch,\n\u001b[0m\u001b[0;32m   1057\u001b[0m                     \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mindspore\\train\\model.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mindspore\\train\\model.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, epoch, train_dataset, callbacks, dataset_sink_mode, sink_size, initial_epoch, valid_dataset, valid_frequency, valid_dataset_sink_mode)\u001b[0m\n\u001b[0;32m    608\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_reuse_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdataset_sink_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcb_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_infos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"device_target\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"CPU\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m                 logger.info(\"The CPU cannot support dataset sink mode currently.\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mindspore\\train\\model.py\u001b[0m in \u001b[0;36m_train_process\u001b[1;34m(self, epoch, train_dataset, list_callback, cb_params, initial_epoch, valid_infos)\u001b[0m\n\u001b[0;32m    907\u001b[0m                 \u001b[0mlist_callback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_step_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_network_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_network\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[0mcb_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss_scale_manager\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss_scale_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_drop_overflow_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mindspore\\nn\\cell.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m             \u001b[0m_pynative_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_res\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 660\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mindspore\\nn\\cell.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[0m_pynative_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 656\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_construct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    657\u001b[0m             \u001b[0m_pynative_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mindspore\\nn\\cell.py\u001b[0m in \u001b[0;36m_run_construct\u001b[1;34m(self, cast_inputs, kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shard_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enable_forward_hook\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_forward_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mindspore\\nn\\wrap\\cell_wrapper.py\u001b[0m in \u001b[0;36mconstruct\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[0msens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mindspore\\nn\\cell.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m             \u001b[0m_pynative_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_res\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 660\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mindspore\\nn\\cell.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[0m_pynative_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 656\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_construct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    657\u001b[0m             \u001b[0m_pynative_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mindspore\\nn\\cell.py\u001b[0m in \u001b[0;36m_run_construct\u001b[1;34m(self, cast_inputs, kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shard_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enable_forward_hook\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_forward_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mindspore\\nn\\wrap\\cell_wrapper.py\u001b[0m in \u001b[0;36mconstruct\u001b[1;34m(self, data, label)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backbone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mindspore\\nn\\cell.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m             \u001b[0m_pynative_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_res\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 660\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mindspore\\nn\\cell.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[0m_pynative_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 656\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_construct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    657\u001b[0m             \u001b[0m_pynative_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mindspore\\nn\\cell.py\u001b[0m in \u001b[0;36m_run_construct\u001b[1;34m(self, cast_inputs, kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shard_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enable_forward_hook\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_forward_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: construct() missing 2 required positional arguments: 'h' and 'c'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "steps_per_epoch=5\n",
    "def get_lr(global_step, lr_init, lr_end, lr_max, warmup_epochs, total_epochs):\n",
    "    warmup_steps = warmup_epochs * steps_per_epoch \n",
    "    total_steps = total_epochs * steps_per_epoch  \n",
    "    lr_each_step = []\n",
    "    for i in range(total_steps):\n",
    "        if i < warmup_steps:\n",
    "            lr = (lr_max - lr_init) / warmup_steps * i + lr_init  \n",
    "        else:\n",
    "            lr = lr_max - (lr_max - lr_end) * (i - warmup_steps) / (total_steps - warmup_steps)  # 学习率衰减\n",
    "        lr_each_step.append(lr)\n",
    "    current_step = global_step - 1\n",
    "    lr = lr_each_step[current_step]\n",
    "    return lr\n",
    "if args_train.pre_trained:\n",
    "    load_param_into_net(network, load_checkpoint(args_train.pre_trained))\n",
    "ds_train = lstm_create_dataset(args_train.preprocess_path, cfg.batch_size, 1)\n",
    "loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "cfg.dynamic_lr=True\n",
    "if cfg.dynamic_lr:\n",
    "    lr = Tensor(get_lr(global_step=5,lr_init=0.001, lr_end=0.01, lr_max=0.1,warmup_epochs=5,\n",
    "                        total_epochs=5))\n",
    "else:\n",
    "    lr = cfg.learning_rate\n",
    "opt = nn.Momentum(network.trainable_params(), lr, cfg.momentum)\n",
    "loss_cb = LossMonitor()\n",
    "model = Model(network, loss, opt, {'acc': Accuracy()})\n",
    "print(\"============== Starting Training ==============\")\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps,\n",
    "                                 keep_checkpoint_max=cfg.keep_checkpoint_max)\n",
    "ckpoint_cb = ModelCheckpoint(prefix=\"lstm\", directory=args_train.ckpt_path, config=config_ck)\n",
    "time_cb = TimeMonitor(data_size=ds_train.get_dataset_size())\n",
    "if args_train.device_target == \"CPU\":\n",
    "    model.train(cfg.num_epochs, ds_train, callbacks=[time_cb, ckpoint_cb, loss_cb], dataset_sink_mode=False)\n",
    "else:\n",
    "    model.train(cfg.num_epochs, ds_train, callbacks=[time_cb, ckpoint_cb, loss_cb])\n",
    "print(\"============== Training Success ==============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f63fd75",
   "metadata": {},
   "source": [
    "## 7 模型测试\n",
    "根据处理后的测试数据以及建立的LSTM模型，对模型进行测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b9c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_eval = lstm_create_dataset(args_test.preprocess_path, cfg.batch_size, training=False)\n",
    "print(\"============== Starting Testing ==============\")\n",
    "param_dict = load_checkpoint('lstm-20_390.ckpt')\n",
    "load_param_into_net(network, param_dict)\n",
    "if args_test.device_target == \"CPU\":\n",
    "    acc = model.eval(ds_eval, dataset_sink_mode=False)\n",
    "else:\n",
    "    acc = model.eval(ds_eval)\n",
    "print(\"============== {} ==============\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c88331",
   "metadata": {},
   "source": [
    "## 8 实验总结\n",
    "本实验介绍了LSTM算法的原理，并按照步骤基于MindSpore实现了LSTM算法，并包含了对模型的测试部分，用于验证模型在随机输入数据上的预测结果和状态信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dc2aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
