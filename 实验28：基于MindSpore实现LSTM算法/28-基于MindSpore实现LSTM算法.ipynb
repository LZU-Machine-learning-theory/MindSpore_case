{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  基于MindSpore实现LSTM算法 \n",
    "本实验基于MindSpore构建LSTM模型，使用SentimentNet实现情感分类,并训练和测试模型。\n",
    "## 1 实验目的\n",
    "1.通过实验了解LSTM算法\n",
    "\n",
    "2.基于MindSpore中实现LSTM算法\n",
    "## 2 LSTM算法原理介绍\n",
    "LSTM四个函数层与具体介绍如下：\n",
    "\n",
    "(1)第一个函数层：遗忘门\n",
    "    ![jupyter](./Figures/fig001.png)\n",
    " \n",
    "对于上一时刻LSTM中的单元状态，一些信息可能会随着时间的流逝而过时。为了不让过多记忆影响神经网络对现在输入的处理，我们应该选择性遗忘一些在之前单元状态中的分量——这个工作就交给了遗忘门。\n",
    "\n",
    "每一次输入一个新的输入，LSTM会先根据新的输入和上一时刻的输出决定遗忘之前的哪些记忆——输入和上一步的输出会整合为一个单独的向量，然后通过sigmoid神经层，最后点对点的乘在单元状态上。因为sigmoid 函数会将任意输入压缩到 (0,1) 的区间上，我们可以非常直觉的得出这个门的工作原理 —— 如果整合后的向量某个分量在通过sigmoid层后变为0，那么显然单元状态在对位相乘后对应的分量也会变成0，换句话说，遗忘了这个分量上的信息；如果某个分量通过sigmoid层后为1，单元状态会“保持完整记忆”。不同的sigmoid输出会带来不同信息的记忆与遗忘。通过这种方式，LSTM可以长期记忆重要信息，并且记忆可以随着输入进行动态调整。下面的公式可以用来描述遗忘门的计算，其中f_t就是sigmoid神经层的输出向量：\n",
    "\n",
    "$f_t=σ(W_f∙[h_(t-1),x_t ]+b_f)$\n",
    "\n",
    "（2）第二个、第三个函数层：记忆门\n",
    "记忆门是用来控制是否将在t时刻（现在）的数据并入单元状态中的控制单位。首先，用tanh函数层将现在的向量中的有效信息提取出来，然后使用sigmoid函数来控制这些记忆要放多少进入单元状态。这两者结合起来就可以做到：\n",
    "\n",
    " ![jupyter](./Figures/fig002.png)\n",
    " \n",
    "从当前输入中提取有效信息；对提取的有效信息做出筛选，为每个分量做出评级(0 ~ 1)，评级越高的最后会有越多的记忆进入单元状态。下面的公式可以分别表示这两个步骤在LSTM中的计算：\n",
    "\n",
    "$C_{t}^{'}=tanh⁡(W_c∙[h_{(t-1)},x_t ]+b_c)$\n",
    "\n",
    "$i_t=σ(W_i∙[h_{(t-1)},x_t ]+b_i)$\n",
    "\n",
    "（3）第四个函数层：输出门\n",
    "\n",
    "输出门就是LSTM单元用于计算当前时刻的输出值的神经层。输出层会先将当前输入值与上一时刻输出值整合后的向量用sigmoid函数提取其中的信息，然后，会将当前的单元状态通过tanh函数压缩映射到区间(-1, 1)中，将经过tanh函数处理后的单元状态与sigmoid函数处理后的单元状态，整合后的向量点对点的乘起来就可以得到LSTM在 t时刻的输出。\n",
    "\n",
    "LSTM模型是由时刻的输入词$X_{t}$ ，细胞状态$C_{t}$，临时细胞状态$\\widetilde{C_{t}} $，隐层状态$h_{t}$，遗忘门$f_{t}$，记忆门$i_{t}$，输出门$ o_{t}$组成。LSTM的计算过程可以概括为:通过对细胞状态中信息遗忘和记忆新的信息使得对后续时刻计算有用的信息得以传递，而无用的信息被丢弃，并在每个时间步都会输出隐层状态$h_{t}$ ，其中遗忘、记忆与输出由通过上个时刻的隐层状态$h_{t-1}$和当前输入$X_{t}$计算出来的遗忘门$f_{t}$，记忆门$ i_{t}$，输出门$o_{t}$来控制。\n",
    "\n",
    "LSTM总体框架图如下：\n",
    " ![jupyter](./Figures/fig003.png)\n",
    "\n",
    "\n",
    "## 3 实验环境\n",
    "### 实验环境要求\n",
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=MindSpore 2.0；Python环境=3.7\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU CUDA 10.1|Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|\n",
    "## 4 数据处理\n",
    "IMDB是一个与国内豆瓣比较类似的与电影相关的网站，而本次实验用到的数据集是这个网站中的一些用户评论。IMDB数据集共包含50000项影评文字，训练数据和测试数据各25000项，每一项影评文字都被标记为正面评价或负面评价，所以本实验可以看做一个二分类问题。IMDB数据集官网：[Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/)。\n",
    "\n",
    "方式一，从斯坦福大学官网下载aclImdb_v1.tar.gz并解压。\n",
    "\n",
    "方式二，从华为云OBS中下载aclImdb_v1.tar.gz并解压。\n",
    "\n",
    "同时，我们要下载GloVe文件，并在文件glove.6B.300d.txt开头处添加新的一行400000 300，即总共读取400000个单词，每个单词用300维度的词向量表示。 修改glove.6B.300.txt如下:\n",
    "\n",
    "400000 300\n",
    "\n",
    "the -0.071549 0.093459 0.023738 -0.090339 0.056123 0.32547…\n",
    "\n",
    "确定评价标准：\n",
    "作为典型的分类问题，情感分类的评价标准可以比照普通的分类问题处理。常见的精度（Accuracy）、精准度（Precision）、召回率（Recall）和F_beta分数都可以作为参考。\n",
    "\n",
    "精度（Accuracy）=分类正确的样本数目/总样本数目\n",
    "\n",
    "精准度（Precision）=真阳性样本数目/所有预测类别为阳性的样本数目\n",
    "\n",
    "召回率（Recall）=真阳性样本数目/所有真实类别为阳性的样本数目\n",
    "\n",
    "F1分数=(2∗Precision∗Recall)/(Precision+Recall)\n",
    "\n",
    "在IMDB这个数据集中，正负样本数差别不大，可以简单地用精度（accuracy）作为分类器的衡量标准。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 模型构建\n",
    "（1）导入Python库&模块并配置运行信息\n",
    "\n",
    "导入MindSpore模块和辅助模块。\n",
    "\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入mindspore模块和辅助模块\n",
    "import argparse\n",
    "from mindspore import context\n",
    "from easydict import EasyDict as edict\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import gensim\n",
    "from mindspore.mindrecord import FileWriter\n",
    "import os\n",
    "import mindspore.dataset as ds\n",
    "import math\n",
    "from mindspore import Tensor, nn, context, Parameter, ParameterTuple\n",
    "from mindspore.common.initializer import initializer\n",
    "import mindspore.ops as ops\n",
    "from mindspore.train import Model,CheckpointConfig, ModelCheckpoint, TimeMonitor, LossMonitor,Accuracy\n",
    "from mindspore import nn\n",
    "from mindspore import load_checkpoint, load_param_into_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2）定义参数变量\n",
    "\n",
    "device_target：指定Ascend或CPU/GPU环境。\n",
    "pre_trained：预加载CheckPoint文件。\n",
    "preprocess：是否预处理数据集，默认为否。\n",
    "aclimdb_path：数据集存放路径。\n",
    "glove_path：GloVe文件存放路径。\n",
    "preprocess_path：预处理数据集的结果文件夹。\n",
    "ckpt_path：CheckPoint文件路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current context loaded:\n",
      "    mode: 0\n",
      "    device_target: GPU\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from mindspore import context\n",
    "from easydict import EasyDict as edict\n",
    "# LSTM网络参数\n",
    "lstm_cfg = edict({\n",
    "    'num_classes': 2,\n",
    "    'learning_rate': 0.1,\n",
    "    'momentum': 0.9,\n",
    "    'num_epochs': 10,\n",
    "    'batch_size': 64,\n",
    "    'embed_size': 300,\n",
    "    'num_hiddens': 100,\n",
    "    'num_layers': 2,\n",
    "    'bidirectional': True,\n",
    "    'save_checkpoint_steps': 390,\n",
    "    'keep_checkpoint_max': 10\n",
    "})\n",
    "cfg = lstm_cfg\n",
    "parser = argparse.ArgumentParser(description='MindSpore LSTM Example')\n",
    "parser.add_argument('--preprocess', type=str, default='false', choices=['true', 'false'],\n",
    "                    help='whether to preprocess data.')\n",
    "parser.add_argument('--aclimdb_path', type=str, default=\"./datasets/aclImdb\",\n",
    "                    help='path where the dataset is stored.')\n",
    "parser.add_argument('--glove_path', type=str, default=\"./datasets/glove\",\n",
    "                    help='path where the GloVe is stored.')\n",
    "parser.add_argument('--preprocess_path', type=str, default=\"./preprocess\",\n",
    "                    help='path where the pre-process data is stored.')\n",
    "parser.add_argument('--ckpt_path', type=str, default=\"./models/ckpt/nlp_application\",\n",
    "                    help='the path to save the checkpoint file.')\n",
    "parser.add_argument('--pre_trained', type=str, default=None,\n",
    "                    help='the pretrained checkpoint file path.')\n",
    "parser.add_argument('--device_target', type=str, default=\"GPU\", choices=['GPU', 'CPU'],\n",
    "                    help='the target device to run, support \"GPU\", \"CPU\". Default: \"GPU\".')\n",
    "args = parser.parse_args(['--device_target', 'GPU', '--preprocess', 'true'])\n",
    "context.set_context(\n",
    "        mode=context.GRAPH_MODE,\n",
    "        save_graphs=False,\n",
    "        device_target=args.device_target)\n",
    "print(\"Current context loaded:\\n    mode: {}\\n    device_target: {}\".format(context.get_context(\"mode\"), context.get_context(\"device_target\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）数据的读取与处理\n",
    "\n",
    "按照下面的流程解析原始数据集，获得features与labels：sentence->tokenized->encoded->padding->features。\n",
    "\n",
    "定义convert_to_mindrecord函数将数据集格式转换为MindRecord格式，便于MindSpore读取。\n",
    "对文本数据集进行处理，包括编码、分词、对齐、处理GloVe原始数据，使之能够适应网络结构。\n",
    "\n",
    "定义convert_to_mindrecord函数将数据集格式转换为MindRecord格式，便于MindSpore读取。\n",
    "\n",
    "转换成功后会在`preprocess`目录下生成MindRecord文件，通常该操作在数据集不变的情况下，无需每次训练都执行，此时查看`preprocess`文件目录结构。\n",
    "\n",
    "```text\n",
    "preprocess\n",
    "├── aclImdb_test.mindrecord0\n",
    "├── aclImdb_test.mindrecord0.db\n",
    "├── aclImdb_test.mindrecord1\n",
    "├── aclImdb_test.mindrecord1.db\n",
    "├── aclImdb_test.mindrecord2\n",
    "├── aclImdb_test.mindrecord2.db\n",
    "├── aclImdb_test.mindrecord3\n",
    "├── aclImdb_test.mindrecord3.db\n",
    "├── aclImdb_train.mindrecord0\n",
    "├── aclImdb_train.mindrecord0.db\n",
    "├── aclImdb_train.mindrecord1\n",
    "├── aclImdb_train.mindrecord1.db\n",
    "├── aclImdb_train.mindrecord2\n",
    "├── aclImdb_train.mindrecord2.db\n",
    "├── aclImdb_train.mindrecord3\n",
    "├── aclImdb_train.mindrecord3.db\n",
    "└── weight.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Data Pre-processing ==============\n",
      "======================= Successful =======================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import gensim\n",
    "from mindspore.mindrecord import FileWriter\n",
    "class ImdbParser():\n",
    "# 按照下面的流程解析原始数据集，获得features与labels：sentence->tokenized->encoded->padding->features\n",
    "    def __init__(self, imdb_path, glove_path, embed_size=300):\n",
    "        self.__segs = ['train', 'test']\n",
    "        self.__label_dic = {'pos': 1, 'neg': 0}\n",
    "        self.__imdb_path = imdb_path\n",
    "        self.__glove_dim = embed_size\n",
    "        self.__glove_file = os.path.join(glove_path, 'glove.6B.' + str(self.__glove_dim) + 'd.txt')\n",
    "        self.__imdb_datas = {}\n",
    "        self.__features = {}\n",
    "        self.__labels = {}\n",
    "        self.__vacab = {}\n",
    "        self.__word2idx = {}\n",
    "        self.__weight_np = {}\n",
    "        self.__wvmodel = None\n",
    "    def parse(self):\n",
    "#解析imdb数据集\n",
    "        self.__wvmodel = gensim.models.KeyedVectors.load_word2vec_format(self.__glove_file)\n",
    "        for seg in self.__segs:\n",
    "            self.__parse_imdb_datas(seg)\n",
    "            self.__parse_features_and_labels(seg)\n",
    "            self.__gen_weight_np(seg)\n",
    "    def __parse_imdb_datas(self, seg):\n",
    "#从原始文本中加载数据\n",
    "        data_lists = []\n",
    "        for label_name, label_id in self.__label_dic.items():\n",
    "            sentence_dir = os.path.join(self.__imdb_path, seg, label_name)\n",
    "            for file in os.listdir(sentence_dir):\n",
    "                with open(os.path.join(sentence_dir, file), mode='r', encoding='utf8') as f:\n",
    "                    sentence = f.read().replace('\\n', '')\n",
    "                    data_lists.append([sentence, label_id])\n",
    "        self.__imdb_datas[seg] = data_lists\n",
    "    def __parse_features_and_labels(self, seg):\n",
    "#解析features与labels\n",
    "        features = []\n",
    "        labels = []\n",
    "        for sentence, label in self.__imdb_datas[seg]:\n",
    "            features.append(sentence)\n",
    "            labels.append(label)\n",
    "        self.__features[seg] = features\n",
    "        self.__labels[seg] = labels\n",
    "        self.__updata_features_to_tokenized(seg)\n",
    "        self.__parse_vacab(seg)\n",
    "        self.__encode_features(seg)\n",
    "        self.__padding_features(seg)\n",
    "    def __updata_features_to_tokenized(self, seg):\n",
    "#切分原始语句\n",
    "        tokenized_features = []\n",
    "        for sentence in self.__features[seg]:\n",
    "            tokenized_sentence = [word.lower() for word in sentence.split(\" \")]\n",
    "            tokenized_features.append(tokenized_sentence)\n",
    "        self.__features[seg] = tokenized_features\n",
    "    def __parse_vacab(self, seg):\n",
    "#构建词汇表\n",
    "        tokenized_features = self.__features[seg]\n",
    "        vocab = set(chain(*tokenized_features))\n",
    "        self.__vacab[seg] = vocab\n",
    "        word_to_idx = {word: i + 1 for i, word in enumerate(vocab)}\n",
    "        word_to_idx['<unk>'] = 0\n",
    "        self.__word2idx[seg] = word_to_idx\n",
    "    def __encode_features(self, seg):\n",
    "#词汇编码\n",
    "        word_to_idx = self.__word2idx['train']\n",
    "        encoded_features = []\n",
    "        for tokenized_sentence in self.__features[seg]:\n",
    "            encoded_sentence = []\n",
    "            for word in tokenized_sentence:\n",
    "                encoded_sentence.append(word_to_idx.get(word, 0))\n",
    "            encoded_features.append(encoded_sentence)\n",
    "        self.__features[seg] = encoded_features\n",
    "    def __padding_features(self, seg, maxlen=500, pad=0):\n",
    "# 将所有features填充到相同的长度\n",
    "        padded_features = []\n",
    "        for feature in self.__features[seg]:\n",
    "            if len(feature) >= maxlen:\n",
    "                padded_feature = feature[:maxlen]\n",
    "            else:\n",
    "                padded_feature = feature\n",
    "                while len(padded_feature) < maxlen:\n",
    "                    padded_feature.append(pad)\n",
    "            padded_features.append(padded_feature)\n",
    "        self.__features[seg] = padded_features\n",
    "    def __gen_weight_np(self, seg):\n",
    "   # 使用gensim获取权重\n",
    "        weight_np = np.zeros((len(self.__word2idx[seg]), self.__glove_dim), dtype=np.float32)\n",
    "        for word, idx in self.__word2idx[seg].items():\n",
    "            if word not in self.__wvmodel:\n",
    "                continue\n",
    "            word_vector = self.__wvmodel.get_vector(word)\n",
    "            weight_np[idx, :] = word_vector\n",
    "        self.__weight_np[seg] = weight_np\n",
    "    def get_datas(self, seg):\n",
    "#返回 features, labels, weight\n",
    "        features = np.array(self.__features[seg]).astype(np.int32)\n",
    "        labels = np.array(self.__labels[seg]).astype(np.int32)\n",
    "        weight = np.array(self.__weight_np[seg])\n",
    "        return features, labels, weight\n",
    "def _convert_to_mindrecord(data_home, features, labels, weight_np=None, training=True):\n",
    "#将原始数据集转换为mindrecord格式\n",
    "    if weight_np is not None:\n",
    "        np.savetxt(os.path.join(data_home, 'weight.txt'), weight_np)\n",
    "# 写入mindrecord\n",
    "    schema_json = {\"id\": {\"type\": \"int32\"},\n",
    "                   \"label\": {\"type\": \"int32\"},\n",
    "                   \"feature\": {\"type\": \"int32\", \"shape\": [-1]}}\n",
    "    data_dir = os.path.join(data_home, \"aclImdb_train.mindrecord\")\n",
    "    if not training:\n",
    "        data_dir = os.path.join(data_home, \"aclImdb_test.mindrecord\")\n",
    "    def get_imdb_data(features, labels):\n",
    "        data_list = []\n",
    "        for i, (label, feature) in enumerate(zip(labels, features)):\n",
    "            data_json = {\"id\": i,\n",
    "                         \"label\": int(label),\n",
    "                         \"feature\": feature.reshape(-1)}\n",
    "            data_list.append(data_json)\n",
    "        return data_list\n",
    "    writer = FileWriter(data_dir, shard_num=4)\n",
    "    data = get_imdb_data(features, labels)\n",
    "    writer.add_schema(schema_json, \"nlp_schema\")\n",
    "    writer.add_index([\"id\", \"label\"])\n",
    "    writer.write_raw_data(data)\n",
    "    writer.commit()\n",
    "def convert_to_mindrecord(embed_size, aclimdb_path, preprocess_path, glove_path):\n",
    "#将原始数据集转换为mindrecord格式\n",
    "    parser = ImdbParser(aclimdb_path, glove_path, embed_size)\n",
    "    parser.parse()\n",
    "    if not os.path.exists(preprocess_path):\n",
    "        print(f\"preprocess path {preprocess_path} is not exist\")\n",
    "        os.makedirs(preprocess_path)\n",
    "    train_features, train_labels, train_weight_np = parser.get_datas('train')\n",
    "    _convert_to_mindrecord(preprocess_path, train_features, train_labels, train_weight_np)\n",
    "    test_features, test_labels, _ = parser.get_datas('test')\n",
    "    _convert_to_mindrecord(preprocess_path, test_features, test_labels, training=False)\n",
    "if args.preprocess == \"true\":\n",
    "    os.system(\"rm -f ./preprocess/aclImdb* weight*\")\n",
    "    print(\"============== Starting Data Pre-processing ==============\")\n",
    "    convert_to_mindrecord(cfg.embed_size, args.aclimdb_path, args.preprocess_path, args.glove_path)\n",
    "    print(\"======================= Successful =======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4)创建训练集：\n",
    "定义创建数据集函数lstm_create_dataset，创建训练集ds_train。\n",
    "\n",
    "通过create_dict_iterator方法创建字典迭代器，读取已创建的数据集ds_train中的数据。\n",
    "\n",
    "运行以下一段代码，创建数据集并读取第1个batch中的label数据列表和第1个batch中第1个元素的feature数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first batch contains label below:\n",
      "[0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 0 1\n",
      " 0 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0]\n",
      "\n",
      "The feature of the first item in the first batch is below vector:\n",
      "[249996  54143 184172 203651 229589 221693 185989 118515  64846  54704\n",
      "  19712 140286  54143  10035 223633 182804 110279  20992 185989 118515\n",
      "  54143 229589 124426 189682 129826  98619 251411  16315 100038 112995\n",
      " 237022 116461  30735 229874  38533  25750  44090  30219  30735 229874\n",
      " 171780 118515  65081  44090  74354 128277  82354 118515 215392  61497\n",
      " 212639    923 210633 105168 249996  54143 185745 184172 187822 185213\n",
      " 223619 100038  65443  73067 129442  44090 118515 156542  82301 111804\n",
      "  66658 184172  42988  95885 185989  76874  13192 171920 229589 156542\n",
      "  45558   5290  52959  80287  91542  91662 114496 112876  42988 192087\n",
      " 185507 186212  66658 233582 230976 143758 128277 215027 229589 154143\n",
      " 246234 167821 184159  40065 100038 112995 238258 180552 118515  95633\n",
      " 128277 118515  99327  98619 184172  24185  98619 184172  88217 128277\n",
      " 159969 128277  98619  96460  44090 118515 130663    710 128277 247284\n",
      " 118515  90362 185989 118515  90745 100038 112995 187822  42867 249652\n",
      " 118515 123509 239643 184172 118515 212864 185989  98619 161660      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mindspore.dataset as ds\n",
    "def lstm_create_dataset(data_home, batch_size, repeat_num=1, training=True):\n",
    "#创建数据集\n",
    "    ds.config.set_seed(1)\n",
    "    data_dir = os.path.join(data_home, \"aclImdb_train.mindrecord0\")\n",
    "    if not training:\n",
    "        data_dir = os.path.join(data_home, \"aclImdb_test.mindrecord0\")\n",
    "    data_set = ds.MindDataset(data_dir, columns_list=[\"feature\", \"label\"], num_parallel_workers=4)\n",
    "# 对数据集进行shuffle、batch与repeat操作\n",
    "    data_set = data_set.shuffle(buffer_size=data_set.get_dataset_size())\n",
    "    data_set = data_set.batch(batch_size=batch_size, drop_remainder=True)\n",
    "    data_set = data_set.repeat(count=repeat_num)\n",
    "    return data_set\n",
    "ds_train = lstm_create_dataset(args.preprocess_path, cfg.batch_size)\n",
    "iterator = next(ds_train.create_dict_iterator())\n",
    "first_batch_label = iterator[\"label\"].asnumpy()\n",
    "first_batch_first_feature = iterator[\"feature\"].asnumpy()[0]\n",
    "print(f\"The first batch contains label below:\\n{first_batch_label}\\n\")\n",
    "print(f\"The feature of the first item in the first batch is below vector:\\n{first_batch_first_feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5)模型构建\n",
    "\n",
    "导入初始化网络所需模块。\n",
    "\n",
    "定义需要单层LSTM小算子堆叠的设备类型。\n",
    "\n",
    "定义lstm_default_state函数来初始化网络参数及网络状态。\n",
    "\n",
    "定义stack_lstm_default_state函数来初始化小算子堆叠需要的初始化网络参数及网络状态。\n",
    "\n",
    "针对CPU场景，自定义单层LSTM小算子堆叠，来实现多层LSTM大算子功能。\n",
    "\n",
    "使用Cell方法，定义网络结构（SentimentNet网络）。\n",
    "\n",
    "实例化SentimentNet，创建网络，最后输出网络中加载的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('embedding.embedding_table', Parameter (name=embedding.embedding_table, value=Tensor(shape=[252193, 300], dtype=Float32, value=\n",
      "[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00 ...  0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      " [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00 ...  0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      " [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00 ...  0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      " ...\n",
      " [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00 ...  0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      " [-2.64310002e-01,  2.03539997e-01, -1.07670002e-01 ...  3.17510009e-01, -6.45749986e-01,  4.42129999e-01],\n",
      " [-2.82150000e-01,  2.53950000e-01,  3.94300014e-01 ...  1.75999999e-01,  7.86110014e-02, -7.89420009e-02]]))), ('encoder.weight', Parameter (name=encoder.weight, value=Tensor(shape=[563200, 1, 1], dtype=Float32, value=\n",
      "[[[-1.65955983e-02]],\n",
      " [[ 4.40648980e-02]],\n",
      " [[-9.99771282e-02]],\n",
      " ...\n",
      " [[-6.54547513e-02]],\n",
      " [[ 1.46641862e-02]],\n",
      " [[-2.03442890e-02]]]))), ('decoder.weight', Parameter (name=decoder.weight, value=Tensor(shape=[2, 400], dtype=Float32, value=\n",
      "[[ 8.68825766e-04,  1.55616635e-02, -3.46743106e-03 ... -1.70452073e-02,  6.96127317e-05, -1.37791187e-02],\n",
      " [ 5.52378222e-03, -2.03212705e-02,  1.68735497e-02 ...  1.62047185e-02,  5.66494651e-03, -1.49743268e-02]]))), ('decoder.bias', Parameter (name=decoder.bias, value=Tensor(shape=[2], dtype=Float32, value= [ 0.00000000e+00,  0.00000000e+00])))])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from mindspore import Tensor, nn, context, Parameter, ParameterTuple\n",
    "from mindspore.common.initializer import initializer\n",
    "import mindspore.ops as ops\n",
    "# 当设备类型为CPU时采用堆叠类型的LSTM\n",
    "STACK_LSTM_DEVICE = [\"CPU\"]\n",
    "# 将短期记忆(h)和长期记忆(c)初始化为0\n",
    "def lstm_default_state(batch_size, hidden_size, num_layers, bidirectional):\n",
    "#LSTM网络输入初始化\n",
    "    num_directions = 2 if bidirectional else 1\n",
    "    h = Tensor(np.zeros((num_layers * num_directions, batch_size, hidden_size)).astype(np.float32))\n",
    "    c = Tensor(np.zeros((num_layers * num_directions, batch_size, hidden_size)).astype(np.float32))\n",
    "    return h, c\n",
    "def stack_lstm_default_state(batch_size, hidden_size, num_layers, bidirectional):\n",
    "#STACK LSTM网络输入初始化\n",
    "    num_directions = 2 if bidirectional else 1\n",
    "    h_list = c_list = []\n",
    "    for _ in range(num_layers):\n",
    "        h_list.append(Tensor(np.zeros((num_directions, batch_size, hidden_size)).astype(np.float32)))\n",
    "        c_list.append(Tensor(np.zeros((num_directions, batch_size, hidden_size)).astype(np.float32)))\n",
    "    h, c = tuple(h_list), tuple(c_list)\n",
    "    return h, c\n",
    "class StackLSTM(nn.Cell):\n",
    "#  实现堆叠LSTM\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 num_layers=1,\n",
    "                 has_bias=True,\n",
    "                 batch_first=False,\n",
    "                 dropout=0.0,\n",
    "                 bidirectional=False):\n",
    "        super(StackLSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.transpose = ops.Transpose()\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        input_size_list = [input_size]\n",
    "        for i in range(num_layers - 1):\n",
    "            input_size_list.append(hidden_size * num_directions)\n",
    "# LSTMCell为单层RNN结构，通过堆叠LSTMCell可完成StackLSTM\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layers.append(nn.LSTMCell(input_size=input_size_list[i],\n",
    "                                      hidden_size=hidden_size,\n",
    "                                      has_bias=has_bias,\n",
    "                                      batch_first=batch_first,\n",
    "                                      bidirectional=bidirectional,\n",
    "                                      dropout=dropout))\n",
    "# 权重初始化\n",
    "        weights = []\n",
    "        for i in range(num_layers):\n",
    "            weight_size = (input_size_list[i] + hidden_size) * num_directions * hidden_size * 4\n",
    "            if has_bias:\n",
    "                bias_size = num_directions * hidden_size * 4\n",
    "                weight_size = weight_size + bias_size\n",
    "            stdv = 1 / math.sqrt(hidden_size)\n",
    "            w_np = np.random.uniform(-stdv, stdv, (weight_size, 1, 1)).astype(np.float32)\n",
    "            weights.append(Parameter(initializer(Tensor(w_np), w_np.shape), name=\"weight\" + str(i)))\n",
    "        self.lstms = layers\n",
    "        self.weight = ParameterTuple(tuple(weights))\n",
    "    def construct(self, x, hx):\n",
    "#构建网络\n",
    "        if self.batch_first:\n",
    "            x = self.transpose(x, (1, 0, 2))\n",
    "        h, c = hx\n",
    "        hn = cn = None\n",
    "        for i in range(self.num_layers):\n",
    "            x, hn, cn, _, _ = self.lstms[i](x, h[i], c[i], self.weight[i])\n",
    "        if self.batch_first:\n",
    "            x = self.transpose(x, (1, 0, 2))\n",
    "        return x, (hn, cn)\n",
    "class SentimentNet(nn.Cell):\n",
    "#构建SentimentNet\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embed_size,\n",
    "                 num_hiddens,\n",
    "                 num_layers,\n",
    "                 bidirectional,\n",
    "                 num_classes,\n",
    "                 weight,\n",
    "                 batch_size):\n",
    "        super(SentimentNet, self).__init__()\n",
    "# 对数据中的词汇进行降维\n",
    "        self.embedding = nn.Embedding(vocab_size,\n",
    "                                      embed_size,\n",
    "                                      embedding_table=weight)\n",
    "        self.embedding.embedding_table.requires_grad = False\n",
    "        self.trans = ops.Transpose()\n",
    "        self.perm = (1, 0, 2)\n",
    "# 判断是否需要堆叠LSTM\n",
    "        if context.get_context(\"device_target\") in STACK_LSTM_DEVICE:\n",
    "            self.encoder = StackLSTM(input_size=embed_size,\n",
    "                                     hidden_size=num_hiddens,\n",
    "                                     num_layers=num_layers,\n",
    "                                     has_bias=True,\n",
    "                                     bidirectional=bidirectional,\n",
    "                                     dropout=0.0)\n",
    "            self.h, self.c = stack_lstm_default_state(batch_size, num_hiddens, num_layers, bidirectional)\n",
    "        else:\n",
    "            self.encoder = nn.LSTM(input_size=embed_size,\n",
    "                                   hidden_size=num_hiddens,\n",
    "                                   num_layers=num_layers,\n",
    "                                   has_bias=True,\n",
    "                                   bidirectional=bidirectional,\n",
    "                                   dropout=0.0)\n",
    "            self.h, self.c = lstm_default_state(batch_size, num_hiddens, num_layers, bidirectional)\n",
    "        self.concat = ops.Concat(1)\n",
    "        if bidirectional:\n",
    "            self.decoder = nn.Dense(num_hiddens * 4, num_classes)\n",
    "        else:\n",
    "            self.decoder = nn.Dense(num_hiddens * 2, num_classes)\n",
    "    def construct(self, inputs):\n",
    "# 输入：(64,500,300)\n",
    "        embeddings = self.embedding(inputs)\n",
    "        embeddings = self.trans(embeddings, self.perm)\n",
    "        output, _ = self.encoder(embeddings, (self.h, self.c))\n",
    "        encoding = self.concat((output[0], output[499]))\n",
    "        outputs = self.decoder(encoding)\n",
    "        return outputs\n",
    "embedding_table = np.loadtxt(os.path.join(args.preprocess_path, \"weight.txt\")).astype(np.float32)\n",
    "network = SentimentNet(vocab_size=embedding_table.shape[0],\n",
    "                       embed_size=cfg.embed_size,\n",
    "                       num_hiddens=cfg.num_hiddens,\n",
    "                       num_layers=cfg.num_layers,\n",
    "                       bidirectional=cfg.bidirectional,\n",
    "                       num_classes=cfg.num_classes,\n",
    "                       weight=Tensor(embedding_table),\n",
    "                       batch_size=cfg.batch_size)\n",
    "print(network.parameters_dict(recurse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 模型训练\n",
    "根据建立的LSTM模型，对模型进行训练：\n",
    "\n",
    "运行以下一段代码，创建优化器和损失函数模型，加载训练数据集（ds_train）并配置好CheckPoint生成信息，然后使用model.train接口，进行模型训练。根据输出可以看到loss值随着训练逐步降低，最后达到0.262左右。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Training ==============\n",
      "epoch: 1 step: 78, loss is 0.2971678\n",
      "epoch: 1 step: 156, loss is 0.30519545\n",
      "epoch: 1 step: 234, loss is 0.2370582\n",
      "epoch: 1 step: 312, loss is 0.25823578\n",
      "epoch: 1 step: 390, loss is 0.2899053\n",
      "Epoch time: 27745.798, per step time: 71.143\n",
      "epoch: 2 step: 78, loss is 0.20885809\n",
      "epoch: 2 step: 156, loss is 0.2168142\n",
      "epoch: 2 step: 234, loss is 0.14624771\n",
      "epoch: 2 step: 312, loss is 0.2152691\n",
      "epoch: 2 step: 390, loss is 0.3756763\n",
      "Epoch time: 27407.312, per step time: 70.275\n",
      "epoch: 3 step: 78, loss is 0.116764486\n",
      "epoch: 3 step: 156, loss is 0.20790516\n",
      "epoch: 3 step: 234, loss is 0.2118046\n",
      "epoch: 3 step: 312, loss is 0.18587393\n",
      "epoch: 3 step: 390, loss is 0.25241128\n",
      "Epoch time: 27251.069, per step time: 69.875\n",
      "epoch: 4 step: 78, loss is 0.11729147\n",
      "epoch: 4 step: 156, loss is 0.16071466\n",
      "epoch: 4 step: 234, loss is 0.43869072\n",
      "epoch: 4 step: 312, loss is 0.37149796\n",
      "epoch: 4 step: 390, loss is 0.18670222\n",
      "Epoch time: 27441.597, per step time: 70.363\n",
      "epoch: 5 step: 78, loss is 0.08070815\n",
      "epoch: 5 step: 156, loss is 0.143559\n",
      "epoch: 5 step: 234, loss is 0.292204\n",
      "epoch: 5 step: 312, loss is 0.07726648\n",
      "epoch: 5 step: 390, loss is 0.15458854\n",
      "Epoch time: 27602.059, per step time: 70.775\n",
      "epoch: 6 step: 78, loss is 0.16412595\n",
      "epoch: 6 step: 156, loss is 0.1664415\n",
      "epoch: 6 step: 234, loss is 0.1091502\n",
      "epoch: 6 step: 312, loss is 0.112443276\n",
      "epoch: 6 step: 390, loss is 0.14458877\n",
      "Epoch time: 27568.301, per step time: 70.688\n",
      "epoch: 7 step: 78, loss is 0.110504806\n",
      "epoch: 7 step: 156, loss is 0.079935536\n",
      "epoch: 7 step: 234, loss is 0.29199448\n",
      "epoch: 7 step: 312, loss is 0.1512347\n",
      "epoch: 7 step: 390, loss is 0.3185295\n",
      "Epoch time: 27512.058, per step time: 70.544\n",
      "epoch: 8 step: 78, loss is 0.22663717\n",
      "epoch: 8 step: 156, loss is 0.21799277\n",
      "epoch: 8 step: 234, loss is 0.13152371\n",
      "epoch: 8 step: 312, loss is 0.168206\n",
      "epoch: 8 step: 390, loss is 0.1784227\n",
      "Epoch time: 27545.180, per step time: 70.629\n",
      "epoch: 9 step: 78, loss is 0.27715153\n",
      "epoch: 9 step: 156, loss is 0.085485235\n",
      "epoch: 9 step: 234, loss is 0.35549596\n",
      "epoch: 9 step: 312, loss is 0.1265975\n",
      "epoch: 9 step: 390, loss is 0.081303015\n",
      "Epoch time: 27582.971, per step time: 70.726\n",
      "epoch: 10 step: 78, loss is 0.19696395\n",
      "epoch: 10 step: 156, loss is 0.03179455\n",
      "epoch: 10 step: 234, loss is 0.11651886\n",
      "epoch: 10 step: 312, loss is 0.050257515\n",
      "epoch: 10 step: 390, loss is 0.025655827\n",
      "Epoch time: 27546.935, per step time: 70.633\n",
      "============== Training Success ==============\n"
     ]
    }
   ],
   "source": [
    "from mindspore import Model\n",
    "from mindspore.train.callback import CheckpointConfig, ModelCheckpoint, TimeMonitor, LossMonitor\n",
    "from mindspore.nn import Accuracy\n",
    "from mindspore import nn\n",
    "os.system(\"rm -f {0}/*.ckpt {0}/*.meta\".format(args.ckpt_path))\n",
    "#定义损失函数\n",
    "loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "opt = nn.Momentum(network.trainable_params(), cfg.learning_rate, cfg.momentum)\n",
    "#创建模型对象 model\n",
    "model = Model(network, loss, opt, {'acc': Accuracy()})\n",
    "#创建损失监视器（LossMonitor）对象\n",
    "loss_cb = LossMonitor(per_print_times=78)\n",
    "#输出训练开始的提示信息\n",
    "print(\"============== Starting Training ==============\")\n",
    "#配置模型的检查点（checkpoint）保存方式\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps,\n",
    "                             keep_checkpoint_max=cfg.keep_checkpoint_max)\n",
    "ckpoint_cb = ModelCheckpoint(prefix=\"lstm\", directory=args.ckpt_path, config=config_ck)\n",
    "#创建时间监视器（TimeMonitor）对象\n",
    "time_cb = TimeMonitor(data_size=ds_train.get_dataset_size())\n",
    "if args.device_target == \"CPU\":\n",
    "    model.train(cfg.num_epochs, ds_train, callbacks=[time_cb, ckpoint_cb, loss_cb], dataset_sink_mode=False)\n",
    "else:\n",
    "    model.train(cfg.num_epochs, ds_train, callbacks=[time_cb, ckpoint_cb, loss_cb])\n",
    "print(\"============== Training Success ==============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 模型测试\n",
    "根据处理后的测试数据以及建立的LSTM模型，对模型进行测试：\n",
    "\n",
    "创建并加载验证数据集（ds_eval），加载由训练保存的CheckPoint文件，进行验证，查看模型质量，此步骤用时约30秒。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Testing ==============\n",
      "============== {'acc': 0.8476362179487179} ==============\n"
     ]
    }
   ],
   "source": [
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "#加载模型的检查点文件和将参数加载到网络中\n",
    "args.ckpt_path_saved = f'{args.ckpt_path}/lstm-{cfg.num_epochs}_390.ckpt'\n",
    "print(\"============== Starting Testing ==============\")\n",
    "ds_eval = lstm_create_dataset(args.preprocess_path, cfg.batch_size, training=False)\n",
    "#加载之前保存的检查点文件args.ckpt_path_saved，并将参数加载到网络network中\n",
    "param_dict = load_checkpoint(args.ckpt_path_saved)\n",
    "load_param_into_net(network, param_dict)\n",
    "if args.device_target == \"CPU\":\n",
    "    acc = model.eval(ds_eval, dataset_sink_mode=False)\n",
    "else:\n",
    "    acc = model.eval(ds_eval)\n",
    "#输出准确性\n",
    "print(\"============== {} ==============\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 实验总结\n",
    "\n",
    "以上便完成了MindSpore自然语言处理应用的体验，通过本次体验全面了解了如何使用MindSpore进行自然语言中处理情感分类问题，理解了如何通过定义和初始化基于LSTM的SentimentNet网络进行训练模型及验证正确率。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
