{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b480ed77",
   "metadata": {},
   "source": [
    "#  基于MindSpore实现LSTM算法 \n",
    "本实验基于MindSpore实现LSTM算法，并利用模型进行文本预测。\n",
    "## 1 实验目的\n",
    "1.通过实验了解LSTM算法\n",
    "\n",
    "2.基于MindSpore中实现LSTM算法\n",
    "## 2 LSTM算法原理介绍\n",
    "LSTM四个函数层与具体介绍如下：\n",
    "(1)第一个函数层：遗忘门\n",
    "    ![jupyter](./Figures/fig001.png)\n",
    " \n",
    "对于上一时刻LSTM中的单元状态，一些信息可能会随着时间的流逝而过时。为了不让过多记忆影响神经网络对现在输入的处理，我们应该选择性遗忘一些在之前单元状态中的分量——这个工作就交给了遗忘门。\n",
    "\n",
    "每一次输入一个新的输入，LSTM会先根据新的输入和上一时刻的输出决定遗忘之前的哪些记忆——输入和上一步的输出会整合为一个单独的向量，然后通过sigmoid神经层，最后点对点的乘在单元状态上。因为sigmoid 函数会将任意输入压缩到 (0,1) 的区间上，我们可以非常直觉的得出这个门的工作原理 —— 如果整合后的向量某个分量在通过sigmoid层后变为0，那么显然单元状态在对位相乘后对应的分量也会变成0，换句话说，遗忘了这个分量上的信息；如果某个分量通过sigmoid层后为1，单元状态会“保持完整记忆”。不同的sigmoid输出会带来不同信息的记忆与遗忘。通过这种方式，LSTM可以长期记忆重要信息，并且记忆可以随着输入进行动态调整。下面的公式可以用来描述遗忘门的计算，其中f_t就是sigmoid神经层的输出向量：\n",
    "\n",
    "$f_t=σ(W_f∙[h_(t-1),x_t ]+b_f)$\n",
    "\n",
    "（2）第二个、第三个函数层：记忆门\n",
    "记忆门是用来控制是否将在t时刻（现在）的数据并入单元状态中的控制单位。首先，用tanh函数层将现在的向量中的有效信息提取出来，然后使用sigmoid函数来控制这些记忆要放多少进入单元状态。这两者结合起来就可以做到：\n",
    "\n",
    " ![jupyter](./Figures/fig002.png)\n",
    " \n",
    "从当前输入中提取有效信息；对提取的有效信息做出筛选，为每个分量做出评级(0 ~ 1)，评级越高的最后会有越多的记忆进入单元状态。下面的公式可以分别表示这两个步骤在LSTM中的计算：\n",
    "\n",
    "$C_{t}^{'}=tanh⁡(W_c∙[h_{(t-1)},x_t ]+b_c)$\n",
    "\n",
    "$i_t=σ(W_i∙[h_{(t-1)},x_t ]+b_i)$\n",
    "\n",
    "（3）第四个函数层：输出门\n",
    "\n",
    "输出门就是LSTM单元用于计算当前时刻的输出值的神经层。输出层会先将当前输入值与上一时刻输出值整合后的向量用sigmoid函数提取其中的信息，然后，会将当前的单元状态通过tanh函数压缩映射到区间(-1, 1)中，将经过tanh函数处理后的单元状态与sigmoid函数处理后的单元状态，整合后的向量点对点的乘起来就可以得到LSTM在 t时刻的输出。\n",
    "\n",
    "\n",
    "## 3 实验环境\n",
    "### 实验环境要求\n",
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=1.8；Python环境=3.7\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore1.8 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU CUDA 10.1|Linux-x86_64| MindSpore1.8 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore1.8 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e85054",
   "metadata": {},
   "source": [
    "## 4 数据处理\n",
    "### 4.1 数据准备\n",
    "本次实验需要下载两个数据集并解压使用：\n",
    "\n",
    "（1）lmdb数据集，链接地址如下：\n",
    "http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz；\n",
    "\n",
    "（2）GLove.6b.gz数据集，链接地址如下：\n",
    "\n",
    "http://nlp.stanford.edu/data/glove.6B.zip。\n",
    "\n",
    "此外，还需要增加下列内容：\n",
    "\n",
    "（1）指定读取的数据条数和词向量宽度固定的长度：400000，300\n",
    "\n",
    "（2）可运行文件的组织形式：28-LSTM.ipynb；\n",
    "\n",
    "aclImdb：test、train、imdb.vocab、imdbEr.txt、README；\n",
    "\n",
    "glove：glove.6B.50d.txt、glove.6B.100d.txt、glove.6B.200d.txt、glove.6B.300d.txt。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fc05d1",
   "metadata": {},
   "source": [
    "## 5 模型构建\n",
    "（1）导入Python库&模块并配置运行信息\n",
    "\n",
    "导入依赖包\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f399df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入MindSpore中的nn模块\n",
    "import mindspore.nn as nn\n",
    "#导入MindSpore中的ops模块\n",
    "import mindspore.ops as ops\n",
    "#导入MindSpore中ops模块的operations类\n",
    "from mindspore.ops import operations as P\n",
    "#导入MindSpore中的Model\n",
    "from mindspore.train.model import Model\n",
    "#配置当前执行环境\n",
    "from mindspore import context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac10750",
   "metadata": {},
   "source": [
    "（2）数据的读取与处理\n",
    "\n",
    "读取与处理Imdb数据集，完成数据转换，设置特征编码方式，定义特征编码、特征填充函数，生成特征、标签、权重值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "/src/imdb.py\n",
    "imdb dataset parser.\n",
    "\"\"\"\n",
    "import os\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "\n",
    "class ImdbParser():\n",
    "    \"\"\"\n",
    "    parse aclImdb data to features and labels.\n",
    "    sentence->tokenized->encoded->padding->features\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, imdb_path, glove_path, embed_size=300):\n",
    "        self.__segs = ['train', 'test']\n",
    "        self.__label_dic = {'pos': 1, 'neg': 0}\n",
    "        self.__imdb_path = imdb_path\n",
    "        self.__glove_dim = embed_size\n",
    "        self.__glove_file = os.path.join(glove_path, 'glove.6B.' + str(self.__glove_dim) + 'd.txt')\n",
    "\n",
    "        # properties\n",
    "        self.__imdb_datas = {}\n",
    "        self.__features = {}\n",
    "        self.__labels = {}\n",
    "        self.__vacab = {}\n",
    "        self.__word2idx = {}\n",
    "        self.__weight_np = {}\n",
    "        self.__wvmodel = None\n",
    "\n",
    "    def parse(self):\n",
    "        \"\"\"\n",
    "        parse imdb data to memory\n",
    "        \"\"\"\n",
    "        self.__wvmodel = gensim.models.KeyedVectors.load_word2vec_format(self.__glove_file)\n",
    "\n",
    "        for seg in self.__segs:\n",
    "            self.__parse_imdb_datas(seg)\n",
    "            self.__parse_features_and_labels(seg)\n",
    "            self.__gen_weight_np(seg)\n",
    "\n",
    "    def __parse_imdb_datas(self, seg):\n",
    "        \"\"\"\n",
    "        load data from txt\n",
    "        \"\"\"\n",
    "        data_lists = []\n",
    "        for label_name, label_id in self.__label_dic.items():\n",
    "            sentence_dir = os.path.join(self.__imdb_path, seg, label_name)\n",
    "            for file in os.listdir(sentence_dir):\n",
    "                with open(os.path.join(sentence_dir, file), mode='r', encoding='utf8') as f:\n",
    "                    sentence = f.read().replace('\\n', '')\n",
    "                    data_lists.append([sentence, label_id])\n",
    "        self.__imdb_datas[seg] = data_lists\n",
    "\n",
    "    def __parse_features_and_labels(self, seg):\n",
    "        \"\"\"\n",
    "        parse features and labels\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        labels = []\n",
    "        for sentence, label in self.__imdb_datas[seg]:\n",
    "            features.append(sentence)\n",
    "            labels.append(label)\n",
    "\n",
    "        self.__features[seg] = features\n",
    "        self.__labels[seg] = labels\n",
    "\n",
    "        # update feature to tokenized\n",
    "        self.__updata_features_to_tokenized(seg)\n",
    "        # parse vacab\n",
    "        self.__parse_vacab(seg)\n",
    "        # encode feature\n",
    "        self.__encode_features(seg)\n",
    "        # padding feature\n",
    "        self.__padding_features(seg)\n",
    "\n",
    "    def __updata_features_to_tokenized(self, seg):\n",
    "        tokenized_features = []\n",
    "        for sentence in self.__features[seg]:\n",
    "            tokenized_sentence = [word.lower() for word in sentence.split(\" \")]\n",
    "            tokenized_features.append(tokenized_sentence)\n",
    "        self.__features[seg] = tokenized_features\n",
    "\n",
    "    def __parse_vacab(self, seg):\n",
    "        # vocab\n",
    "        tokenized_features = self.__features[seg]\n",
    "        vocab = set(chain(*tokenized_features))\n",
    "        self.__vacab[seg] = vocab\n",
    "\n",
    "        # word_to_idx: {'hello': 1, 'world':111, ... '<unk>': 0}\n",
    "        word_to_idx = {word: i + 1 for i, word in enumerate(vocab)}\n",
    "        word_to_idx['<unk>'] = 0\n",
    "        self.__word2idx[seg] = word_to_idx\n",
    "\n",
    "    def __encode_features(self, seg):\n",
    "        \"\"\" encode word to index \"\"\"\n",
    "        word_to_idx = self.__word2idx['train']\n",
    "        encoded_features = []\n",
    "        for tokenized_sentence in self.__features[seg]:\n",
    "            encoded_sentence = []\n",
    "            for word in tokenized_sentence:\n",
    "                encoded_sentence.append(word_to_idx.get(word, 0))\n",
    "            encoded_features.append(encoded_sentence)\n",
    "        self.__features[seg] = encoded_features\n",
    "\n",
    "    def __padding_features(self, seg, maxlen=500, pad=0):\n",
    "        \"\"\" pad all features to the same length \"\"\"\n",
    "        padded_features = []\n",
    "        for feature in self.__features[seg]:\n",
    "            if len(feature) >= maxlen:\n",
    "                padded_feature = feature[:maxlen]\n",
    "            else:\n",
    "                padded_feature = feature\n",
    "                while len(padded_feature) < maxlen:\n",
    "                    padded_feature.append(pad)\n",
    "            padded_features.append(padded_feature)\n",
    "        self.__features[seg] = padded_features\n",
    "\n",
    "    def __gen_weight_np(self, seg):\n",
    "        \"\"\"\n",
    "        generate weight by gensim\n",
    "        \"\"\"\n",
    "        weight_np = np.zeros((len(self.__word2idx[seg]), self.__glove_dim), dtype=np.float32)\n",
    "        for word, idx in self.__word2idx[seg].items():\n",
    "            if word not in self.__wvmodel:\n",
    "                continue\n",
    "            word_vector = self.__wvmodel.get_vector(word)\n",
    "            weight_np[idx, :] = word_vector\n",
    "\n",
    "        self.__weight_np[seg] = weight_np\n",
    "\n",
    "    def get_datas(self, seg):\n",
    "        \"\"\"\n",
    "        return features, labels, and weight\n",
    "        \"\"\"\n",
    "        features = np.array(self.__features[seg]).astype(np.int32)\n",
    "        labels = np.array(self.__labels[seg]).astype(np.int32)\n",
    "        weight = np.array(self.__weight_np[seg])\n",
    "        return features, labels, weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aa3672",
   "metadata": {},
   "source": [
    "对图像应用映射操作，定义ID、标签、特征的类型，定义数据转换函数：将imdb数据集转换为mindrecoed数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9d1382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "/src/dataset.py \n",
    "Data operations, will be used in train.py and eval.py\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import mindspore.dataset as ds\n",
    "from mindspore.mindrecord import FileWriter\n",
    "\n",
    "\n",
    "def lstm_create_dataset(data_home, batch_size, repeat_num=1, training=True):\n",
    "    \"\"\"Data operations.\"\"\"\n",
    "    ds.config.set_seed(1)\n",
    "    data_dir = os.path.join(data_home, \"aclImdb_train.mindrecord0\")\n",
    "    if not training:\n",
    "        data_dir = os.path.join(data_home, \"aclImdb_test.mindrecord0\")\n",
    "\n",
    "    data_set = ds.MindDataset(data_dir, columns_list=[\"feature\", \"label\"], num_parallel_workers=4)\n",
    "\n",
    "    # apply map operations on images\n",
    "    data_set = data_set.shuffle(buffer_size=data_set.get_dataset_size())\n",
    "    data_set = data_set.batch(batch_size=batch_size, drop_remainder=True)\n",
    "    data_set = data_set.repeat(count=repeat_num)\n",
    "\n",
    "    return data_set\n",
    "\n",
    "\n",
    "def _convert_to_mindrecord(data_home, features, labels, weight_np=None, training=True):\n",
    "    \"\"\"\n",
    "    convert imdb dataset to mindrecoed dataset\n",
    "    \"\"\"\n",
    "    if weight_np is not None:\n",
    "        np.savetxt(os.path.join(data_home, 'weight.txt'), weight_np)\n",
    "\n",
    "    # write mindrecord\n",
    "    schema_json = {\"id\": {\"type\": \"int32\"},\n",
    "                   \"label\": {\"type\": \"int32\"},\n",
    "                   \"feature\": {\"type\": \"int32\", \"shape\": [-1]}}\n",
    "\n",
    "    data_dir = os.path.join(data_home, \"aclImdb_train.mindrecord\")\n",
    "    if not training:\n",
    "        data_dir = os.path.join(data_home, \"aclImdb_test.mindrecord\")\n",
    "\n",
    "    def get_imdb_data(features, labels):\n",
    "        data_list = []\n",
    "        for i, (label, feature) in enumerate(zip(labels, features)):\n",
    "            data_json = {\"id\": i,\n",
    "                         \"label\": int(label),\n",
    "                         \"feature\": feature.reshape(-1)}\n",
    "            data_list.append(data_json)\n",
    "        return data_list\n",
    "\n",
    "    writer = FileWriter(data_dir, shard_num=4)\n",
    "    data = get_imdb_data(features, labels)\n",
    "    writer.add_schema(schema_json, \"nlp_schema\")\n",
    "    writer.add_index([\"id\", \"label\"])\n",
    "    writer.write_raw_data(data)\n",
    "    writer.commit()\n",
    "\n",
    "\n",
    "def convert_to_mindrecord(embed_size, aclimdb_path, preprocess_path, glove_path):\n",
    "    \"\"\"\n",
    "    convert imdb dataset to mindrecoed dataset\n",
    "    \"\"\"\n",
    "    parser = ImdbParser(aclimdb_path, glove_path, embed_size)\n",
    "    parser.parse()\n",
    "\n",
    "    if not os.path.exists(preprocess_path):\n",
    "        print(f\"preprocess path {preprocess_path} is not exist\")\n",
    "        os.makedirs(preprocess_path)\n",
    "\n",
    "    train_features, train_labels, train_weight_np = parser.get_datas('train')\n",
    "    _convert_to_mindrecord(preprocess_path, train_features, train_labels, train_weight_np)\n",
    "\n",
    "    test_features, test_labels, _ = parser.get_datas('test')\n",
    "    _convert_to_mindrecord(preprocess_path, test_features, test_labels, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b431c39c",
   "metadata": {},
   "source": [
    "（3）定义参数变量\n",
    "\n",
    "根据LSTM算法原理，配置LSTM的config信息文件，并设置训练以及模型构建的参数信息，然后根据训练集数据与测试机数据设置参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8711ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "network config setting\n",
    "\"\"\"\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "# LSTM CONFIG\n",
    "lstm_cfg = edict({\n",
    "    'num_classes': 2,\n",
    "    'learning_rate': 0.1,\n",
    "    'momentum': 0.9,\n",
    "    'num_epochs': 20,    #在训练时可以缩小该数字，以缩短训练时间\n",
    "    'batch_size': 64,\n",
    "    'embed_size': 300,\n",
    "    'num_hiddens': 100,\n",
    "    'num_layers': 2,\n",
    "    'bidirectional': True,\n",
    "    'save_checkpoint_steps': 390,\n",
    "    'keep_checkpoint_max': 10\n",
    "})\n",
    "\n",
    "args_train = edict({\n",
    "    'preprocess': 'true',\n",
    "    'aclimdb_path': \"./aclImdb\",\n",
    "    'glove_path': \"./glove\",\n",
    "    'preprocess_path': \"./preprocess\",\n",
    "    'ckpt_path': \"./\",\n",
    "    'pre_trained': None,\n",
    "    'device_target': \"GPU\",\n",
    "})\n",
    "\n",
    "\n",
    "args_test = edict({\n",
    "    'preprocess': 'false',\n",
    "    'aclimdb_path': \"./aclImdb\",\n",
    "    'glove_path': \"./glove\",\n",
    "    'preprocess_path': \"./preprocess\",\n",
    "    'ckpt_path': \"./lstm-20_390.ckpt\",\n",
    "    'pre_trained': None,\n",
    "    'device_target': \"GPU\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81c33db",
   "metadata": {},
   "source": [
    "(4)模型构建\n",
    "\n",
    "根据处理后的数据集，定义LSTM网络，构建LSTM网络模型。\n",
    "根据提示，补充“将输入映射到向量”部分的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cf1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "src/lstm.py\n",
    "LSTM.\n",
    "\"\"\"\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "\n",
    "class SentimentNet(nn.Cell):\n",
    "    \"\"\"Sentiment network structure.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embed_size,\n",
    "                 num_hiddens,\n",
    "                 num_layers,\n",
    "                 bidirectional,\n",
    "                 num_classes,\n",
    "                 weight,\n",
    "                 batch_size):\n",
    "        super(SentimentNet, self).__init__()\n",
    "# 将输入映射到向量，补充代码\n",
    "\n",
    "    def construct(self, inputs):\n",
    "        # input：(64,500,300)\n",
    "        embeddings = self.embedding(inputs)\n",
    "        embeddings = self.trans(embeddings, self.perm)\n",
    "        output, _ = self.encoder(embeddings)\n",
    "        # states[i] size(64,200)  -> encoding.size(64,400)\n",
    "        encoding = self.concat((output[0], output[499]))\n",
    "        outputs = self.decoder(encoding)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6e8ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#参考答案\n",
    "# 将输入映射到向量\n",
    "        self.embedding = nn.Embedding(vocab_size,\n",
    "                                      embed_size,\n",
    "                                      embedding_table=weight)\n",
    "        self.embedding.embedding_table.requires_grad = False\n",
    "        self.trans = ops.Transpose()\n",
    "        self.perm = (1, 0, 2)\n",
    "\n",
    "        self.encoder = nn.LSTM(input_size=embed_size,\n",
    "                               hidden_size=num_hiddens,\n",
    "                               num_layers=num_layers,\n",
    "                               has_bias=True,\n",
    "                               bidirectional=bidirectional,\n",
    "                               dropout=0.0)\n",
    "\n",
    "        self.concat = ops.Concat(1)\n",
    "        if bidirectional:\n",
    "            self.decoder = nn.Dense(num_hiddens * 4, num_classes)\n",
    "        else:\n",
    "            self.decoder = nn.Dense(num_hiddens * 2, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506cfead",
   "metadata": {},
   "source": [
    "## 6 模型训练\n",
    "根据建立的LSTM模型，对模型进行训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e7e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#################train lstm example on aclImdb########################\n",
    "python train.py --preprocess=true --aclimdb_path=your_imdb_path --glove_path=your_glove_path\n",
    "\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "from src.config import lstm_cfg as cfg\n",
    "from src.dataset import convert_to_mindrecord\n",
    "from src.dataset import lstm_create_dataset\n",
    "from src.lstm import SentimentNet\n",
    "\"\"\"\n",
    "from mindspore import Tensor, nn, Model, context, load_param_into_net, load_checkpoint\n",
    "from mindspore.nn import Accuracy\n",
    "from mindspore.train.callback import LossMonitor, CheckpointConfig, ModelCheckpoint, TimeMonitor\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "if 1:\n",
    "    args = args_train\n",
    "\n",
    "    cfg = lstm_cfg\n",
    "    context.set_context(\n",
    "        mode=context.GRAPH_MODE,\n",
    "        save_graphs=False,\n",
    "        device_target=args.device_target)\n",
    "\n",
    "    if args.preprocess == \"true\":\n",
    "        print(\"============== Starting Data Pre-processing ==============\")\n",
    "        convert_to_mindrecord(cfg.embed_size, args.aclimdb_path, args.preprocess_path, args.glove_path)\n",
    "\n",
    "    embedding_table = np.loadtxt(os.path.join(args.preprocess_path, \"weight.txt\")).astype(np.float32)\n",
    "    network = SentimentNet(vocab_size=embedding_table.shape[0],\n",
    "                           embed_size=cfg.embed_size,\n",
    "                           num_hiddens=cfg.num_hiddens,\n",
    "                           num_layers=cfg.num_layers,\n",
    "                           bidirectional=cfg.bidirectional,\n",
    "                           num_classes=cfg.num_classes,\n",
    "                           weight=Tensor(embedding_table),\n",
    "                           batch_size=cfg.batch_size)\n",
    "    # pre_trained\n",
    "    if args.pre_trained:\n",
    "        load_param_into_net(network, load_checkpoint(args.pre_trained))\n",
    "\n",
    "    loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    opt = nn.Momentum(network.trainable_params(), cfg.learning_rate, cfg.momentum)\n",
    "    loss_cb = LossMonitor()\n",
    "\n",
    "    model = Model(network, loss, opt, {'acc': Accuracy()})\n",
    "\n",
    "    print(\"============== Starting Training ==============\")\n",
    "    ds_train = lstm_create_dataset(args.preprocess_path, cfg.batch_size, 1)\n",
    "    config_ck = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps,\n",
    "                                 keep_checkpoint_max=cfg.keep_checkpoint_max)\n",
    "    ckpoint_cb = ModelCheckpoint(prefix=\"lstm\", directory=args.ckpt_path, config=config_ck)\n",
    "    time_cb = TimeMonitor(data_size=ds_train.get_dataset_size())\n",
    "    if args.device_target == \"CPU\":\n",
    "        model.train(cfg.num_epochs, ds_train, callbacks=[time_cb, ckpoint_cb, loss_cb], dataset_sink_mode=False)\n",
    "    else:\n",
    "        model.train(cfg.num_epochs, ds_train, callbacks=[time_cb, ckpoint_cb, loss_cb])\n",
    "    print(\"============== Training Success ==============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d2e3f",
   "metadata": {},
   "source": [
    "### 7 模型测试\n",
    "根据建立的LSTM模型，对模型进行测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c6be7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#################train lstm example on aclImdb########################\n",
    "python eval.py --ckpt_path=./lstm-20-390.ckpt\n",
    "\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "from src.config import lstm_cfg as cfg\n",
    "from src.dataset import lstm_create_dataset, convert_to_mindrecord\n",
    "from src.lstm import SentimentNet\n",
    "\"\"\"\n",
    "from mindspore import Tensor, nn, Model, context, load_checkpoint, load_param_into_net\n",
    "from mindspore.nn import Accuracy\n",
    "from mindspore.train.callback import LossMonitor\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "if 1:\n",
    "    args = args_test\n",
    "\n",
    "    context.set_context(\n",
    "        mode=context.GRAPH_MODE,\n",
    "        save_graphs=False,\n",
    "        device_target=args.device_target)\n",
    "\n",
    "    if args.preprocess == \"true\":\n",
    "        print(\"============== Starting Data Pre-processing ==============\")\n",
    "        convert_to_mindrecord(cfg.embed_size, args.aclimdb_path, args.preprocess_path, args.glove_path)\n",
    "\n",
    "    embedding_table = np.loadtxt(os.path.join(args.preprocess_path, \"weight.txt\")).astype(np.float32)\n",
    "    network = SentimentNet(vocab_size=embedding_table.shape[0],\n",
    "                           embed_size=cfg.embed_size,\n",
    "                           num_hiddens=cfg.num_hiddens,\n",
    "                           num_layers=cfg.num_layers,\n",
    "                           bidirectional=cfg.bidirectional,\n",
    "                           num_classes=cfg.num_classes,\n",
    "                           weight=Tensor(embedding_table),\n",
    "                           batch_size=cfg.batch_size)\n",
    "\n",
    "    loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    opt = nn.Momentum(network.trainable_params(), cfg.learning_rate, cfg.momentum)\n",
    "    loss_cb = LossMonitor()\n",
    "\n",
    "    model = Model(network, loss, opt, {'acc': Accuracy()})\n",
    "\n",
    "    print(\"============== Starting Testing ==============\")\n",
    "    ds_eval = lstm_create_dataset(args.preprocess_path, cfg.batch_size, training=False)\n",
    "    param_dict = load_checkpoint(args.ckpt_path)\n",
    "    load_param_into_net(network, param_dict)\n",
    "    if args.device_target == \"CPU\":\n",
    "        acc = model.eval(ds_eval, dataset_sink_mode=False)\n",
    "    else:\n",
    "        acc = model.eval(ds_eval)\n",
    "    print(\"============== {} ==============\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe09c1",
   "metadata": {},
   "source": [
    "## 8 实验总结\n",
    "本实验介绍了LSTM算法的原理，并按照步骤基于MindSpore实现了LSTM算法，利用lmdb数据集和GLove.6b.gz数据集构建了LSTM模型，对模型进行测试。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindspore_py39",
   "language": "python",
   "name": "mindspore_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
