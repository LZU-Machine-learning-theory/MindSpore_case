{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91878a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入MindSpore中的nn模块\n",
    "import mindspore.nn as nn\n",
    "#导入MindSpore中的ops模块\n",
    "import mindspore.ops as ops\n",
    "#导入MindSpore中ops模块的operations类\n",
    "from mindspore.ops import operations as P\n",
    "#导入MindSpore中的Model\n",
    "from mindspore.train import Model\n",
    "#配置当前执行环境\n",
    "from mindspore import context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c94e2954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用EasyDict库创建LSTM的配置文件\n",
    "from easydict import EasyDict as edict\n",
    "# LSTM CONFIG LSTM的配置项\n",
    "lstm_cfg = edict({\n",
    "    'num_classes': 2,\n",
    "    'learning_rate': 0.1,\n",
    "    'momentum': 0.9,\n",
    "    'num_epochs': 20,    #在训练时可以缩小该数字，以缩短训练时间\n",
    "    'batch_size': 64,\n",
    "    'embed_size': 500,\n",
    "    'num_hiddens': 100,\n",
    "    'num_layers': 2,\n",
    "    'bidirectional': True,\n",
    "    'save_checkpoint_steps': 390,\n",
    "    'keep_checkpoint_max': 10,\n",
    "    'vocab_size':6\n",
    "})\n",
    "#训练参数\n",
    "args_train = edict({\n",
    "    'preprocess': 'true',\n",
    "    'aclimdb_path': \"./aclImdb\",\n",
    "    'glove_path': \"./glove\",\n",
    "    'preprocess_path': \"C:/Users/Administrator/Desktop/28-基于MindSpore实现LSTM算法/preprocessed\",\n",
    "    'ckpt_path': \"./\",\n",
    "    'pre_trained': None,\n",
    "    'device_target': \"CPU\",\n",
    "})\n",
    "#测试参数\n",
    "args_test = edict({\n",
    "    'preprocess': 'false',\n",
    "    'aclimdb_path': \"./aclImdb\",\n",
    "    'glove_path': \"./glove\",\n",
    "    #'preprocess_path': \"./preprocess\",\n",
    "    'preprocess_path': \"C:/Users/Administrator/Desktop/28-基于MindSpore实现LSTM算法/preprocessed\",\n",
    "    'ckpt_path': \"./lstm-20_390.ckpt\",\n",
    "    'pre_trained': None,\n",
    "    'device_target':  \"CPU\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c213ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weight file: C:/Users/Administrator/Desktop/28-基于MindSpore实现LSTM算法/preprocessed/weight.npy\n",
      "Saved weight file: C:/Users/Administrator/Desktop/28-基于MindSpore实现LSTM算法/preprocessed/weight.npy\n",
      "Train Features: [[   843 101308 190657 ...      0      0      0]\n",
      " [137928  18339  17857 ...      0      0      0]\n",
      " [186950  32579  74349 ...      0      0      0]\n",
      " ...\n",
      " [ 83743 147545  75199 ...      0      0      0]\n",
      " [121126 232050  57228 ...      0      0      0]\n",
      " [251249 190657 213461 ...      0      0      0]]\n",
      "Train Labels: [1 1 1 ... 0 0 0]\n",
      "Train Weights: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Test Features: [[ 83743 144724  23492 ...      0      0      0]\n",
      " [ 80919 179673 218301 ...      0      0      0]\n",
      " [ 48615 128921 103689 ...      0      0      0]\n",
      " ...\n",
      " [160358  36325 107934 ...      0      0      0]\n",
      " [ 33094 205948 224495 ...      0      0      0]\n",
      " [ 15771      0 124843 ...      0      0      0]]\n",
      "Test Labels: [1 1 1 ... 0 0 0]\n",
      "Test Weights: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#imdb数据解析\n",
    "import os\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import gensim\n",
    "imdb_path = r\"C:\\Users\\Administrator\\Desktop\\28-基于MindSpore实现LSTM算法\\aclImdb\"\n",
    "glove_path = r\"C:\\Users\\Administrator\\Desktop\\28-基于MindSpore实现LSTM算法\\glove\"\n",
    "preprocess_path = r\"C:\\Users\\Administrator\\Desktop\\28-基于MindSpore实现LSTM算法\\preprocessed\"\n",
    "class ImdbParser():\n",
    "    def __init__(self, imdb_path, glove_path, embed_size=300):\n",
    "        self.__segs = ['train', 'test']\n",
    "        self.__label_dic = {'pos': 1, 'neg': 0}\n",
    "        self.__imdb_path = imdb_path\n",
    "        self.__glove_dim = embed_size\n",
    "        self.__glove_file = os.path.join(glove_path, 'glove.6B.' + str(self.__glove_dim) + 'd.txt')\n",
    "# 定义属性值\n",
    "        self.__imdb_datas = {}\n",
    "        self.__features = {}\n",
    "        self.__labels = {}\n",
    "        self.__vacab = {}\n",
    "        self.__word2idx = {}\n",
    "        self.__weight_np = {}\n",
    "        self.__wvmodel = None\n",
    "    def parse(self):\n",
    "#解析imdb数据到内存\n",
    "        self.__wvmodel = gensim.models.KeyedVectors.load_word2vec_format(self.__glove_file)\n",
    "        for seg in self.__segs:\n",
    "            self.__parse_imdb_datas(seg)\n",
    "            self.__parse_features_and_labels(seg)\n",
    "            self.__gen_weight_np(seg)\n",
    "    def __parse_imdb_datas(self, seg):\n",
    "#从txt中加载数据\n",
    "        data_lists = []\n",
    "        for label_name, label_id in self.__label_dic.items():\n",
    "            sentence_dir = os.path.join(self.__imdb_path, seg, label_name)\n",
    "            for file in os.listdir(sentence_dir):\n",
    "                with open(os.path.join(sentence_dir, file), mode='r', encoding='utf8') as f:\n",
    "                    sentence = f.read().replace('\\n', '')\n",
    "                    data_lists.append([sentence, label_id])\n",
    "        self.__imdb_datas[seg] = data_lists\n",
    "    def __parse_features_and_labels(self, seg):\n",
    "#解析特征与标签\n",
    "        features = []\n",
    "        labels = []\n",
    "        for sentence, label in self.__imdb_datas[seg]:\n",
    "            features.append(sentence)\n",
    "            labels.append(label)\n",
    "        self.__features[seg] = features\n",
    "        self.__labels[seg] = labels\n",
    "#更新特征到标记\n",
    "        self.__updata_features_to_tokenized(seg)\n",
    "# 解析vacab\n",
    "        self.__parse_vacab(seg)\n",
    "#编码特征\n",
    "        self.__encode_features(seg)\n",
    "#填充特征\n",
    "        self.__padding_features(seg)\n",
    "    def __updata_features_to_tokenized(self, seg):\n",
    "# 创建一个空列表，用于存储分词后的句子\n",
    "        tokenized_features = []\n",
    "# 遍历指定部分的特征中的每个句子\n",
    "        for sentence in self.__features[seg]:\n",
    "# 将句子拆分为单词列表，并将每个单词转换为小写\n",
    "            tokenized_sentence = [word.lower() for word in sentence.split(\" \")]\n",
    "# 将分词后的句子添加到 tokenized_features 列表中\n",
    "            tokenized_features.append(tokenized_sentence)\n",
    "# 将分词后的特征更新为原始特征\n",
    "        self.__features[seg] = tokenized_features\n",
    "    def __parse_vacab(self, seg):\n",
    "# 获取分词后的特征\n",
    "        tokenized_features = self.__features[seg]\n",
    "# 将分词后的特征压平为单个词汇集\n",
    "        vocab = set(chain(*tokenized_features))\n",
    "# 将词汇集存储在 __vacab 属性中\n",
    "        self.__vacab[seg] = vocab\n",
    "# 创建一个词汇表字典，将每个单词映射到它在词汇集中的索引值加一\n",
    "        word_to_idx = {word: i + 1 for i, word in enumerate(vocab)}\n",
    "# 将特殊单词 <unk> 映射到索引值 0，以避免在解析过程中遇到未知的单词\n",
    "        word_to_idx['<unk>'] = 0\n",
    "# 将词汇表字典存储在 __word2idx 属性中\n",
    "        self.__word2idx[seg] = word_to_idx\n",
    "    def __encode_features(self, seg):\n",
    "# 获取训练集上的词汇表字典，用于将单词编码为索引\n",
    "        word_to_idx = self.__word2idx['train']\n",
    "        encoded_features = []\n",
    "# 遍历分词后的特征列表\n",
    "        for tokenized_sentence in self.__features[seg]:\n",
    "            encoded_sentence = []\n",
    "# 遍历每个分词后的句子中的单词\n",
    "            for word in tokenized_sentence:\n",
    "# 将单词编码为索引，如果单词不在词汇表中，将其编码为索引值为 0，即 '<unk>' 的索引值\n",
    "                encoded_sentence.append(word_to_idx.get(word, 0))\n",
    "# 将编码后的句子添加到编码特征列表中\n",
    "            encoded_features.append(encoded_sentence)\n",
    "# 更新分词后的特征列表为编码特征列表\n",
    "        self.__features[seg] = encoded_features\n",
    "    def __padding_features(self, seg, maxlen=500, pad=0):\n",
    "        padded_features = []\n",
    "# 遍历特征列表中的每个特征\n",
    "        for feature in self.__features[seg]:\n",
    "# 如果当前特征长度大于等于 maxlen，则只取前 maxlen 个元素\n",
    "            if len(feature) >= maxlen:\n",
    "                padded_feature = feature[:maxlen]\n",
    "# 否则，在当前特征后面添加 pad 直到特征长度达到 maxlen\n",
    "            else:\n",
    "                padded_feature = feature\n",
    "                while len(padded_feature) < maxlen:\n",
    "                    padded_feature.append(pad)\n",
    "# 将填充后的特征添加到填充特征列表中\n",
    "            padded_features.append(padded_feature)\n",
    "# 更新分词后的特征列表为填充特征列表\n",
    "        self.__features[seg] = padded_features\n",
    "    def __gen_weight_np(self, seg):\n",
    "        weight_np = np.zeros((len(self.__word2idx[seg]), self.__glove_dim), dtype=np.float32)\n",
    "        for word, idx in self.__word2idx[seg].items():\n",
    "            if word not in self.__wvmodel:\n",
    "                continue\n",
    "                word_vector = self.__wvmodel.get_vector(word)\n",
    "                weight_np[idx, :] = word_vector\n",
    "        weight_file = os.path.join(self.__imdb_path, seg, 'C:/Users/Administrator/Desktop/28-基于MindSpore实现LSTM算法/preprocessed/weight.npy')\n",
    "        np.save(weight_file, weight_np)\n",
    "        print(\"Saved weight file:\", weight_file) \n",
    "        self.__weight_np[seg] = weight_np\n",
    "    def get_datas(self, seg):\n",
    "#返回特征、标签和权重值\n",
    "        features = np.array(self.__features[seg]).astype(np.int32)\n",
    "        labels = np.array(self.__labels[seg]).astype(np.int32)\n",
    "        weight = np.array(self.__weight_np[seg])\n",
    "        return features, labels, weight\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建 ImdbParser 对象\n",
    "    parser = ImdbParser(imdb_path, glove_path)\n",
    "\n",
    "    # 解析数据\n",
    "    parser.parse()\n",
    "    # 获取训练集数据\n",
    "    train_features, train_labels, train_weights = parser.get_datas('train')\n",
    "    print(\"Train Features:\", train_features)\n",
    "    print(\"Train Labels:\", train_labels)\n",
    "    print(\"Train Weights:\", train_weights)\n",
    "\n",
    "    # 获取测试集数据\n",
    "    test_features, test_labels, test_weights = parser.get_datas('test')\n",
    "    print(\"Test Features:\", test_features)\n",
    "    print(\"Test Labels:\", test_labels)\n",
    "    print(\"Test Weights:\", test_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ae292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor\n",
    "from mindspore.train.model import Model\n",
    "from mindspore.nn.metrics import Accuracy\n",
    "from mindspore.nn.loss import SoftmaxCrossEntropyWithLogits\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "from mindspore import context\n",
    "\n",
    "# 设置运行模式\n",
    "context.set_context(device_target=args_train.device_target)\n",
    "\n",
    "# 定义 LSTM 模型\n",
    "class LSTMModel(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=128, num_layers=2, has_bias=True, bidirectional=False)\n",
    "        self.dense = nn.Dense(128, 1)\n",
    "\n",
    "    def construct(self, x):\n",
    "        output, _ = self.lstm(x)\n",
    "        output = output[:, -1, :]\n",
    "        output = self.dense(output)\n",
    "        return output\n",
    "\n",
    "# 创建 LSTM 模型实例\n",
    "lstm_model = LSTMModel()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "loss_fn = SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "optimizer = nn.Adam(params=lstm_model.trainable_params(), learning_rate=0.01)\n",
    "\n",
    "# 加载数据\n",
    "train_features = Tensor(train_features, dtype=mindspore.float32)\n",
    "train_labels = Tensor(train_labels, dtype=mindspore.int32)\n",
    "train_weights = Tensor(train_weights, dtype=mindspore.float32)\n",
    "#data=(train_features, train_labels, train_weights)\n",
    "# 创建数据集\n",
    "#train_dataset = ds.GeneratorDataset(source=data,column_names=[\"data\", \"label\",\"weights\"])\n",
    "#train_dataset = ds.NumpySlicesDataset([train_features, train_labels, train_weights], column_names=['features', 'labels', 'weights'])\n",
    "data = [(train_features, train_labels, train_weights)]\n",
    "train_dataset = ds.NumpySlicesDataset(data)\n",
    "# 设置保存检查点的配置\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=1000, keep_checkpoint_max=10)\n",
    "ckpoint_cb = ModelCheckpoint(prefix='lstm', directory='./checkpoints', config=config_ck)\n",
    "\n",
    "# 创建训练模型\n",
    "model = Model(lstm_model, loss_fn, optimizer, metrics={'accuracy': Accuracy()})\n",
    "\n",
    "# 训练模型\n",
    "model.train(epoch=10, train_dataset=train_dataset, callbacks=[ckpoint_cb, LossMonitor()])\n",
    "\n",
    "# 保存最终模型\n",
    "model.save_checkpoint('./checkpoints/lstm_final.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1595bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor\n",
    "\n",
    "# 加载测试数据\n",
    "test_features = load_test_features()  # 加载测试特征数据\n",
    "test_labels = load_test_labels()  # 加载测试标签数据\n",
    "\n",
    "# 将数据转换为张量\n",
    "test_features = Tensor(test_features, dtype=mindspore.float32)\n",
    "\n",
    "# 加载模型\n",
    "model = LSTMModel()  # 创建LSTM模型实例\n",
    "model.load_checkpoint(\"model.ckpt\")  # 加载模型参数\n",
    "\n",
    "# 进行模型推理\n",
    "output = model(test_features)\n",
    "predicted_labels = np.argmax(output.asnumpy(), axis=1)  # 获取预测标签\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = np.mean(predicted_labels == test_labels)\n",
    "\n",
    "print(\"Test Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
