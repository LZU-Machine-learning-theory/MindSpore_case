{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于MindSpore构造卷积层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本实验主要专注于卷积层的原理和构造，使用MindSpore构造卷积层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、实验目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 掌握卷积层的原理和特征。\n",
    "- 掌握如何使用MindSpore构造卷积层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、卷积层原理介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积层的主要作用是提取图像中的特征，浅层卷积层用来提取边缘、纹理等特征，深层卷积层用来提取更加抽象的特征，整合在一起构成了丰富的图像特征。\n",
    "\n",
    "卷积层由一组和输入层有着相同通道数的卷积核构成，将卷积核在输入层上按照指定步长滑动，每到一个位置计算卷积核权重和对应输入特征的乘积，所有乘积求和作为输出特征图的一个特征值，单个卷积核在输入特征上滑动一遍就得到了单通道的输出特征，一组卷积核全部进行上述过程就得到了包含若干通道的输出特征图。这种每次滑动到一个局部位置的计算方式能够在非常大的程度上减少参数量，同时一个物体无论在图像中的什么位置，这一组卷积核都能够提取其特征，具有平移不变性。\n",
    "\n",
    "以单通道为例，卷积的简易过程如图所示，从左到右三部分依次为输入图像、卷积核（过滤器）、输出特征，输入图像尺寸为5×5，卷积核尺寸为3×3，输出特征图尺寸为3×3。卷积核中心滑动到输入图像中某一像素的位置，则重叠的部分分别计算乘积，最后求和作为当前位置的输出特征值。\n",
    "<img src=\"./Figures/fig001.jpg\" style=\"zoom:70%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图中的卷积计算过程如下：\n",
    "\n",
    "第一行卷积的结果为：1×(-1) + 0×(-1) + 0×(-1) = -1 \n",
    "\n",
    "第二行卷积的结果为：1×(-1) + 0× 1 + 1×(-1) = -2\n",
    "\n",
    "第三行卷积的结果为：1×(-1) + 0×(-1) + 1×(-1) = -2\n",
    "\n",
    "然后把三行的结果相加等于-5。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积层输出特征图尺寸计算方式：输入特征图尺寸为$w_i×h_i×c_i$（分别为宽、高、通道数），卷积核的尺寸为$k_i×k_i$（k表示卷积核的边长），输出通道数为$n_{i+1}$，卷积步长为$s$，输入特征图周围填充0特征值的行数为$p_0$，输出特征图的尺寸为$w_{i+1}×h_{i+1}×c_{i+1}$，则输出特征图的尺寸为：\n",
    "$$w_{i+1}=\\frac{w_i-k_i+2p_0}{s}+1$$\n",
    "$$h_{i+1}=\\frac{h_i-k_i+2p_0}{s}+1$$\n",
    "$$c_{i+1}=n_{i+1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当卷积结束之后，可以发现图像变小了，原来是5×5的，现在变成了3×3的，这不是想要的结果，因此进行零填充，因为填充的是二维图像，所以在图像四周都要填成0。填充完之后再开始做卷积运算，中间部分已得出，需要计算新填充的部分，用同样的方式计算完所有的位置，二维卷积的零填充如图所示：\n",
    "<img src=\"./Figures/fig002.jpg\" style=\"zoom:70%\" />\n",
    "原来的图像是5×5的，零填充之后，得到的也是5×5，大小保持不变。\n",
    "根据上面的公式，我们可以计算输出特征图的尺寸。输入特征图尺寸为5×5×1，卷积核的尺寸为3×3，卷积步长$s$为1，输入特征图周围填充0特征值的行数$p_0$为1，根据公式得到输出特征图的尺寸为5×5×1。\n",
    "$$w_{i+1}=\\frac{5-3+2}{1}+1=5$$\n",
    "$$h_{i+1}=\\frac{5-3+2}{1}+1=5$$\n",
    "$$c_{i+1}=n_{i+1}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、实验环境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=MindSpore 2.0；Python环境=3.7\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU CUDA 10.1|Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对输入Tensor计算二维卷积。该Tensor的常见shape为$(N,C_{in},H_{in},W_{in})$，其中N为batch size，$C_{in}$为空间维度，$H_{in}$,$W_{in}$分别为特征层的高度和宽度。现给出Tensor的shape为(1,120,1024,640)计算二维卷积。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 数据加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入需要的Python库，调用mindspore.nn.Conv2d()，它是对输入Tensor计算二维卷积，其中has_bias设置为默认值'False'，weight_init设置为'normal'，然后用给出的Tensor进行数据加载，Tensor的shape为(1,120,1024,640)，然后输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.17673276  0.01873722  0.01873722 ...  0.01873722  0.15733194\n",
      "    0.18270826]\n",
      "  [-0.02393796  0.1633252   0.1633252  ...  0.1633252   0.23819993\n",
      "    0.22824927]\n",
      "  [-0.02393796  0.1633252   0.1633252  ...  0.1633252   0.23819993\n",
      "    0.22824927]\n",
      "  ...\n",
      "  [-0.02393796  0.1633252   0.1633252  ...  0.1633252   0.23819993\n",
      "    0.22824927]\n",
      "  [ 0.214774    0.27904704  0.27904704 ...  0.27904704  0.29368705\n",
      "    0.23236483]\n",
      "  [ 0.19655114  0.28352883  0.28352883 ...  0.2835287   0.36032274\n",
      "    0.21884324]]]\n",
      "(1, 240, 1024, 640)\n"
     ]
    }
   ],
   "source": [
    "from mindspore.common.tensor import Tensor\n",
    "import mindspore.nn as nn\n",
    "import numpy as np\n",
    "import mindspore.common.dtype as mstype\n",
    "\n",
    "# 给出Tensor的shape为(1,120,1024,640)计算二维卷积。\n",
    "net = nn.Conv2d(120, 240, 4, has_bias=False, weight_init='normal')\n",
    "# 输入\n",
    "x = Tensor(np.ones([1, 120, 1024, 640]), mstype.float32)\n",
    "output = net(x)\n",
    "# 输出\n",
    "print(output[:,6])\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**导入Python库&模块**\n",
    "\n",
    "在使用前，导入需要的Python库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入科学计算库\n",
    "import numpy as np\n",
    "# 导入神经网络模块\n",
    "import mindspore.nn as nn\n",
    "# 被初始化的Tensor的数据类型\n",
    "import mindspore.common.dtype as mstype\n",
    "from mindspore import log as logger\n",
    "# 环境设置模块\n",
    "from mindspore import context\n",
    "# 常见操作\n",
    "from mindspore.ops import operations as P\n",
    "from mindspore.common.parameter import Parameter\n",
    "# 导入初始化神经元的各个参数\n",
    "from mindspore.common.initializer import initializer\n",
    "# 用于初始化Tensor的Tensor\n",
    "from mindspore import Tensor\n",
    "import mindspore._checkparam as Validator # nightly测试\n",
    "# from mindspore._checkparam import twice\n",
    "from mindspore._extends import cell_attr_register \n",
    "# MindSpore中神经网络的基本构成单元\n",
    "from mindspore.nn.cell import Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用Mindspore官方定义的卷积神经网络层**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用MindSpore官方定义的_Conv类，该类首先定义卷积过程中要使用的参数，如：卷积核的高度和宽度、卷积核的移动步长、填充模式以及数据格式等参数。然后初始化卷积层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对由多个输入平面组成的输入信号应用N-D卷积\n",
    "class _Conv(Cell):\n",
    "    def __init__(self,\n",
    "                 in_channels,        # 输入Tensor的空间维度\n",
    "                 out_channels,       # 输出Tensor的空间维度\n",
    "                 kernel_size,        # 指定卷积核的高度和宽度\n",
    "                 stride,             # 卷积核的移动步长\n",
    "                 pad_mode,           # 指定填充模式。默认值\"same\"，指输出的高度和宽度分别与输入整除stride后的值相同。\n",
    "                 padding,            # 输入的高度和宽度方向上填充的数量\n",
    "                 dilation,           # 卷积核膨胀尺寸\n",
    "                 group,              # 将过滤器拆分为组\n",
    "                 has_bias,           # 卷积层是否添加偏置参数，默认值：False\n",
    "                 weight_init,        # 权重参数的初始化方法\n",
    "                 bias_init,          # 偏置参数的初始化方法\n",
    "                 data_format='NCHW', # 数据格式的可选值有\"NHWC\"、\"NCHW\"。默认值:\"NCHW\"\n",
    "                 transposed=False):\n",
    "        # 初始化卷积层\n",
    "        super(_Conv, self).__init__()\n",
    "        # 对于构造函数中的self参数，其代表的是当前正在初始化的类对象\n",
    "        self.in_channels = Validator.check_positive_int(in_channels, 'in_channels', self.cls_name)\n",
    "        self.out_channels = Validator.check_positive_int(out_channels, 'out_channels', self.cls_name)\n",
    "        self.kernel_size = kernel_size\n",
    "        # self所表示的是实际调用该方法的对象\n",
    "        self.stride = stride\n",
    "        self.pad_mode = pad_mode\n",
    "        self.weight_init = weight_init\n",
    "        self.bias_init = bias_init\n",
    "        # 数据格式的可选值有\"NHWC\"、\"NCHW\"。默认值:\"NCHW\"\n",
    "        self.data_format = Validator.check_string(data_format, ['NCHW', 'NHWC', 'NCDHW'], 'format', self.cls_name)\n",
    "        if context.get_context(\"device_target\") != \"GPU\" and self.data_format == \"NHWC\":\n",
    "            raise ValueError(f\"For '{self.cls_name}', the \\\"NHWC\\\" format only support in GPU target, \"\n",
    "                             f\"but got the 'format' is {self.data_format} and \"\n",
    "                             f\"the platform is {context.get_context('device_target')}.\")\n",
    "        if isinstance(padding, int):\n",
    "            Validator.check_non_negative_int(padding, 'padding', self.cls_name)\n",
    "            self.padding = padding\n",
    "        elif isinstance(padding, tuple):\n",
    "            # 对输入进行填充。在输入的高度和宽度方向上填充padding大小的0\n",
    "            for pad in padding:\n",
    "                Validator.check_non_negative_int(pad, 'padding item', self.cls_name)\n",
    "            self.padding = padding\n",
    "        else:\n",
    "            raise TypeError(f\"For '{self.cls_name}', the type of 'padding' must be int or tuple(int), \"\n",
    "                            f\"but got {type(padding).__name__}.\")\n",
    "\n",
    "        # 卷积核膨胀尺寸\n",
    "        self.dilation = dilation\n",
    "        self.group = Validator.check_positive_int(group)\n",
    "        # 卷积层是否添加偏置参数\n",
    "        self.has_bias = has_bias\n",
    "        # 卷积核的高度和宽度。数据类型为整型或两个整型的tuple\n",
    "        for kernel_size_elem in kernel_size:\n",
    "            Validator.check_positive_int(kernel_size_elem, 'kernel_size item', self.cls_name)\n",
    "        for stride_elem in stride:\n",
    "            Validator.check_positive_int(stride_elem, 'stride item', self.cls_name)\n",
    "        for dilation_elem in dilation:\n",
    "            Validator.check_positive_int(dilation_elem, 'dilation item', self.cls_name)\n",
    "        # 将过滤器拆分为组\n",
    "        if in_channels % group != 0:\n",
    "            raise ValueError(f\"For '{self.cls_name}', the attr 'in_channels' must be divisible by attr 'group', \"\n",
    "                             f\"but got 'in_channels': {in_channels} and 'group': {group}.\")\n",
    "        # in_channels和out_channels必须可被group整除\n",
    "        # 如果组数等于in_channels和out_channels，这个二维卷积层也被称为二维深度卷积层。默认值：1。\n",
    "        if out_channels % group != 0:\n",
    "            raise ValueError(f\"For '{self.cls_name}', the 'out_channels' must be divisible by attr 'group', \"\n",
    "                             f\"but got 'out_channels': {out_channels} and 'group': {group}.\")\n",
    "        if transposed:\n",
    "            shape = [in_channels, out_channels // group, *kernel_size]\n",
    "        else:\n",
    "            shape = [out_channels, *kernel_size, in_channels // group] \\\n",
    "                if self.data_format == \"NHWC\" else [out_channels, in_channels // group, *kernel_size]\n",
    "        # 权重参数\n",
    "        self.weight = Parameter(initializer(self.weight_init, shape), name='weight')\n",
    "\n",
    "        if Validator.check_bool(has_bias, \"has_bias\", self.cls_name):\n",
    "            self.bias = Parameter(initializer(self.bias_init, [out_channels]), name='bias')\n",
    "        else:\n",
    "            if self.bias_init != 'zeros':\n",
    "                logger.warning(\"Value of 'has_bias' is False, value of 'bias_init' will be ignored.\")\n",
    "            self.bias = None\n",
    "\n",
    "    # 构造网络\n",
    "    def construct(self, *inputs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def extend_repr(self):\n",
    "        s = 'input_channels={}, output_channels={}, kernel_size={}, ' \\\n",
    "            'stride={}, pad_mode={}, padding={}, dilation={}, ' \\\n",
    "            'group={}, has_bias={}, ' \\\n",
    "            'weight_init={}, bias_init={}, format={}'.format(\n",
    "                # self所表示的是实际调用该方法的对象\n",
    "                self.in_channels,\n",
    "                self.out_channels,\n",
    "                self.kernel_size,\n",
    "                self.stride,\n",
    "                self.pad_mode,\n",
    "                self.padding,\n",
    "                self.dilation,\n",
    "                self.group,\n",
    "                self.has_bias,\n",
    "                self.weight_init,\n",
    "                self.bias_init,\n",
    "                self.data_format)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**实现二维卷积运算**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义Conv2d类，首先进行初始化，该过程包括初始化参数和初始化二维卷积两部分，初始化参数部分将二维卷积核的移动步长定义为1，填充模式设置为默认值'same'，二维卷积核膨胀尺寸设置为1等。然后初始化二维卷积，最后构造二维卷积神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(_Conv):\n",
    "    @cell_attr_register\n",
    "    def __init__(self,\n",
    "                 in_channels,         # 输入Tensor的空间维度\n",
    "                 out_channels,        # 输出Tensor的空间维度\n",
    "                 kernel_size,         # 指定二维卷积核的高度和宽度\n",
    "                 stride=1,            # 二维卷积核的移动步长\n",
    "                 pad_mode='same',     # 指定填充模式。默认值\"same\"，指输出的高度和宽度分别与输入整除stride后的值相同。\n",
    "                 padding=0,           # 输入的高度和宽度方向上填充的数量\n",
    "                 dilation=1,          # 二维卷积核膨胀尺寸\n",
    "                 group=1,             # 将过滤器拆分为组\n",
    "                 has_bias=False,      # 二维卷积层是否添加偏置参数，默认值：False\n",
    "                 weight_init='normal',# 权重参数的初始化方法\n",
    "                 bias_init='zeros',   # 偏置参数的初始化方法\n",
    "                 data_format='NCHW'): # 数据格式的可选值有\"NHWC\"、\"NCHW\"。默认值:\"NCHW\"\n",
    "        # 初始化二维卷积\n",
    "        kernel_size = Validator.twice(kernel_size) # nightly测试\n",
    "        stride = Validator.twice(stride)\n",
    "        self._dilation = dilation\n",
    "        dilation = Validator.twice(dilation)\n",
    "        super(Conv2d, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            pad_mode,\n",
    "            padding,\n",
    "            dilation,\n",
    "            group,\n",
    "            has_bias,\n",
    "            weight_init,\n",
    "            bias_init,\n",
    "            data_format)\n",
    "        self.conv2d = P.Conv2D(out_channel=self.out_channels,\n",
    "                               kernel_size=self.kernel_size,\n",
    "                               mode=1,\n",
    "                               pad_mode=self.pad_mode,\n",
    "                               pad=self.padding,\n",
    "                               stride=self.stride,\n",
    "                               dilation=self.dilation,\n",
    "                               group=self.group,\n",
    "                               data_format=self.data_format)\n",
    "        self.bias_add = P.BiasAdd(data_format=self.data_format)\n",
    "\n",
    "    # 构造二维卷积神经网络\n",
    "    def construct(self, x):\n",
    "        output = self.conv2d(x, self.weight)\n",
    "        if self.has_bias:\n",
    "            output = self.bias_add(output, self.bias)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6、模型测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定Tensor的shape为(1,120,1024,640)，然后调用Conv2d函数来计算二维卷积，最后输出结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.02908076  0.05783416  0.05783416 ...  0.05783416  0.0747276\n",
      "   -0.10985402]\n",
      "  [-0.18333124 -0.2664398  -0.2664398  ... -0.2664398  -0.16775273\n",
      "   -0.19988897]\n",
      "  [-0.18333124 -0.2664398  -0.2664398  ... -0.2664398  -0.16775273\n",
      "   -0.19988897]\n",
      "  ...\n",
      "  [-0.18333124 -0.2664398  -0.2664398  ... -0.2664398  -0.16775273\n",
      "   -0.19988897]\n",
      "  [-0.23326604 -0.3525596  -0.3525596  ... -0.3525596  -0.24423432\n",
      "   -0.22144832]\n",
      "  [-0.34975982 -0.29625094 -0.29625094 ... -0.29625088 -0.09688124\n",
      "   -0.07446267]]]\n",
      "(1, 240, 1024, 640)\n"
     ]
    }
   ],
   "source": [
    "net = Conv2d(120, 240, 4, has_bias=False, weight_init='normal')\n",
    "# 输入\n",
    "x = Tensor(np.ones([1, 120, 1024, 640]), mstype.float32)\n",
    "# 输出\n",
    "output = net(x)\n",
    "print(output[:,6])\n",
    "print(output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
