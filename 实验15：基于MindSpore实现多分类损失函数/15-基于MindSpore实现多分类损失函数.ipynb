{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于MindSpore实现多分类损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、实验目的\n",
    "- 了解多分类损失函数原理。\n",
    "- 掌握如何使用MIndspore实现多分类损失函数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、多分类损失函数原理介绍\n",
    "二分类损失函数中定义了一个简单的平均绝对误差损失函数MAELoss，但许多深度学习应用的数据集较复杂，如目标检测网络Faster R-CNN的数据中就包含多个标签，而非简单的一条数据对应一个标签，这时损失函数的定义和使用略有不同。  \n",
    "针对本实验中创建的多标签数据集，定义多标签损失函数MAELossForMultiLabel。\n",
    "$$ loss\\ 1=\\frac{1}{m}\\ \\sum_{i=1}^{m}\\left|y1_i-f\\left(x_i\\right)\\right| $$\n",
    "$$ loss\\ 2=\\frac{1}{m}\\ \\sum_{i=1}^{m}\\left|y2_i-f\\left(x_i\\right)\\right| $$\n",
    "$$ loss=\\frac{\\left(loss1+loss2\\right)}{2} $$\n",
    "上式中，f(x)为样例标签的预测值，y1和y2为样例标签的真实值，$loss\\ 1$为预测值与真实值y1之间距离的平均值，$loss\\ 2$为预测值与真实值y2之间距离的平均值，loss为损失值$loss\\ 1$与损失值$loss\\ 2$平均值。  \n",
    "在 MAELossForMultilabel中的construct方法的输入有三个，预测值base，真实值target1和target2，在construct中分别计算预测值与真实值target1、预测值与真实值target2之间的误差，将两误差取平均后作为最终的损失函数值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、实验环境\n",
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=1.8；Python环境=3.7\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore1.8 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU CUDA 10.1|Linux-x86_64| MindSpore1.8 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore1.8 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|MindSpore官网"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 构建多标签数据集\n",
    "Numpy模块主要用于数据的基本运算操作。MindSpore相关模块主要用于搭建网络、调用优化器、读取数据集和将数据集处理成网络的标准输入格式。  \n",
    "数据集的两个标签分别由\n",
    "$$y_1=2x+3+{noise}_1$$\n",
    "$$y_2=2x+3+{noise}_2$$\n",
    "生成。其中${noise}_1$和${noise}_2$为服从标准正态分布的随机值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from mindspore import dataset as ds\n",
    "import mindspore.nn as nn\n",
    "import mindspore as ms\n",
    "\n",
    "# 生成带有两个标签的数据集\n",
    "def get_multilabel_data(num, w=2.0, b=3.0):\n",
    "    for _ in range(num):\n",
    "        x = np.random.uniform(-10.0, 10.0)\n",
    "        # noise1和noise2为服从标准正态分布的随机值\n",
    "        noise1 = np.random.normal(0, 1)\n",
    "        noise2 = np.random.normal(-1, 1)\n",
    "        # 定义第一个标签\n",
    "        y1 = x * w + b + noise1                   \n",
    "        # 定义第二个标签\n",
    "        y2 = x * w + b + noise2                   \n",
    "        yield np.array([x]).astype(np.float32), np.array([y1]).astype(np.float32), np.array([y2]).astype(np.float32)\n",
    "\n",
    "def create_multilabel_dataset(num_data, batch_size=16):\n",
    "    dataset = ds.GeneratorDataset(list(get_multilabel_data(num_data)), column_names=['data', 'label1', 'label2'])\n",
    "    # 每个batch有16个数据\n",
    "    dataset = dataset.batch(batch_size) \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 多标签损失函数\n",
    "定义多标签损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义多标签损失函数\n",
    "class MAELossForMultiLabel(nn.LossBase):\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super(MAELossForMultiLabel, self).__init__(reduction)\n",
    "        self.abs = ops.Abs()\n",
    "\n",
    "    def construct(self, base, target1, target2):\n",
    "        # 计算第一个标签的误差\n",
    "        x1 = self.abs(base - target1)\n",
    "        # 计算第二个标签的误差\n",
    "        x2 = self.abs(base - target2)\n",
    "        # 将两误差取平均后作为最终的损失函数值                           \n",
    "        return (self.get_loss(x1) + self.get_loss(x2))/2        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 定义损失函数\n",
    "使用 Model 关联指定的前向网络、损失函数和优化器时，因 Model 内默认使用的 nn.WithLossCell 只接受两个输入： data 和 label ，故不适用于多标签场景。在多标签场景下，若想使用 Model 进行模型训练，则需事先把前向网络与多标签损失函数关联起来，即自定义损失网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义损失网络\n",
    "class CustomWithLossCell(nn.Cell):\n",
    "    def __init__(self, backbone, loss_fn):\n",
    "        super(CustomWithLossCell, self).__init__(auto_prefix=False)\n",
    "        self._backbone = backbone\n",
    "        self._loss_fn = loss_fn\n",
    "\n",
    "    def construct(self, data, label1, label2):\n",
    "        output = self._backbone(data)\n",
    "        return self._loss_fn(output, label1, label2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 定义网络模型\n",
    "定义线性回归网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.common.initializer import Normal\n",
    "import mindspore.ops as ops\n",
    "from mindspore.train import LossMonitor\n",
    "# 定义线性回归网络\n",
    "class LinearNet(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.fc = nn.Dense(1, 1, Normal(0.02), Normal(0.02))\n",
    "\n",
    "    def construct(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6、模型训练\n",
    "定义多标签损失函数、损失网络和优化器，并开始模型的训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1, loss is 11.635913848876953\n",
      "epoch: 1 step: 2, loss is 10.088363647460938\n",
      "epoch: 1 step: 3, loss is 8.024824142456055\n",
      "epoch: 1 step: 4, loss is 13.17223072052002\n",
      "epoch: 1 step: 5, loss is 9.105937957763672\n",
      "epoch: 1 step: 6, loss is 8.499217987060547\n",
      "epoch: 1 step: 7, loss is 9.618066787719727\n",
      "epoch: 1 step: 8, loss is 5.723186492919922\n",
      "epoch: 1 step: 9, loss is 6.688713073730469\n",
      "epoch: 1 step: 10, loss is 5.644274711608887\n",
      "epoch: 2 step: 1, loss is 4.9399871826171875\n",
      "epoch: 2 step: 2, loss is 3.3624444007873535\n",
      "epoch: 2 step: 3, loss is 4.058444976806641\n",
      "epoch: 2 step: 4, loss is 4.039160251617432\n",
      "epoch: 2 step: 5, loss is 2.4770522117614746\n",
      "epoch: 2 step: 6, loss is 2.351071834564209\n",
      "epoch: 2 step: 7, loss is 2.09580135345459\n",
      "epoch: 2 step: 8, loss is 2.4196841716766357\n",
      "epoch: 2 step: 9, loss is 2.578582286834717\n",
      "epoch: 2 step: 10, loss is 2.815429449081421\n",
      "epoch: 3 step: 1, loss is 2.584831714630127\n",
      "epoch: 3 step: 2, loss is 3.321431875228882\n",
      "epoch: 3 step: 3, loss is 3.4809741973876953\n",
      "epoch: 3 step: 4, loss is 2.870295286178589\n",
      "epoch: 3 step: 5, loss is 3.87853741645813\n",
      "epoch: 3 step: 6, loss is 3.0472283363342285\n",
      "epoch: 3 step: 7, loss is 2.4966182708740234\n",
      "epoch: 3 step: 8, loss is 1.8933708667755127\n",
      "epoch: 3 step: 9, loss is 1.9416322708129883\n",
      "epoch: 3 step: 10, loss is 2.2728123664855957\n",
      "epoch: 4 step: 1, loss is 1.7829253673553467\n",
      "epoch: 4 step: 2, loss is 1.8593499660491943\n",
      "epoch: 4 step: 3, loss is 2.3236236572265625\n",
      "epoch: 4 step: 4, loss is 2.2236099243164062\n",
      "epoch: 4 step: 5, loss is 2.0301904678344727\n",
      "epoch: 4 step: 6, loss is 2.1740596294403076\n",
      "epoch: 4 step: 7, loss is 1.2684593200683594\n",
      "epoch: 4 step: 8, loss is 1.9849094152450562\n",
      "epoch: 4 step: 9, loss is 2.1781835556030273\n",
      "epoch: 4 step: 10, loss is 2.0939652919769287\n",
      "epoch: 5 step: 1, loss is 1.9866008758544922\n",
      "epoch: 5 step: 2, loss is 1.8039129972457886\n",
      "epoch: 5 step: 3, loss is 1.6874022483825684\n",
      "epoch: 5 step: 4, loss is 1.725449562072754\n",
      "epoch: 5 step: 5, loss is 1.7159069776535034\n",
      "epoch: 5 step: 6, loss is 1.544924259185791\n",
      "epoch: 5 step: 7, loss is 1.3200085163116455\n",
      "epoch: 5 step: 8, loss is 1.7902419567108154\n",
      "epoch: 5 step: 9, loss is 1.495276689529419\n",
      "epoch: 5 step: 10, loss is 1.3352165222167969\n",
      "epoch: 6 step: 1, loss is 1.626112699508667\n",
      "epoch: 6 step: 2, loss is 1.5859043598175049\n",
      "epoch: 6 step: 3, loss is 1.3656136989593506\n",
      "epoch: 6 step: 4, loss is 1.7658056020736694\n",
      "epoch: 6 step: 5, loss is 1.256749153137207\n",
      "epoch: 6 step: 6, loss is 1.1211895942687988\n",
      "epoch: 6 step: 7, loss is 1.1811497211456299\n",
      "epoch: 6 step: 8, loss is 1.414482593536377\n",
      "epoch: 6 step: 9, loss is 1.5017952919006348\n",
      "epoch: 6 step: 10, loss is 1.0166857242584229\n",
      "epoch: 7 step: 1, loss is 1.0263983011245728\n",
      "epoch: 7 step: 2, loss is 1.0615432262420654\n",
      "epoch: 7 step: 3, loss is 1.2398250102996826\n",
      "epoch: 7 step: 4, loss is 1.1178611516952515\n",
      "epoch: 7 step: 5, loss is 1.0463687181472778\n",
      "epoch: 7 step: 6, loss is 1.2398638725280762\n",
      "epoch: 7 step: 7, loss is 1.085270643234253\n",
      "epoch: 7 step: 8, loss is 1.3174996376037598\n",
      "epoch: 7 step: 9, loss is 1.0539658069610596\n",
      "epoch: 7 step: 10, loss is 1.068223237991333\n",
      "epoch: 8 step: 1, loss is 1.0313681364059448\n",
      "epoch: 8 step: 2, loss is 0.9323046207427979\n",
      "epoch: 8 step: 3, loss is 1.0451021194458008\n",
      "epoch: 8 step: 4, loss is 1.1681275367736816\n",
      "epoch: 8 step: 5, loss is 0.935871958732605\n",
      "epoch: 8 step: 6, loss is 1.0316143035888672\n",
      "epoch: 8 step: 7, loss is 1.0066380500793457\n",
      "epoch: 8 step: 8, loss is 0.9489136338233948\n",
      "epoch: 8 step: 9, loss is 0.8414185047149658\n",
      "epoch: 8 step: 10, loss is 0.840072512626648\n",
      "epoch: 9 step: 1, loss is 0.940424919128418\n",
      "epoch: 9 step: 2, loss is 0.9068505764007568\n",
      "epoch: 9 step: 3, loss is 0.769752562046051\n",
      "epoch: 9 step: 4, loss is 0.7248209714889526\n",
      "epoch: 9 step: 5, loss is 1.099791407585144\n",
      "epoch: 9 step: 6, loss is 0.7989118099212646\n",
      "epoch: 9 step: 7, loss is 1.0865890979766846\n",
      "epoch: 9 step: 8, loss is 0.7501547932624817\n",
      "epoch: 9 step: 9, loss is 1.001189947128296\n",
      "epoch: 9 step: 10, loss is 1.0565162897109985\n",
      "epoch: 10 step: 1, loss is 0.9623186588287354\n",
      "epoch: 10 step: 2, loss is 0.7336476445198059\n",
      "epoch: 10 step: 3, loss is 1.1098051071166992\n",
      "epoch: 10 step: 4, loss is 0.8913776278495789\n",
      "epoch: 10 step: 5, loss is 0.7469063401222229\n",
      "epoch: 10 step: 6, loss is 1.0558159351348877\n",
      "epoch: 10 step: 7, loss is 0.9516366720199585\n",
      "epoch: 10 step: 8, loss is 0.909956693649292\n",
      "epoch: 10 step: 9, loss is 0.9460468292236328\n",
      "epoch: 10 step: 10, loss is 0.7968189120292664\n"
     ]
    }
   ],
   "source": [
    "ds_train = create_multilabel_dataset(num_data=160)\n",
    "net = LinearNet()\n",
    "# 定义多标签损失函数\n",
    "loss = MAELossForMultiLabel()\n",
    "# 定义损失网络，连接前向网络和多标签损失函数\n",
    "loss_net = CustomWithLossCell(net, loss)\n",
    "# 定义优化器\n",
    "opt = nn.Momentum(net.trainable_params(), learning_rate=0.005, momentum=0.9)\n",
    "# 定义Model，多标签场景下Model无需指定损失函数\n",
    "model = ms.Model(network=loss_net, optimizer=opt)\n",
    "\n",
    "model.train(epoch=10, train_dataset=ds_train, callbacks=[LossMonitor(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7、模型预测\n",
    "使用模型进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:[[8.72642184]]\n",
      "predict result:[[[19.74023]]]\n",
      "true result1:[[20.45284368]]\n",
      "true result2:[[20.45284368]]\n"
     ]
    }
   ],
   "source": [
    "from mindspore.train import Model\n",
    "from mindspore import Tensor\n",
    "\n",
    "model_predict = Model(net,loss_net,opt,metrics={\"loss\"})\n",
    "# 生成测试数据\n",
    "w=2.0\n",
    "b=3.0\n",
    "x = np.random.uniform(-10.0, 10.0, (1,1))\n",
    "x1 = np.array([x]).astype(np.float32)\n",
    "# 定义第一个标签\n",
    "true_result1 = x * w + b      \n",
    "# 定义第二个标签\n",
    "true_result2 = x * w + b            \n",
    "print('data:' + '%s'%x)\n",
    "# 模型测试\n",
    "test_result = model_predict.predict(Tensor(x1))\n",
    "print('predict result:' + '%s'%test_result)\n",
    "print('true result1:' + '%s'%true_result1)\n",
    "print('true result2:' + '%s'%true_result2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
