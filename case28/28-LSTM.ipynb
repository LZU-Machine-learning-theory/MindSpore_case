{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c93eafe7-7514-4e57-9af5-d3e30455a6b0",
   "metadata": {},
   "source": [
    "# 基于MindSpore实现LSTM算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07f97b-a465-492f-8477-bc3ebeba3e38",
   "metadata": {},
   "source": [
    "## 基于MindSpore实现LSTM算法进行文本预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4cc0ce-285a-40ac-8411-bc01f8a4a912",
   "metadata": {},
   "source": [
    "### 导入依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5861f722-131e-49e9-930b-aefc6cda3b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore.ops import operations as P\n",
    "from mindspore.train.model import Model\n",
    "from mindspore import context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea75d5b0-0d91-443c-ab05-b1d4ed1be08d",
   "metadata": {},
   "source": [
    "### 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a79e23-6cfc-4ee1-8a55-3cda136f4edc",
   "metadata": {},
   "source": [
    "#### 数据集\n",
    "\n",
    "###### 下载lmdb数据集并解压\n",
    "wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "\n",
    "tar -zxvf aclImdb_v1.tar.gz\n",
    "\n",
    "###### 下载GLove.6b.gz并解压 wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "###### 或在通过存储在缓存的s3地址下载 wget https://apache-mxnet.s3.cn-north-1.amazonaws.com.cn/gluon/embeddings/glove/glove.6B.zip\n",
    "\n",
    "unzip glove.6B.zip -d ./glove\n",
    "\n",
    "###### 在数据集最前面增加一行内容\n",
    "vim glove/glove.6B.300d.txt\n",
    "###### 增加下列内容，指定读取的数据条数和词向量宽度固定的长度\n",
    "400000    300\n",
    "\n",
    "###### 可运行文件的组织形式：\n",
    "\n",
    "28-LSTM.ipynb\n",
    "\n",
    "aclImdb\n",
    "   * test\n",
    "   * train\n",
    "   * imdb.vocab\n",
    "   * imdbEr.txt\n",
    "   * README\n",
    "   \n",
    "glove\n",
    "  * glove.6B.50d.txt\n",
    "  * glove.6B.100d.txt\n",
    "  * glove.6B.200d.txt\n",
    "  * glove.6B.300d.txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e15e70-046c-4ac6-9c22-c1aa4f7bb6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "/src/imdb.py\n",
    "imdb dataset parser.\n",
    "\"\"\"\n",
    "import os\n",
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "\n",
    "class ImdbParser():\n",
    "    \"\"\"\n",
    "    parse aclImdb data to features and labels.\n",
    "    sentence->tokenized->encoded->padding->features\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, imdb_path, glove_path, embed_size=300):\n",
    "        self.__segs = ['train', 'test']\n",
    "        self.__label_dic = {'pos': 1, 'neg': 0}\n",
    "        self.__imdb_path = imdb_path\n",
    "        self.__glove_dim = embed_size\n",
    "        self.__glove_file = os.path.join(glove_path, 'glove.6B.' + str(self.__glove_dim) + 'd.txt')\n",
    "\n",
    "        # properties\n",
    "        self.__imdb_datas = {}\n",
    "        self.__features = {}\n",
    "        self.__labels = {}\n",
    "        self.__vacab = {}\n",
    "        self.__word2idx = {}\n",
    "        self.__weight_np = {}\n",
    "        self.__wvmodel = None\n",
    "\n",
    "    def parse(self):\n",
    "        \"\"\"\n",
    "        parse imdb data to memory\n",
    "        \"\"\"\n",
    "        self.__wvmodel = gensim.models.KeyedVectors.load_word2vec_format(self.__glove_file)\n",
    "\n",
    "        for seg in self.__segs:\n",
    "            self.__parse_imdb_datas(seg)\n",
    "            self.__parse_features_and_labels(seg)\n",
    "            self.__gen_weight_np(seg)\n",
    "\n",
    "    def __parse_imdb_datas(self, seg):\n",
    "        \"\"\"\n",
    "        load data from txt\n",
    "        \"\"\"\n",
    "        data_lists = []\n",
    "        for label_name, label_id in self.__label_dic.items():\n",
    "            sentence_dir = os.path.join(self.__imdb_path, seg, label_name)\n",
    "            for file in os.listdir(sentence_dir):\n",
    "                with open(os.path.join(sentence_dir, file), mode='r', encoding='utf8') as f:\n",
    "                    sentence = f.read().replace('\\n', '')\n",
    "                    data_lists.append([sentence, label_id])\n",
    "        self.__imdb_datas[seg] = data_lists\n",
    "\n",
    "    def __parse_features_and_labels(self, seg):\n",
    "        \"\"\"\n",
    "        parse features and labels\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        labels = []\n",
    "        for sentence, label in self.__imdb_datas[seg]:\n",
    "            features.append(sentence)\n",
    "            labels.append(label)\n",
    "\n",
    "        self.__features[seg] = features\n",
    "        self.__labels[seg] = labels\n",
    "\n",
    "        # update feature to tokenized\n",
    "        self.__updata_features_to_tokenized(seg)\n",
    "        # parse vacab\n",
    "        self.__parse_vacab(seg)\n",
    "        # encode feature\n",
    "        self.__encode_features(seg)\n",
    "        # padding feature\n",
    "        self.__padding_features(seg)\n",
    "\n",
    "    def __updata_features_to_tokenized(self, seg):\n",
    "        tokenized_features = []\n",
    "        for sentence in self.__features[seg]:\n",
    "            tokenized_sentence = [word.lower() for word in sentence.split(\" \")]\n",
    "            tokenized_features.append(tokenized_sentence)\n",
    "        self.__features[seg] = tokenized_features\n",
    "\n",
    "    def __parse_vacab(self, seg):\n",
    "        # vocab\n",
    "        tokenized_features = self.__features[seg]\n",
    "        vocab = set(chain(*tokenized_features))\n",
    "        self.__vacab[seg] = vocab\n",
    "\n",
    "        # word_to_idx: {'hello': 1, 'world':111, ... '<unk>': 0}\n",
    "        word_to_idx = {word: i + 1 for i, word in enumerate(vocab)}\n",
    "        word_to_idx['<unk>'] = 0\n",
    "        self.__word2idx[seg] = word_to_idx\n",
    "\n",
    "    def __encode_features(self, seg):\n",
    "        \"\"\" encode word to index \"\"\"\n",
    "        word_to_idx = self.__word2idx['train']\n",
    "        encoded_features = []\n",
    "        for tokenized_sentence in self.__features[seg]:\n",
    "            encoded_sentence = []\n",
    "            for word in tokenized_sentence:\n",
    "                encoded_sentence.append(word_to_idx.get(word, 0))\n",
    "            encoded_features.append(encoded_sentence)\n",
    "        self.__features[seg] = encoded_features\n",
    "\n",
    "    def __padding_features(self, seg, maxlen=500, pad=0):\n",
    "        \"\"\" pad all features to the same length \"\"\"\n",
    "        padded_features = []\n",
    "        for feature in self.__features[seg]:\n",
    "            if len(feature) >= maxlen:\n",
    "                padded_feature = feature[:maxlen]\n",
    "            else:\n",
    "                padded_feature = feature\n",
    "                while len(padded_feature) < maxlen:\n",
    "                    padded_feature.append(pad)\n",
    "            padded_features.append(padded_feature)\n",
    "        self.__features[seg] = padded_features\n",
    "\n",
    "    def __gen_weight_np(self, seg):\n",
    "        \"\"\"\n",
    "        generate weight by gensim\n",
    "        \"\"\"\n",
    "        weight_np = np.zeros((len(self.__word2idx[seg]), self.__glove_dim), dtype=np.float32)\n",
    "        for word, idx in self.__word2idx[seg].items():\n",
    "            if word not in self.__wvmodel:\n",
    "                continue\n",
    "            word_vector = self.__wvmodel.get_vector(word)\n",
    "            weight_np[idx, :] = word_vector\n",
    "\n",
    "        self.__weight_np[seg] = weight_np\n",
    "\n",
    "    def get_datas(self, seg):\n",
    "        \"\"\"\n",
    "        return features, labels, and weight\n",
    "        \"\"\"\n",
    "        features = np.array(self.__features[seg]).astype(np.int32)\n",
    "        labels = np.array(self.__labels[seg]).astype(np.int32)\n",
    "        weight = np.array(self.__weight_np[seg])\n",
    "        return features, labels, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca4b686-79a6-41b0-bafc-a576d2fc13d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "/src/dataset.py \n",
    "Data operations, will be used in train.py and eval.py\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import mindspore.dataset as ds\n",
    "from mindspore.mindrecord import FileWriter\n",
    "\n",
    "\n",
    "def lstm_create_dataset(data_home, batch_size, repeat_num=1, training=True):\n",
    "    \"\"\"Data operations.\"\"\"\n",
    "    ds.config.set_seed(1)\n",
    "    data_dir = os.path.join(data_home, \"aclImdb_train.mindrecord0\")\n",
    "    if not training:\n",
    "        data_dir = os.path.join(data_home, \"aclImdb_test.mindrecord0\")\n",
    "\n",
    "    data_set = ds.MindDataset(data_dir, columns_list=[\"feature\", \"label\"], num_parallel_workers=4)\n",
    "\n",
    "    # apply map operations on images\n",
    "    data_set = data_set.shuffle(buffer_size=data_set.get_dataset_size())\n",
    "    data_set = data_set.batch(batch_size=batch_size, drop_remainder=True)\n",
    "    data_set = data_set.repeat(count=repeat_num)\n",
    "\n",
    "    return data_set\n",
    "\n",
    "\n",
    "def _convert_to_mindrecord(data_home, features, labels, weight_np=None, training=True):\n",
    "    \"\"\"\n",
    "    convert imdb dataset to mindrecoed dataset\n",
    "    \"\"\"\n",
    "    if weight_np is not None:\n",
    "        np.savetxt(os.path.join(data_home, 'weight.txt'), weight_np)\n",
    "\n",
    "    # write mindrecord\n",
    "    schema_json = {\"id\": {\"type\": \"int32\"},\n",
    "                   \"label\": {\"type\": \"int32\"},\n",
    "                   \"feature\": {\"type\": \"int32\", \"shape\": [-1]}}\n",
    "\n",
    "    data_dir = os.path.join(data_home, \"aclImdb_train.mindrecord\")\n",
    "    if not training:\n",
    "        data_dir = os.path.join(data_home, \"aclImdb_test.mindrecord\")\n",
    "\n",
    "    def get_imdb_data(features, labels):\n",
    "        data_list = []\n",
    "        for i, (label, feature) in enumerate(zip(labels, features)):\n",
    "            data_json = {\"id\": i,\n",
    "                         \"label\": int(label),\n",
    "                         \"feature\": feature.reshape(-1)}\n",
    "            data_list.append(data_json)\n",
    "        return data_list\n",
    "\n",
    "    writer = FileWriter(data_dir, shard_num=4)\n",
    "    data = get_imdb_data(features, labels)\n",
    "    writer.add_schema(schema_json, \"nlp_schema\")\n",
    "    writer.add_index([\"id\", \"label\"])\n",
    "    writer.write_raw_data(data)\n",
    "    writer.commit()\n",
    "\n",
    "\n",
    "def convert_to_mindrecord(embed_size, aclimdb_path, preprocess_path, glove_path):\n",
    "    \"\"\"\n",
    "    convert imdb dataset to mindrecoed dataset\n",
    "    \"\"\"\n",
    "    parser = ImdbParser(aclimdb_path, glove_path, embed_size)\n",
    "    parser.parse()\n",
    "\n",
    "    if not os.path.exists(preprocess_path):\n",
    "        print(f\"preprocess path {preprocess_path} is not exist\")\n",
    "        os.makedirs(preprocess_path)\n",
    "\n",
    "    train_features, train_labels, train_weight_np = parser.get_datas('train')\n",
    "    _convert_to_mindrecord(preprocess_path, train_features, train_labels, train_weight_np)\n",
    "\n",
    "    test_features, test_labels, _ = parser.get_datas('test')\n",
    "    _convert_to_mindrecord(preprocess_path, test_features, test_labels, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83af692d-d3bd-4452-8f50-e5fdb6a05656",
   "metadata": {},
   "source": [
    "### 定义LSTM网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff6ceecb-8e60-42fe-ba1c-2eb05564bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "src/lstm.py\n",
    "LSTM.\n",
    "\"\"\"\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "\n",
    "class SentimentNet(nn.Cell):\n",
    "    \"\"\"Sentiment network structure.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embed_size,\n",
    "                 num_hiddens,\n",
    "                 num_layers,\n",
    "                 bidirectional,\n",
    "                 num_classes,\n",
    "                 weight,\n",
    "                 batch_size):\n",
    "        super(SentimentNet, self).__init__()\n",
    "        # Map words to vectors\n",
    "        self.embedding = nn.Embedding(vocab_size,\n",
    "                                      embed_size,\n",
    "                                      embedding_table=weight)\n",
    "        self.embedding.embedding_table.requires_grad = False\n",
    "        self.trans = ops.Transpose()\n",
    "        self.perm = (1, 0, 2)\n",
    "\n",
    "        self.encoder = nn.LSTM(input_size=embed_size,\n",
    "                               hidden_size=num_hiddens,\n",
    "                               num_layers=num_layers,\n",
    "                               has_bias=True,\n",
    "                               bidirectional=bidirectional,\n",
    "                               dropout=0.0)\n",
    "\n",
    "        self.concat = ops.Concat(1)\n",
    "        if bidirectional:\n",
    "            self.decoder = nn.Dense(num_hiddens * 4, num_classes)\n",
    "        else:\n",
    "            self.decoder = nn.Dense(num_hiddens * 2, num_classes)\n",
    "\n",
    "    def construct(self, inputs):\n",
    "        # input：(64,500,300)\n",
    "        embeddings = self.embedding(inputs)\n",
    "        embeddings = self.trans(embeddings, self.perm)\n",
    "        output, _ = self.encoder(embeddings)\n",
    "        # states[i] size(64,200)  -> encoding.size(64,400)\n",
    "        encoding = self.concat((output[0], output[499]))\n",
    "        outputs = self.decoder(encoding)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34db239b-9131-4e69-b567-1d42143a4f77",
   "metadata": {},
   "source": [
    "### 参数说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "824516b9-2656-4898-b288-65cbe8af6ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "network config setting\n",
    "\"\"\"\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "# LSTM CONFIG\n",
    "lstm_cfg = edict({\n",
    "    'num_classes': 2,\n",
    "    'learning_rate': 0.1,\n",
    "    'momentum': 0.9,\n",
    "    'num_epochs': 20,    #在训练时可以缩小该数字，以缩短训练时间\n",
    "    'batch_size': 64,\n",
    "    'embed_size': 300,\n",
    "    'num_hiddens': 100,\n",
    "    'num_layers': 2,\n",
    "    'bidirectional': True,\n",
    "    'save_checkpoint_steps': 390,\n",
    "    'keep_checkpoint_max': 10\n",
    "})\n",
    "\n",
    "args_train = edict({\n",
    "    'preprocess': 'true',\n",
    "    'aclimdb_path': \"./aclImdb\",\n",
    "    'glove_path': \"./glove\",\n",
    "    'preprocess_path': \"./preprocess\",\n",
    "    'ckpt_path': \"./\",\n",
    "    'pre_trained': None,\n",
    "    'device_target': \"GPU\",\n",
    "})\n",
    "\n",
    "\n",
    "args_test = edict({\n",
    "    'preprocess': 'false',\n",
    "    'aclimdb_path': \"./aclImdb\",\n",
    "    'glove_path': \"./glove\",\n",
    "    'preprocess_path': \"./preprocess\",\n",
    "    'ckpt_path': \"./lstm-20_390.ckpt\",\n",
    "    'pre_trained': None,\n",
    "    'device_target': \"GPU\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea5041-a82b-4783-98d1-2d2166fe5160",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61483dda-94a3-44c0-ba6f-93865f612833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Data Pre-processing ==============\n",
      "preprocess path ./preprocess is not exist\n",
      "============== Starting Training ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(19885:139636537116480,MainProcess):2022-11-06-19:21:52.636.799 [mindspore/ops/primitive.py:710] The \"_check_is_tensor\" is a constexpr function. The input arguments must be all constant value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 390, loss is 0.7205508351325989\n",
      "Train epoch time: 250188.561 ms, per step time: 641.509 ms\n",
      "epoch: 2 step: 390, loss is 0.6671831011772156\n",
      "Train epoch time: 47229.054 ms, per step time: 121.100 ms\n",
      "epoch: 3 step: 390, loss is 0.4601467549800873\n",
      "Train epoch time: 48292.142 ms, per step time: 123.826 ms\n",
      "epoch: 4 step: 390, loss is 0.450219064950943\n",
      "Train epoch time: 46433.243 ms, per step time: 119.060 ms\n",
      "epoch: 5 step: 390, loss is 0.29337450861930847\n",
      "Train epoch time: 46568.676 ms, per step time: 119.407 ms\n",
      "epoch: 6 step: 390, loss is 0.3129003643989563\n",
      "Train epoch time: 45734.321 ms, per step time: 117.267 ms\n",
      "epoch: 7 step: 390, loss is 0.3851388692855835\n",
      "Train epoch time: 46201.746 ms, per step time: 118.466 ms\n",
      "epoch: 8 step: 390, loss is 0.31343045830726624\n",
      "Train epoch time: 45994.209 ms, per step time: 117.934 ms\n",
      "epoch: 9 step: 390, loss is 0.4255286157131195\n",
      "Train epoch time: 46170.017 ms, per step time: 118.385 ms\n",
      "epoch: 10 step: 390, loss is 0.34127986431121826\n",
      "Train epoch time: 46841.445 ms, per step time: 120.106 ms\n",
      "epoch: 11 step: 390, loss is 0.48328787088394165\n",
      "Train epoch time: 46268.562 ms, per step time: 118.637 ms\n",
      "epoch: 12 step: 390, loss is 0.32908645272254944\n",
      "Train epoch time: 46295.593 ms, per step time: 118.707 ms\n",
      "epoch: 13 step: 390, loss is 0.2960771322250366\n",
      "Train epoch time: 46462.420 ms, per step time: 119.134 ms\n",
      "epoch: 14 step: 390, loss is 0.2120082676410675\n",
      "Train epoch time: 46804.857 ms, per step time: 120.012 ms\n",
      "epoch: 15 step: 390, loss is 0.27453160285949707\n",
      "Train epoch time: 46647.650 ms, per step time: 119.609 ms\n",
      "epoch: 16 step: 390, loss is 0.2562940716743469\n",
      "Train epoch time: 46767.332 ms, per step time: 119.916 ms\n",
      "epoch: 17 step: 390, loss is 0.2511977553367615\n",
      "Train epoch time: 46525.773 ms, per step time: 119.297 ms\n",
      "epoch: 18 step: 390, loss is 0.15805645287036896\n",
      "Train epoch time: 46826.617 ms, per step time: 120.068 ms\n",
      "epoch: 19 step: 390, loss is 0.1930314153432846\n",
      "Train epoch time: 46807.944 ms, per step time: 120.020 ms\n",
      "epoch: 20 step: 390, loss is 0.11822246760129929\n",
      "Train epoch time: 46660.658 ms, per step time: 119.643 ms\n",
      "============== Training Success ==============\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#################train lstm example on aclImdb########################\n",
    "python train.py --preprocess=true --aclimdb_path=your_imdb_path --glove_path=your_glove_path\n",
    "\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "from src.config import lstm_cfg as cfg\n",
    "from src.dataset import convert_to_mindrecord\n",
    "from src.dataset import lstm_create_dataset\n",
    "from src.lstm import SentimentNet\n",
    "\"\"\"\n",
    "from mindspore import Tensor, nn, Model, context, load_param_into_net, load_checkpoint\n",
    "from mindspore.nn import Accuracy\n",
    "from mindspore.train.callback import LossMonitor, CheckpointConfig, ModelCheckpoint, TimeMonitor\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "if 1:\n",
    "    args = args_train\n",
    "\n",
    "    cfg = lstm_cfg\n",
    "    context.set_context(\n",
    "        mode=context.GRAPH_MODE,\n",
    "        save_graphs=False,\n",
    "        device_target=args.device_target)\n",
    "\n",
    "    if args.preprocess == \"true\":\n",
    "        print(\"============== Starting Data Pre-processing ==============\")\n",
    "        convert_to_mindrecord(cfg.embed_size, args.aclimdb_path, args.preprocess_path, args.glove_path)\n",
    "\n",
    "    embedding_table = np.loadtxt(os.path.join(args.preprocess_path, \"weight.txt\")).astype(np.float32)\n",
    "    network = SentimentNet(vocab_size=embedding_table.shape[0],\n",
    "                           embed_size=cfg.embed_size,\n",
    "                           num_hiddens=cfg.num_hiddens,\n",
    "                           num_layers=cfg.num_layers,\n",
    "                           bidirectional=cfg.bidirectional,\n",
    "                           num_classes=cfg.num_classes,\n",
    "                           weight=Tensor(embedding_table),\n",
    "                           batch_size=cfg.batch_size)\n",
    "    # pre_trained\n",
    "    if args.pre_trained:\n",
    "        load_param_into_net(network, load_checkpoint(args.pre_trained))\n",
    "\n",
    "    loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    opt = nn.Momentum(network.trainable_params(), cfg.learning_rate, cfg.momentum)\n",
    "    loss_cb = LossMonitor()\n",
    "\n",
    "    model = Model(network, loss, opt, {'acc': Accuracy()})\n",
    "\n",
    "    print(\"============== Starting Training ==============\")\n",
    "    ds_train = lstm_create_dataset(args.preprocess_path, cfg.batch_size, 1)\n",
    "    config_ck = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps,\n",
    "                                 keep_checkpoint_max=cfg.keep_checkpoint_max)\n",
    "    ckpoint_cb = ModelCheckpoint(prefix=\"lstm\", directory=args.ckpt_path, config=config_ck)\n",
    "    time_cb = TimeMonitor(data_size=ds_train.get_dataset_size())\n",
    "    if args.device_target == \"CPU\":\n",
    "        model.train(cfg.num_epochs, ds_train, callbacks=[time_cb, ckpoint_cb, loss_cb], dataset_sink_mode=False)\n",
    "    else:\n",
    "        model.train(cfg.num_epochs, ds_train, callbacks=[time_cb, ckpoint_cb, loss_cb])\n",
    "    print(\"============== Training Success ==============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94590778-6498-41f8-934d-f810a0f12669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3746b878-81fa-43c4-8e20-e9a074ec46e6",
   "metadata": {},
   "source": [
    "### 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9399bab-daec-48ca-bc28-39bc9696dea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Testing ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(19885:139636537116480,MainProcess):2022-11-06-19:44:22.474.800 [mindspore/ops/primitive.py:710] The \"_check_is_tensor\" is a constexpr function. The input arguments must be all constant value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== {'acc': 0.8423878205128205} ==============\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#################train lstm example on aclImdb########################\n",
    "python eval.py --ckpt_path=./lstm-20-390.ckpt\n",
    "\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "from src.config import lstm_cfg as cfg\n",
    "from src.dataset import lstm_create_dataset, convert_to_mindrecord\n",
    "from src.lstm import SentimentNet\n",
    "\"\"\"\n",
    "from mindspore import Tensor, nn, Model, context, load_checkpoint, load_param_into_net\n",
    "from mindspore.nn import Accuracy\n",
    "from mindspore.train.callback import LossMonitor\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "if 1:\n",
    "    args = args_test\n",
    "\n",
    "    context.set_context(\n",
    "        mode=context.GRAPH_MODE,\n",
    "        save_graphs=False,\n",
    "        device_target=args.device_target)\n",
    "\n",
    "    if args.preprocess == \"true\":\n",
    "        print(\"============== Starting Data Pre-processing ==============\")\n",
    "        convert_to_mindrecord(cfg.embed_size, args.aclimdb_path, args.preprocess_path, args.glove_path)\n",
    "\n",
    "    embedding_table = np.loadtxt(os.path.join(args.preprocess_path, \"weight.txt\")).astype(np.float32)\n",
    "    network = SentimentNet(vocab_size=embedding_table.shape[0],\n",
    "                           embed_size=cfg.embed_size,\n",
    "                           num_hiddens=cfg.num_hiddens,\n",
    "                           num_layers=cfg.num_layers,\n",
    "                           bidirectional=cfg.bidirectional,\n",
    "                           num_classes=cfg.num_classes,\n",
    "                           weight=Tensor(embedding_table),\n",
    "                           batch_size=cfg.batch_size)\n",
    "\n",
    "    loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    opt = nn.Momentum(network.trainable_params(), cfg.learning_rate, cfg.momentum)\n",
    "    loss_cb = LossMonitor()\n",
    "\n",
    "    model = Model(network, loss, opt, {'acc': Accuracy()})\n",
    "\n",
    "    print(\"============== Starting Testing ==============\")\n",
    "    ds_eval = lstm_create_dataset(args.preprocess_path, cfg.batch_size, training=False)\n",
    "    param_dict = load_checkpoint(args.ckpt_path)\n",
    "    load_param_into_net(network, param_dict)\n",
    "    if args.device_target == \"CPU\":\n",
    "        acc = model.eval(ds_eval, dataset_sink_mode=False)\n",
    "    else:\n",
    "        acc = model.eval(ds_eval)\n",
    "    print(\"============== {} ==============\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3438c1-0348-42a5-8c9a-620086549546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
